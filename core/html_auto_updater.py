#!/usr/bin/env python3
"""
HTMLè‡ªå‹•æ›´æ–°ã‚·ã‚¹ãƒ†ãƒ  - Gemini AIçµ±åˆ
ãƒ‡ãƒ—ãƒ­ã‚¤æ™‚ã«æœ€çµ‚æ›´æ–°æ—¥æ™‚ã¨ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ãƒãƒƒã‚¸ã‚’è‡ªå‹•æ›´æ–°
"""

import os
import re
import json
import shutil
import subprocess
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Optional, Tuple
import logging

# ãƒ­ã‚°è¨­å®š
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class HTMLAutoUpdater:
    def __init__(self):
        self.project_root = Path.cwd()
        self.backup_dir = self.project_root / ".html_backups"
        self.log_file = self.project_root / "logs" / "html_updates.json"
        self.ensure_directories()
        
        # æ›´æ–°å¯¾è±¡HTMLãƒ•ã‚¡ã‚¤ãƒ«
        self.target_files = [
            self.project_root / "index.html",
            self.project_root / "public" / "index.html"
        ]
        
        # æ—¥æœ¬æ™‚é–“ç”¨ã®ã‚¿ã‚¤ãƒ ã‚¾ãƒ¼ãƒ³æƒ…å ±
        self.jst_offset = 9  # UTC+9
        
    def ensure_directories(self):
        """å¿…è¦ãªãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆ"""
        self.backup_dir.mkdir(parents=True, exist_ok=True)
        (self.project_root / "logs").mkdir(exist_ok=True)
        
    def get_japanese_datetime(self) -> str:
        """æ—¥æœ¬æ™‚é–“ã®ç¾åœ¨æ—¥æ™‚ã‚’å–å¾— (YYYYå¹´MMæœˆDDæ—¥ HH:MMå½¢å¼)"""
        now = datetime.utcnow()
        # UTC+9æ™‚é–“ã‚’åŠ ç®—ã—ã¦æ—¥æœ¬æ™‚é–“ã«å¤‰æ›
        jst_time = now.replace(hour=(now.hour + self.jst_offset) % 24)
        return jst_time.strftime('%Yå¹´%mæœˆ%dæ—¥ %H:%M')
    
    def get_git_commit_info(self) -> Dict[str, str]:
        """æœ€æ–°ã®Gitã‚³ãƒŸãƒƒãƒˆæƒ…å ±ã‚’å–å¾—"""
        try:
            # æœ€æ–°ã‚³ãƒŸãƒƒãƒˆãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
            commit_msg = subprocess.run(
                ["git", "log", "-1", "--pretty=format:%s"],
                capture_output=True, text=True, check=True
            ).stdout.strip()
            
            # æœ€æ–°ã‚³ãƒŸãƒƒãƒˆãƒãƒƒã‚·ãƒ¥
            commit_hash = subprocess.run(
                ["git", "log", "-1", "--pretty=format:%h"],
                capture_output=True, text=True, check=True
            ).stdout.strip()
            
            return {
                "message": commit_msg,
                "hash": commit_hash,
                "timestamp": self.get_japanese_datetime()
            }
        except subprocess.CalledProcessError as e:
            logger.warning(f"Gitæƒ…å ±å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
            return {
                "message": "Gitæƒ…å ±å–å¾—å¤±æ•—",
                "hash": "unknown",
                "timestamp": self.get_japanese_datetime()
            }
    
    def generate_status_badge(self, commit_message: str) -> str:
        """ã‚³ãƒŸãƒƒãƒˆãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‹ã‚‰é©åˆ‡ãªã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ãƒãƒƒã‚¸ã‚’ç”Ÿæˆ"""
        commit_lower = commit_message.lower()
        
        # AIæ¨å¥¨ãƒãƒƒã‚¸ãƒãƒƒãƒ”ãƒ³ã‚°
        badge_patterns = {
            "ãƒ‡ã‚£ã‚¹ã‚«ãƒƒã‚·ãƒ§ãƒ³": "ãƒ‡ã‚£ã‚¹ã‚«ãƒƒã‚·ãƒ§ãƒ³ã‚µã‚¤ãƒˆçµ±åˆå®Œäº†",
            "discussion": "ãƒ‡ã‚£ã‚¹ã‚«ãƒƒã‚·ãƒ§ãƒ³ã‚µã‚¤ãƒˆçµ±åˆå®Œäº†", 
            "ui": "UIæ”¹å–„å®Œäº†",
            "design": "ãƒ‡ã‚¶ã‚¤ãƒ³æ›´æ–°å®Œäº†",
            "feature": "æ–°æ©Ÿèƒ½è¿½åŠ å®Œäº†",
            "fix": "ãƒã‚°ä¿®æ­£å®Œäº†",
            "deploy": "è‡ªå‹•ãƒ‡ãƒ—ãƒ­ã‚¤å®Œäº†",
            "auto": "è‡ªå‹•ã‚·ã‚¹ãƒ†ãƒ ç¨¼åƒä¸­",
            "test": "ãƒ†ã‚¹ãƒˆå®Ÿè¡Œå®Œäº†",
            "doc": "ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæ›´æ–°å®Œäº†",
            "security": "ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£å¼·åŒ–å®Œäº†",
            "performance": "ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹å‘ä¸Šå®Œäº†",
            "api": "APIçµ±åˆå®Œäº†",
            "database": "ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ›´æ–°å®Œäº†",
            "mobile": "ãƒ¢ãƒã‚¤ãƒ«å¯¾å¿œå®Œäº†"
        }
        
        # ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒãƒƒãƒãƒ³ã‚°
        for keyword, badge in badge_patterns.items():
            if keyword in commit_lower:
                return badge
        
        # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒãƒƒã‚¸ï¼ˆã‚³ãƒŸãƒƒãƒˆã®ç¨®é¡ã‚’æ¨æ¸¬ï¼‰
        if "merge" in commit_lower:
            return "çµ±åˆä½œæ¥­å®Œäº†"
        elif "update" in commit_lower:
            return "ã‚·ã‚¹ãƒ†ãƒ æ›´æ–°å®Œäº†"
        elif "add" in commit_lower:
            return "ã‚³ãƒ³ãƒ†ãƒ³ãƒ„è¿½åŠ å®Œäº†"
        elif "improve" in commit_lower:
            return "ã‚·ã‚¹ãƒ†ãƒ æ”¹å–„å®Œäº†"
        else:
            return "æœ€æ–°ç‰ˆãƒªãƒªãƒ¼ã‚¹å®Œäº†"
    
    def create_backup(self, file_path: Path) -> Path:
        """HTMLãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚’ä½œæˆ"""
        if not file_path.exists():
            return None
            
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        backup_name = f"{file_path.stem}_{timestamp}.html"
        backup_path = self.backup_dir / backup_name
        
        try:
            shutil.copy2(file_path, backup_path)
            logger.info(f"ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ä½œæˆ: {backup_path}")
            return backup_path
        except Exception as e:
            logger.error(f"ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ä½œæˆå¤±æ•—: {e}")
            return None
    
    def update_html_content(self, html_content: str, update_info: Dict) -> str:
        """HTMLã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’æ›´æ–°"""
        updated_content = html_content
        changes = []
        
        # 1. æœ€çµ‚æ›´æ–°æ—¥æ™‚ã®æ›´æ–° (è¡Œ166)
        last_update_pattern = r'(<span id="lastUpdate">)[^<]+(</span>)'
        new_last_update = f'\\g<1>{update_info["datetime"]}\\g<2>'
        
        if re.search(last_update_pattern, updated_content):
            updated_content = re.sub(last_update_pattern, new_last_update, updated_content)
            changes.append(f"æœ€çµ‚æ›´æ–°æ—¥æ™‚: {update_info['datetime']}")
        
        # 2. ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ãƒãƒƒã‚¸ã®æ›´æ–° (è¡Œ164)
        badge_pattern = r'(<span class="badge">)[^<]+(</span>)'
        new_badge = f'\\g<1>{update_info["status_badge"]}\\g<2>'
        
        if re.search(badge_pattern, updated_content):
            updated_content = re.sub(badge_pattern, new_badge, updated_content)
            changes.append(f"ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ãƒãƒƒã‚¸: {update_info['status_badge']}")
        
        # 3. JavaScriptå›ºå®šæ—¥æ™‚ã®æ›´æ–° (è¡Œ392)
        js_datetime_pattern = r"(const LAST_UPDATE = ')[^']+(';)"
        new_js_datetime = f"\\g<1>{update_info['datetime']}\\g<2>"
        
        if re.search(js_datetime_pattern, updated_content):
            updated_content = re.sub(js_datetime_pattern, new_js_datetime, updated_content)
            changes.append(f"JavaScriptæ—¥æ™‚: {update_info['datetime']}")
        
        # 4. Build Time ã‚³ãƒ¡ãƒ³ãƒˆã®æ›´æ–° (è¡Œ3)
        build_time_pattern = r'(<!-- Build Time: )[^-]+(-->)'
        current_month = datetime.now().strftime('%Yå¹´%mæœˆ')
        new_build_time = f'\\g<1>{current_month} \\g<2>'
        
        if re.search(build_time_pattern, updated_content):
            updated_content = re.sub(build_time_pattern, new_build_time, updated_content)
            changes.append(f"ãƒ“ãƒ«ãƒ‰æ™‚é–“: {current_month}")
        
        # 5. Deploy ID ã®æ›´æ–° (è¡Œ4)
        deploy_id_pattern = r'(<!-- Deploy ID: )[^-]+(-->)'
        deploy_id = datetime.now().strftime('%Y%m%d_%H%M')
        new_deploy_id = f'\\g<1>{deploy_id} \\g<2>'
        
        if re.search(deploy_id_pattern, updated_content):
            updated_content = re.sub(deploy_id_pattern, new_deploy_id, updated_content)
            changes.append(f"ãƒ‡ãƒ—ãƒ­ã‚¤ID: {deploy_id}")
        
        return updated_content, changes
    
    def validate_html_integrity(self, html_content: str) -> Tuple[bool, List[str]]:
        """HTMLã®æ•´åˆæ€§ã‚’ãƒã‚§ãƒƒã‚¯"""
        issues = []
        
        # åŸºæœ¬æ§‹é€ ãƒã‚§ãƒƒã‚¯
        required_elements = [
            r'<!DOCTYPE html>',
            r'<html[^>]*>',
            r'<head>',
            r'</head>',
            r'<body>',
            r'</body>',
            r'</html>'
        ]
        
        for element in required_elements:
            if not re.search(element, html_content, re.IGNORECASE):
                issues.append(f"å¿…é ˆè¦ç´ ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {element}")
        
        # å±é™ºãªã‚³ãƒ¼ãƒ‰ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒã‚§ãƒƒã‚¯
        dangerous_patterns = [
            r'<script[^>]*src=["\'][^"\']*[<>]',  # XSSå¯¾ç­–
            r'javascript:',  # JavaScript URL
            r'on\w+\s*=\s*["\'][^"\']*<',  # ã‚¤ãƒ³ãƒ©ã‚¤ãƒ³ã‚¤ãƒ™ãƒ³ãƒˆãƒãƒ³ãƒ‰ãƒ©ãƒ¼ã®ä¸æ­£ä½¿ç”¨
            r'eval\s*\(',  # evalé–¢æ•°
            r'document\.write\s*\('  # document.write
        ]
        
        for pattern in dangerous_patterns:
            if re.search(pattern, html_content, re.IGNORECASE):
                issues.append(f"ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒªã‚¹ã‚¯æ¤œå‡º: {pattern}")
        
        # ã‚¿ã‚°ã®å¯¾å¿œãƒã‚§ãƒƒã‚¯ï¼ˆç°¡æ˜“ç‰ˆï¼‰
        tag_pairs = ['html', 'head', 'body', 'div', 'span', 'script', 'style']
        for tag in tag_pairs:
            open_count = len(re.findall(f'<{tag}[^>]*>', html_content, re.IGNORECASE))
            close_count = len(re.findall(f'</{tag}>', html_content, re.IGNORECASE))
            if open_count != close_count:
                issues.append(f"ã‚¿ã‚°ã®å¯¾å¿œä¸ä¸€è‡´: {tag} (é–‹å§‹:{open_count}, çµ‚äº†:{close_count})")
        
        return len(issues) == 0, issues
    
    def log_update(self, update_info: Dict, changes: List[str], file_path: Path):
        """æ›´æ–°ãƒ­ã‚°ã‚’è¨˜éŒ²"""
        log_entry = {
            "timestamp": datetime.now().isoformat(),
            "file": str(file_path),
            "git_info": update_info.get("git_info", {}),
            "changes": changes,
            "update_datetime": update_info["datetime"],
            "status_badge": update_info["status_badge"]
        }
        
        # æ—¢å­˜ãƒ­ã‚°ã‚’èª­ã¿è¾¼ã¿
        logs = []
        if self.log_file.exists():
            try:
                with open(self.log_file, 'r', encoding='utf-8') as f:
                    logs = json.load(f)
            except:
                logs = []
        
        logs.append(log_entry)
        
        # æœ€æ–°100ä»¶ã®ã¿ä¿æŒ
        if len(logs) > 100:
            logs = logs[-100:]
        
        # ãƒ­ã‚°ä¿å­˜
        try:
            with open(self.log_file, 'w', encoding='utf-8') as f:
                json.dump(logs, f, ensure_ascii=False, indent=2)
        except Exception as e:
            logger.error(f"ãƒ­ã‚°ä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")
    
    def rollback_from_backup(self, file_path: Path, backup_timestamp: str = None) -> bool:
        """ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‹ã‚‰ãƒ­ãƒ¼ãƒ«ãƒãƒƒã‚¯"""
        if not backup_timestamp:
            # æœ€æ–°ã®ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚’ä½¿ç”¨
            backup_files = list(self.backup_dir.glob(f"{file_path.stem}_*.html"))
            if not backup_files:
                logger.error("åˆ©ç”¨å¯èƒ½ãªãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãŒã‚ã‚Šã¾ã›ã‚“")
                return False
            backup_file = max(backup_files, key=lambda p: p.stat().st_mtime)
        else:
            backup_file = self.backup_dir / f"{file_path.stem}_{backup_timestamp}.html"
            if not backup_file.exists():
                logger.error(f"æŒ‡å®šã•ã‚ŒãŸãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {backup_file}")
                return False
        
        try:
            shutil.copy2(backup_file, file_path)
            logger.info(f"ãƒ­ãƒ¼ãƒ«ãƒãƒƒã‚¯å®Œäº†: {backup_file} -> {file_path}")
            return True
        except Exception as e:
            logger.error(f"ãƒ­ãƒ¼ãƒ«ãƒãƒƒã‚¯å¤±æ•—: {e}")
            return False
    
    def update_all_html_files(self) -> Dict:
        """å…¨ã¦ã®HTMLãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ›´æ–°"""
        results = {
            "success": True,
            "updated_files": [],
            "errors": [],
            "backups_created": []
        }
        
        # Gitæƒ…å ±ã‚’å–å¾—
        git_info = self.get_git_commit_info()
        
        # æ›´æ–°æƒ…å ±ã‚’æº–å‚™
        update_info = {
            "datetime": self.get_japanese_datetime(),
            "status_badge": self.generate_status_badge(git_info["message"]),
            "git_info": git_info
        }
        
        logger.info(f"æ›´æ–°é–‹å§‹: {update_info['datetime']}")
        logger.info(f"ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹: {update_info['status_badge']}")
        
        for file_path in self.target_files:
            if not file_path.exists():
                logger.warning(f"ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ã¾ã›ã‚“: {file_path}")
                continue
            
            try:
                # ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ä½œæˆ
                backup_path = self.create_backup(file_path)
                if backup_path:
                    results["backups_created"].append(str(backup_path))
                
                # HTMLãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿
                with open(file_path, 'r', encoding='utf-8') as f:
                    original_content = f.read()
                
                # å†…å®¹ã‚’æ›´æ–°
                updated_content, changes = self.update_html_content(original_content, update_info)
                
                # æ•´åˆæ€§ãƒã‚§ãƒƒã‚¯
                is_valid, issues = self.validate_html_integrity(updated_content)
                if not is_valid:
                    logger.error(f"HTMLã®æ•´åˆæ€§ã‚¨ãƒ©ãƒ¼: {file_path}")
                    for issue in issues:
                        logger.error(f"  - {issue}")
                    results["errors"].append(f"{file_path}: æ•´åˆæ€§ãƒã‚§ãƒƒã‚¯å¤±æ•—")
                    
                    # ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‹ã‚‰ãƒ­ãƒ¼ãƒ«ãƒãƒƒã‚¯
                    if backup_path:
                        self.rollback_from_backup(file_path)
                    continue
                
                # ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ›´æ–°
                with open(file_path, 'w', encoding='utf-8') as f:
                    f.write(updated_content)
                
                # ãƒ­ã‚°è¨˜éŒ²
                self.log_update(update_info, changes, file_path)
                
                results["updated_files"].append({
                    "file": str(file_path),
                    "changes": changes
                })
                
                logger.info(f"æ›´æ–°å®Œäº†: {file_path}")
                for change in changes:
                    logger.info(f"  - {change}")
                
            except Exception as e:
                error_msg = f"{file_path}: {str(e)}"
                results["errors"].append(error_msg)
                results["success"] = False
                logger.error(f"æ›´æ–°ã‚¨ãƒ©ãƒ¼: {error_msg}")
                
                # ã‚¨ãƒ©ãƒ¼æ™‚ã®ãƒ­ãƒ¼ãƒ«ãƒãƒƒã‚¯
                if backup_path:
                    self.rollback_from_backup(file_path)
        
        return results

def main():
    """ãƒ¡ã‚¤ãƒ³ã‚¨ãƒ³ãƒˆãƒªãƒ¼ãƒã‚¤ãƒ³ãƒˆ"""
    print("ğŸ”„ HTMLè‡ªå‹•æ›´æ–°ã‚·ã‚¹ãƒ†ãƒ  - Gemini AIçµ±åˆ")
    print("=" * 50)
    
    updater = HTMLAutoUpdater()
    results = updater.update_all_html_files()
    
    if results["success"] and results["updated_files"]:
        print("âœ… æ›´æ–°å®Œäº†")
        for file_info in results["updated_files"]:
            print(f"ğŸ“„ {file_info['file']}")
            for change in file_info["changes"]:
                print(f"  - {change}")
        
        if results["backups_created"]:
            print(f"\nğŸ’¾ ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ä½œæˆ: {len(results['backups_created'])}ä»¶")
    
    elif results["errors"]:
        print("âŒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ")
        for error in results["errors"]:
            print(f"  - {error}")
        return 1
    
    else:
        print("â„¹ï¸ æ›´æ–°å¯¾è±¡ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
    
    return 0

if __name__ == "__main__":
    import sys
    sys.exit(main())