{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 📊 意味カテゴリ画像分類研究 - Colab版\n",
    "\n",
    "WordNetベースの意味カテゴリ画像分類システムの研究をGoogle Colabで実行します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 環境セットアップ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Colab環境確認\n",
    "try:\n",
    "    import google.colab\n",
    "    IN_COLAB = True\n",
    "    print(\"✅ Google Colabで実行中\")\n",
    "except:\n",
    "    IN_COLAB = False\n",
    "    print(\"❌ ローカル環境で実行中\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 必要なライブラリのインストール\n",
    "if IN_COLAB:\n",
    "    !pip install -q torch torchvision torchaudio\n",
    "    !pip install -q transformers\n",
    "    !pip install -q ultralytics\n",
    "    !pip install -q opencv-python\n",
    "    !pip install -q pillow\n",
    "    !pip install -q matplotlib\n",
    "    !pip install -q seaborn\n",
    "    !pip install -q pandas\n",
    "    !pip install -q numpy\n",
    "    !pip install -q nltk\n",
    "    !pip install -q scipy\n",
    "    !pip install -q scikit-learn\n",
    "    print(\"✅ ライブラリインストール完了\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 基本ライブラリのインポート\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "from transformers import BlipProcessor, BlipForConditionalGeneration\n",
    "from transformers import CLIPProcessor, CLIPModel\n",
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import nltk\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from sklearn.metrics import accuracy_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"✅ ライブラリインポート完了\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NLTK データのダウンロード\n",
    "import nltk\n",
    "nltk.download('wordnet', quiet=True)\n",
    "nltk.download('omw-1.4', quiet=True)\n",
    "from nltk.corpus import wordnet as wn\n",
    "print(\"✅ WordNet準備完了\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Google Driveマウント（オプション）\n",
    "if IN_COLAB:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    print(\"✅ Google Drive接続完了\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 研究システムの初期化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# デバイス設定\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"使用デバイス: {device}\")\n",
    "\n",
    "# 作業ディレクトリ設定\n",
    "import os\n",
    "work_dir = '/content/research' if IN_COLAB else './research'\n",
    "os.makedirs(work_dir, exist_ok=True)\n",
    "os.chdir(work_dir)\n",
    "print(f\"作業ディレクトリ: {work_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデルの初期化\n",
    "print(\"🤖 AIモデルを初期化中...\")\n",
    "\n",
    "# BLIP (画像キャプション生成)\n",
    "blip_processor = BlipProcessor.from_pretrained(\"Salesforce/blip-image-captioning-base\")\n",
    "blip_model = BlipForConditionalGeneration.from_pretrained(\"Salesforce/blip-image-captioning-base\").to(device)\n",
    "\n",
    "# CLIP (画像-テキスト分類)\n",
    "clip_processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "clip_model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\").to(device)\n",
    "\n",
    "# YOLO (物体検出)\n",
    "yolo_model = YOLO('yolov8n.pt')\n",
    "\n",
    "print(\"✅ AIモデル初期化完了\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 研究用画像分類システム"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 意味カテゴリ定義\n",
    "SEMANTIC_CATEGORIES = {\n",
    "    'person': ['person', 'man', 'woman', 'child', 'people', 'human', 'face'],\n",
    "    'animal': ['dog', 'cat', 'bird', 'horse', 'cow', 'elephant', 'bear', 'zebra'],\n",
    "    'food': ['pizza', 'hamburger', 'cake', 'apple', 'banana', 'sandwich', 'donut'],\n",
    "    'vehicle': ['car', 'bus', 'truck', 'motorcycle', 'bicycle', 'airplane', 'boat'],\n",
    "    'building': ['house', 'building', 'bridge', 'castle', 'church', 'tower'],\n",
    "    'furniture': ['chair', 'table', 'sofa', 'bed', 'desk', 'bench'],\n",
    "    'plant': ['tree', 'flower', 'grass', 'plant', 'garden', 'forest'],\n",
    "    'landscape': ['mountain', 'beach', 'lake', 'river', 'sky', 'sunset']\n",
    "}\n",
    "\n",
    "print(\"✅ 意味カテゴリ定義完了\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SemanticImageClassifier:\n",
    "    def __init__(self):\n",
    "        self.results = []\n",
    "        \n",
    "    def generate_caption(self, image):\n",
    "        \"\"\"画像キャプションを生成\"\"\"\n",
    "        inputs = blip_processor(image, return_tensors=\"pt\").to(device)\n",
    "        out = blip_model.generate(**inputs, max_length=50)\n",
    "        caption = blip_processor.decode(out[0], skip_special_tokens=True)\n",
    "        return caption\n",
    "    \n",
    "    def detect_semantic_category(self, caption):\n",
    "        \"\"\"意味カテゴリを検出\"\"\"\n",
    "        caption_lower = caption.lower()\n",
    "        \n",
    "        # 各カテゴリとの一致度を計算\n",
    "        category_scores = {}\n",
    "        for category, keywords in SEMANTIC_CATEGORIES.items():\n",
    "            score = sum(1 for keyword in keywords if keyword in caption_lower)\n",
    "            if score > 0:\n",
    "                category_scores[category] = score\n",
    "        \n",
    "        if category_scores:\n",
    "            return max(category_scores, key=category_scores.get)\n",
    "        return 'general'\n",
    "    \n",
    "    def classify_with_clip(self, image, labels, prefix=\"\"):\n",
    "        \"\"\"CLIP による分類\"\"\"\n",
    "        text_labels = [f\"{prefix}{label}\" for label in labels]\n",
    "        inputs = clip_processor(text=text_labels, images=image, return_tensors=\"pt\", padding=True).to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = clip_model(**inputs)\n",
    "            logits_per_image = outputs.logits_per_image\n",
    "            probs = logits_per_image.softmax(dim=1)\n",
    "            \n",
    "        max_prob_idx = probs.argmax().item()\n",
    "        confidence = probs[0][max_prob_idx].item()\n",
    "        predicted_label = labels[max_prob_idx]\n",
    "        \n",
    "        return predicted_label, confidence\n",
    "    \n",
    "    def get_specialized_approach(self, category):\n",
    "        \"\"\"カテゴリ特化アプローチを取得\"\"\"\n",
    "        specialized_prompts = {\n",
    "            'person': 'a photo of a person: ',\n",
    "            'animal': 'a photo of an animal: ',\n",
    "            'food': 'a photo of food: ',\n",
    "            'vehicle': 'a photo of a vehicle: ',\n",
    "            'building': 'a photo of architecture: ',\n",
    "            'furniture': 'a photo of furniture: ',\n",
    "            'plant': 'a photo of a plant: ',\n",
    "            'landscape': 'a photo of a landscape: '\n",
    "        }\n",
    "        return specialized_prompts.get(category, '')\n",
    "    \n",
    "    def process_image(self, image_path):\n",
    "        \"\"\"画像を処理して研究データを収集\"\"\"\n",
    "        # 画像読み込み\n",
    "        image = Image.open(image_path).convert('RGB')\n",
    "        \n",
    "        # 1. キャプション生成\n",
    "        caption = self.generate_caption(image)\n",
    "        \n",
    "        # 2. 意味カテゴリ検出\n",
    "        semantic_category = self.detect_semantic_category(caption)\n",
    "        \n",
    "        # 3. YOLO物体検出\n",
    "        yolo_results = yolo_model(image_path)\n",
    "        detected_objects = []\n",
    "        for r in yolo_results:\n",
    "            for box in r.boxes:\n",
    "                class_id = int(box.cls[0])\n",
    "                class_name = yolo_model.names[class_id]\n",
    "                confidence = float(box.conf[0])\n",
    "                detected_objects.append({'class': class_name, 'confidence': confidence})\n",
    "        \n",
    "        # 4. 分類実験\n",
    "        if semantic_category in SEMANTIC_CATEGORIES:\n",
    "            category_labels = SEMANTIC_CATEGORIES[semantic_category]\n",
    "            \n",
    "            # 汎用アプローチ\n",
    "            general_label, general_confidence = self.classify_with_clip(image, category_labels)\n",
    "            \n",
    "            # 特化アプローチ\n",
    "            specialized_prefix = self.get_specialized_approach(semantic_category)\n",
    "            specialized_label, specialized_confidence = self.classify_with_clip(\n",
    "                image, category_labels, specialized_prefix\n",
    "            )\n",
    "            \n",
    "            # 改善率計算\n",
    "            improvement_rate = (specialized_confidence - general_confidence) / general_confidence * 100\n",
    "        else:\n",
    "            general_label = general_confidence = specialized_label = specialized_confidence = None\n",
    "            improvement_rate = 0\n",
    "        \n",
    "        # 結果記録\n",
    "        result = {\n",
    "            'image_path': image_path,\n",
    "            'caption': caption,\n",
    "            'semantic_category': semantic_category,\n",
    "            'detected_objects': detected_objects,\n",
    "            'general_label': general_label,\n",
    "            'general_confidence': general_confidence,\n",
    "            'specialized_label': specialized_label,\n",
    "            'specialized_confidence': specialized_confidence,\n",
    "            'improvement_rate': improvement_rate\n",
    "        }\n",
    "        \n",
    "        self.results.append(result)\n",
    "        return result\n",
    "\n",
    "# 分類器初期化\n",
    "classifier = SemanticImageClassifier()\n",
    "print(\"✅ 画像分類システム準備完了\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 画像アップロードと処理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 画像アップロード\n",
    "if IN_COLAB:\n",
    "    from google.colab import files\n",
    "    print(\"📸 研究用画像をアップロードしてください（複数選択可能）:\")\n",
    "    uploaded = files.upload()\n",
    "    \n",
    "    uploaded_files = list(uploaded.keys())\n",
    "    print(f\"✅ {len(uploaded_files)}個の画像がアップロードされました\")\n",
    "    \n",
    "    for filename in uploaded_files:\n",
    "        print(f\"  - {filename}\")\n",
    "else:\n",
    "    # ローカル環境用のサンプル\n",
    "    uploaded_files = ['sample1.jpg', 'sample2.jpg']  # 実際のファイルパスに変更\n",
    "    print(\"ローカル環境: サンプル画像を使用\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 画像処理実行\n",
    "print(\"🔬 画像分析を開始...\")\n",
    "\n",
    "for i, filename in enumerate(uploaded_files):\n",
    "    print(f\"\\n📊 処理中 ({i+1}/{len(uploaded_files)}): {filename}\")\n",
    "    \n",
    "    try:\n",
    "        result = classifier.process_image(filename)\n",
    "        \n",
    "        # 結果表示\n",
    "        print(f\"  📝 キャプション: {result['caption']}\")\n",
    "        print(f\"  📂 意味カテゴリ: {result['semantic_category']}\")\n",
    "        print(f\"  🎯 検出物体数: {len(result['detected_objects'])}\")\n",
    "        \n",
    "        if result['general_confidence']:\n",
    "            print(f\"  📈 汎用アプローチ: {result['general_label']} ({result['general_confidence']:.3f})\")\n",
    "            print(f\"  🚀 特化アプローチ: {result['specialized_label']} ({result['specialized_confidence']:.3f})\")\n",
    "            print(f\"  📊 改善率: {result['improvement_rate']:.2f}%\")\n",
    "        \n",
    "        # 画像表示\n",
    "        img = Image.open(filename)\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        plt.imshow(img)\n",
    "        plt.title(f\"{filename}\\n{result['caption']}\")\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"  ❌ エラー: {e}\")\n",
    "\n",
    "print(f\"\\n✅ 全{len(uploaded_files)}画像の処理完了\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 研究結果の分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 結果をDataFrameに変換\n",
    "if classifier.results:\n",
    "    df = pd.DataFrame(classifier.results)\n",
    "    \n",
    "    # 基本統計\n",
    "    print(\"📊 研究結果統計:\")\n",
    "    print(f\"  - 処理画像数: {len(df)}\")\n",
    "    print(f\"  - 検出カテゴリ数: {df['semantic_category'].nunique()}\")\n",
    "    \n",
    "    # 改善率の統計\n",
    "    valid_improvements = df[df['improvement_rate'] != 0]['improvement_rate']\n",
    "    if len(valid_improvements) > 0:\n",
    "        print(f\"  - 平均改善率: {valid_improvements.mean():.2f}%\")\n",
    "        print(f\"  - 改善率標準偏差: {valid_improvements.std():.2f}%\")\n",
    "        print(f\"  - 最大改善率: {valid_improvements.max():.2f}%\")\n",
    "        print(f\"  - 最小改善率: {valid_improvements.min():.2f}%\")\n",
    "    \n",
    "    # カテゴリ別統計\n",
    "    print(\"\\n📈 カテゴリ別分析:\")\n",
    "    category_stats = df.groupby('semantic_category').agg({\n",
    "        'improvement_rate': ['count', 'mean', 'std'],\n",
    "        'general_confidence': 'mean',\n",
    "        'specialized_confidence': 'mean'\n",
    "    }).round(3)\n",
    "    \n",
    "    print(category_stats)\n",
    "    \n",
    "    # 詳細結果表示\n",
    "    print(\"\\n📋 詳細結果:\")\n",
    "    display_df = df[['image_path', 'semantic_category', 'general_confidence', \n",
    "                     'specialized_confidence', 'improvement_rate']].round(3)\n",
    "    print(display_df)\n",
    "    \n",
    "else:\n",
    "    print(\"❌ 分析する結果がありません\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 可視化グラフ作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# グラフ作成\n",
    "if classifier.results and len(classifier.results) > 1:\n",
    "    plt.style.use('default')\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "    \n",
    "    # 1. 改善率分布\n",
    "    valid_improvements = df[df['improvement_rate'] != 0]['improvement_rate']\n",
    "    if len(valid_improvements) > 0:\n",
    "        axes[0, 0].hist(valid_improvements, bins=10, alpha=0.7, color='skyblue', edgecolor='black')\n",
    "        axes[0, 0].set_title('改善率分布')\n",
    "        axes[0, 0].set_xlabel('改善率 (%)')\n",
    "        axes[0, 0].set_ylabel('頻度')\n",
    "        axes[0, 0].axvline(valid_improvements.mean(), color='red', linestyle='--', \n",
    "                          label=f'平均: {valid_improvements.mean():.1f}%')\n",
    "        axes[0, 0].legend()\n",
    "    \n",
    "    # 2. カテゴリ別改善率\n",
    "    category_improvement = df[df['improvement_rate'] != 0].groupby('semantic_category')['improvement_rate'].mean()\n",
    "    if len(category_improvement) > 0:\n",
    "        category_improvement.plot(kind='bar', ax=axes[0, 1], color='lightgreen')\n",
    "        axes[0, 1].set_title('カテゴリ別平均改善率')\n",
    "        axes[0, 1].set_xlabel('意味カテゴリ')\n",
    "        axes[0, 1].set_ylabel('平均改善率 (%)')\n",
    "        axes[0, 1].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # 3. 確信度比較\n",
    "    valid_confidences = df[(df['general_confidence'].notna()) & (df['specialized_confidence'].notna())]\n",
    "    if len(valid_confidences) > 0:\n",
    "        axes[1, 0].scatter(valid_confidences['general_confidence'], \n",
    "                          valid_confidences['specialized_confidence'], alpha=0.7)\n",
    "        axes[1, 0].plot([0, 1], [0, 1], 'r--', alpha=0.8)\n",
    "        axes[1, 0].set_title('確信度比較')\n",
    "        axes[1, 0].set_xlabel('汎用アプローチ確信度')\n",
    "        axes[1, 0].set_ylabel('特化アプローチ確信度')\n",
    "        axes[1, 0].set_xlim(0, 1)\n",
    "        axes[1, 0].set_ylim(0, 1)\n",
    "    \n",
    "    # 4. カテゴリ分布\n",
    "    category_counts = df['semantic_category'].value_counts()\n",
    "    axes[1, 1].pie(category_counts.values, labels=category_counts.index, autopct='%1.1f%%')\n",
    "    axes[1, 1].set_title('意味カテゴリ分布')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # 統計的検定\n",
    "    if len(valid_confidences) > 1:\n",
    "        t_stat, p_value = stats.ttest_rel(valid_confidences['specialized_confidence'], \n",
    "                                         valid_confidences['general_confidence'])\n",
    "        print(f\"\\n📊 統計的検定結果:\")\n",
    "        print(f\"  - t統計量: {t_stat:.4f}\")\n",
    "        print(f\"  - p値: {p_value:.4f}\")\n",
    "        print(f\"  - 有意性: {'有意 (p < 0.05)' if p_value < 0.05 else '非有意 (p >= 0.05)'}\")\n",
    "\n",
    "else:\n",
    "    print(\"❌ グラフ作成に十分なデータがありません\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. 結果のダウンロード"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 結果をファイルに保存\n",
    "if classifier.results:\n",
    "    # CSV形式で保存\n",
    "    df.to_csv('research_results.csv', index=False, encoding='utf-8')\n",
    "    \n",
    "    # JSON形式で保存\n",
    "    with open('research_results.json', 'w', encoding='utf-8') as f:\n",
    "        json.dump(classifier.results, f, ensure_ascii=False, indent=2)\n",
    "    \n",
    "    # 統計サマリー保存\n",
    "    summary = {\n",
    "        'total_images': len(df),\n",
    "        'categories_detected': df['semantic_category'].nunique(),\n",
    "        'average_improvement': valid_improvements.mean() if len(valid_improvements) > 0 else 0,\n",
    "        'improvement_std': valid_improvements.std() if len(valid_improvements) > 0 else 0,\n",
    "        'category_distribution': df['semantic_category'].value_counts().to_dict(),\n",
    "        'statistical_test': {\n",
    "            't_statistic': t_stat if 't_stat' in locals() else None,\n",
    "            'p_value': p_value if 'p_value' in locals() else None\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    with open('research_summary.json', 'w', encoding='utf-8') as f:\n",
    "        json.dump(summary, f, ensure_ascii=False, indent=2)\n",
    "    \n",
    "    print(\"✅ 結果ファイル保存完了:\")\n",
    "    print(\"  - research_results.csv\")\n",
    "    print(\"  - research_results.json\")\n",
    "    print(\"  - research_summary.json\")\n",
    "    \n",
    "    # Colabからダウンロード\n",
    "    if IN_COLAB:\n",
    "        from google.colab import files\n",
    "        files.download('research_results.csv')\n",
    "        files.download('research_results.json')\n",
    "        files.download('research_summary.json')\n",
    "        print(\"✅ ファイルダウンロード完了\")\n",
    "    \n",
    "    # Google Driveにもバックアップ\n",
    "    if IN_COLAB and os.path.exists('/content/drive/MyDrive'):\n",
    "        import shutil\n",
    "        backup_dir = '/content/drive/MyDrive/research_backup'\n",
    "        os.makedirs(backup_dir, exist_ok=True)\n",
    "        \n",
    "        shutil.copy('research_results.csv', backup_dir)\n",
    "        shutil.copy('research_results.json', backup_dir)\n",
    "        shutil.copy('research_summary.json', backup_dir)\n",
    "        print(\"✅ Google Driveバックアップ完了\")\n",
    "\n",
    "else:\n",
    "    print(\"❌ 保存する結果がありません\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. 研究結果サマリー"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 最終的な研究結果サマリー\n",
    "print(\"=\"*60)\n",
    "print(\"🎓 意味カテゴリ画像分類研究 - 最終結果\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "if classifier.results:\n",
    "    print(f\"\\n📊 実験概要:\")\n",
    "    print(f\"  - 処理画像数: {len(df)}\")\n",
    "    print(f\"  - 検出カテゴリ数: {df['semantic_category'].nunique()}\")\n",
    "    print(f\"  - 使用AI技術: BLIP, CLIP, YOLO, WordNet\")\n",
    "    \n",
    "    if len(valid_improvements) > 0:\n",
    "        print(f\"\\n🚀 特化アプローチの効果:\")\n",
    "        print(f\"  - 平均改善率: {valid_improvements.mean():.2f}%\")\n",
    "        print(f\"  - 改善を示した画像: {len(valid_improvements[valid_improvements > 0])}/{len(valid_improvements)}\")\n",
    "        print(f\"  - 最大改善率: {valid_improvements.max():.2f}%\")\n",
    "        \n",
    "        if 'p_value' in locals() and p_value < 0.05:\n",
    "            print(f\"  - 統計的有意性: 有意 (p = {p_value:.4f})\")\n",
    "            print(f\"  - 結論: 特化アプローチは統計的に有意な改善を示した\")\n",
    "        else:\n",
    "            print(f\"  - 統計的有意性: 非有意 (p = {p_value:.4f})\" if 'p_value' in locals() else \"  - 統計的検定: データ不足\")\n",
    "    \n",
    "    print(f\"\\n📈 カテゴリ別結果:\")\n",
    "    for category in df['semantic_category'].unique():\n",
    "        cat_data = df[df['semantic_category'] == category]\n",
    "        cat_improvements = cat_data[cat_data['improvement_rate'] != 0]['improvement_rate']\n",
    "        if len(cat_improvements) > 0:\n",
    "            print(f\"  - {category}: {len(cat_data)}画像, 平均改善率 {cat_improvements.mean():.2f}%\")\n",
    "        else:\n",
    "            print(f\"  - {category}: {len(cat_data)}画像, 改善率データなし\")\n",
    "    \n",
    "    print(f\"\\n📋 今後の研究方向:\")\n",
    "    print(f\"  - より大規模なデータセットでの検証\")\n",
    "    print(f\"  - 追加の意味カテゴリの探索\")\n",
    "    print(f\"  - より高度な特化アプローチの開発\")\n",
    "    print(f\"  - 実世界アプリケーションへの応用\")\n",
    "    \n",
    "else:\n",
    "    print(\"❌ 研究結果がありません。画像をアップロードして実験を実行してください。\")\n",
    "\n",
    "print(\"\\n✅ 研究実験完了！\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}