#!/usr/bin/env python3
"""
ç ”ç©¶ç‰¹åŒ–SQL ã‚·ã‚¹ãƒ†ãƒ  - ç”»åƒåˆ†é¡ç ”ç©¶ã«æœ€é©åŒ–ã•ã‚ŒãŸSQLæ©Ÿèƒ½
Geminiç›¸è«‡çµæœã‚’åŸºã«è¨­è¨ˆãƒ»å®Ÿè£…
"""

import os
import json
import sqlite3
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Any, Tuple
from gemini_to_sql_system import GeminiToSQLSystem

class ResearchSQLSystem:
    """ç ”ç©¶ç‰¹åŒ–SQLã‚·ã‚¹ãƒ†ãƒ """
    
    def __init__(self, db_path: str = "research_database.db"):
        self.db_path = db_path
        self.base_sql = GeminiToSQLSystem()
        self.conn = None
        self._init_database()
        
    def _init_database(self):
        """ç ”ç©¶ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’åˆæœŸåŒ–"""
        self.conn = sqlite3.connect(self.db_path)
        self.conn.row_factory = sqlite3.Row  # è¾æ›¸å½¢å¼ã§ã‚¢ã‚¯ã‚»ã‚¹å¯èƒ½
        
        # ç ”ç©¶ç”¨ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’ä½œæˆ
        self._create_research_tables()
        
    def _create_research_tables(self):
        """ç ”ç©¶ç”¨ãƒ†ãƒ¼ãƒ–ãƒ«ã‚¹ã‚­ãƒ¼ãƒã‚’ä½œæˆ"""
        
        cursor = self.conn.cursor()
        
        # å®Ÿé¨“ãƒ†ãƒ¼ãƒ–ãƒ«
        cursor.execute("""
        CREATE TABLE IF NOT EXISTS experiments (
            experiment_id TEXT PRIMARY KEY,
            experiment_name TEXT NOT NULL,
            description TEXT,
            created_at DATETIME DEFAULT CURRENT_TIMESTAMP,
            researcher TEXT,
            model_version TEXT,
            dataset_version TEXT,
            parameters TEXT,  -- JSONå½¢å¼ã§ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ä¿å­˜
            status TEXT DEFAULT 'running',
            completion_time DATETIME
        )
        """)
        
        # ã‚«ãƒ†ã‚´ãƒªãƒ†ãƒ¼ãƒ–ãƒ«
        cursor.execute("""
        CREATE TABLE IF NOT EXISTS categories (
            category_id INTEGER PRIMARY KEY AUTOINCREMENT,
            category_name TEXT UNIQUE NOT NULL,
            wordnet_synset TEXT,
            specialized_dataset TEXT,
            description TEXT
        )
        """)
        
        # ç”»åƒãƒ‡ãƒ¼ã‚¿ãƒ†ãƒ¼ãƒ–ãƒ«
        cursor.execute("""
        CREATE TABLE IF NOT EXISTS images (
            image_id TEXT PRIMARY KEY,
            image_path TEXT NOT NULL,
            true_category_id INTEGER,
            metadata TEXT,  -- JSONå½¢å¼ã§ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿
            created_at DATETIME DEFAULT CURRENT_TIMESTAMP,
            FOREIGN KEY (true_category_id) REFERENCES categories (category_id)
        )
        """)
        
        # äºˆæ¸¬çµæœãƒ†ãƒ¼ãƒ–ãƒ«
        cursor.execute("""
        CREATE TABLE IF NOT EXISTS predictions (
            prediction_id INTEGER PRIMARY KEY AUTOINCREMENT,
            experiment_id TEXT,
            image_id TEXT,
            predicted_category_id INTEGER,
            confidence_score REAL,
            processing_time REAL,
            prediction_timestamp DATETIME DEFAULT CURRENT_TIMESTAMP,
            model_output TEXT,  -- JSONå½¢å¼ã§è©³ç´°ãªå‡ºåŠ›
            FOREIGN KEY (experiment_id) REFERENCES experiments (experiment_id),
            FOREIGN KEY (image_id) REFERENCES images (image_id),
            FOREIGN KEY (predicted_category_id) REFERENCES categories (category_id)
        )
        """)
        
        # çµ±è¨ˆçµæœãƒ†ãƒ¼ãƒ–ãƒ«
        cursor.execute("""
        CREATE TABLE IF NOT EXISTS experiment_statistics (
            stat_id INTEGER PRIMARY KEY AUTOINCREMENT,
            experiment_id TEXT,
            metric_name TEXT,
            metric_value REAL,
            category_id INTEGER,  -- ã‚«ãƒ†ã‚´ãƒªåˆ¥çµ±è¨ˆã®å ´åˆ
            calculated_at DATETIME DEFAULT CURRENT_TIMESTAMP,
            calculation_details TEXT,  -- JSONå½¢å¼ã§è¨ˆç®—è©³ç´°
            FOREIGN KEY (experiment_id) REFERENCES experiments (experiment_id),
            FOREIGN KEY (category_id) REFERENCES categories (category_id)
        )
        """)
        
        # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ç›£è¦–ãƒ†ãƒ¼ãƒ–ãƒ«
        cursor.execute("""
        CREATE TABLE IF NOT EXISTS performance_metrics (
            metric_id INTEGER PRIMARY KEY AUTOINCREMENT,
            experiment_id TEXT,
            timestamp DATETIME DEFAULT CURRENT_TIMESTAMP,
            accuracy REAL,
            precision_macro REAL,
            recall_macro REAL,
            f1_score_macro REAL,
            processing_speed REAL,  -- images per second
            memory_usage REAL,  -- MB
            FOREIGN KEY (experiment_id) REFERENCES experiments (experiment_id)
        )
        """)
        
        # æ¯”è¼ƒåˆ†æãƒ†ãƒ¼ãƒ–ãƒ«
        cursor.execute("""
        CREATE TABLE IF NOT EXISTS experiment_comparisons (
            comparison_id INTEGER PRIMARY KEY AUTOINCREMENT,
            comparison_name TEXT,
            experiment_ids TEXT,  -- JSONé…åˆ—
            comparison_metrics TEXT,  -- JSONå½¢å¼
            statistical_significance TEXT,  -- JSONå½¢å¼
            created_at DATETIME DEFAULT CURRENT_TIMESTAMP,
            researcher_notes TEXT
        )
        """)
        
        self.conn.commit()
        
        # åˆæœŸã‚«ãƒ†ã‚´ãƒªãƒ‡ãƒ¼ã‚¿ã‚’æŒ¿å…¥
        self._insert_default_categories()
        
    def _insert_default_categories(self):
        """ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã‚«ãƒ†ã‚´ãƒªã‚’æŒ¿å…¥"""
        
        categories = [
            ('Person', 'person.n.01', 'LFW', 'äººç‰©ãƒ»é¡”èªè­˜ç‰¹åŒ–'),
            ('Animal', 'animal.n.01', 'ImageNet', 'å‹•ç‰©åˆ†é¡ãƒ»è¡Œå‹•èªè­˜ç‰¹åŒ–'),
            ('Food', 'food.n.01', 'Food-101', 'æ–™ç†ãƒ»é£Ÿæèªè­˜ç‰¹åŒ–'),
            ('Landscape', 'landscape.n.01', 'Places365', 'ã‚·ãƒ¼ãƒ³ãƒ»ç’°å¢ƒèªè­˜ç‰¹åŒ–'),
            ('Building', 'building.n.01', 'OpenBuildings', 'å»ºç¯‰ç‰©ãƒ»æ§‹é€ ç‰©èªè­˜ç‰¹åŒ–'),
            ('Furniture', 'furniture.n.01', 'Objects365', 'å®¶å…·ãƒ»æ—¥ç”¨å“èªè­˜ç‰¹åŒ–'),
            ('Vehicle', 'vehicle.n.01', 'Pascal VOC', 'è»Šä¸¡ãƒ»äº¤é€šæ‰‹æ®µèªè­˜ç‰¹åŒ–'),
            ('Plant', 'plant.n.01', 'PlantVillage', 'æ¤ç‰©ãƒ»è¾²ä½œç‰©èªè­˜ç‰¹åŒ–')
        ]
        
        cursor = self.conn.cursor()
        
        for cat_name, synset, dataset, desc in categories:
            cursor.execute("""
            INSERT OR IGNORE INTO categories 
            (category_name, wordnet_synset, specialized_dataset, description)
            VALUES (?, ?, ?, ?)
            """, (cat_name, synset, dataset, desc))
        
        self.conn.commit()
    
    def generate_research_query(self, natural_request: str) -> Dict[str, Any]:
        """ç ”ç©¶å‘ã‘ã®è‡ªç„¶è¨€èªã‹ã‚‰SQLç”Ÿæˆ"""
        
        # ç ”ç©¶ç‰¹åŒ–ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’è¿½åŠ 
        research_context = {
            "experiments": {
                "columns": {
                    "experiment_id": "TEXT PRIMARY KEY",
                    "experiment_name": "TEXT",
                    "researcher": "TEXT",
                    "model_version": "TEXT",
                    "accuracy": "REAL via experiment_statistics",
                    "created_at": "DATETIME"
                }
            },
            "predictions": {
                "columns": {
                    "prediction_id": "INTEGER PRIMARY KEY",
                    "experiment_id": "TEXT",
                    "image_id": "TEXT",
                    "predicted_category_id": "INTEGER",
                    "confidence_score": "REAL",
                    "processing_time": "REAL"
                }
            },
            "categories": {
                "columns": {
                    "category_id": "INTEGER PRIMARY KEY",
                    "category_name": "TEXT",
                    "specialized_dataset": "TEXT"
                }
            }
        }
        
        # ç ”ç©¶ç‰¹åŒ–ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’è¿½åŠ 
        enhanced_request = f"""
        ç ”ç©¶ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ç”¨ã®SQLæ–‡ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚
        
        ç ”ç©¶ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ:
        - ç”»åƒåˆ†é¡ç ”ç©¶ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ
        - 8ã¤ã®å°‚é–€ã‚«ãƒ†ã‚´ãƒªï¼ˆPerson, Animal, Food, etc.ï¼‰
        - å®Ÿé¨“çµæœã®ç®¡ç†ã¨åˆ†æ
        - çµ±è¨ˆçš„æ¤œå®šã¨ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹è©•ä¾¡
        
        ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒªã‚¯ã‚¨ã‚¹ãƒˆ: {natural_request}
        
        åˆ©ç”¨å¯èƒ½ãªãƒ†ãƒ¼ãƒ–ãƒ«:
        - experiments: å®Ÿé¨“ç®¡ç†
        - predictions: äºˆæ¸¬çµæœ
        - categories: ã‚«ãƒ†ã‚´ãƒªç®¡ç†
        - experiment_statistics: çµ±è¨ˆçµæœ
        - performance_metrics: ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æŒ‡æ¨™
        - experiment_comparisons: å®Ÿé¨“æ¯”è¼ƒ
        
        ç ”ç©¶åˆ†æã«é©ã—ãŸSQLæ–‡ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚
        """
        
        return self.base_sql.generate_sql(enhanced_request, research_context)
    
    def insert_experiment_data(self, experiment_data: Dict) -> str:
        """å®Ÿé¨“ãƒ‡ãƒ¼ã‚¿ã‚’æŒ¿å…¥"""
        
        cursor = self.conn.cursor()
        
        experiment_id = experiment_data.get('experiment_id', 
                                          f"exp_{datetime.now().strftime('%Y%m%d_%H%M%S')}")
        
        cursor.execute("""
        INSERT INTO experiments 
        (experiment_id, experiment_name, description, researcher, 
         model_version, dataset_version, parameters)
        VALUES (?, ?, ?, ?, ?, ?, ?)
        """, (
            experiment_id,
            experiment_data.get('experiment_name', ''),
            experiment_data.get('description', ''),
            experiment_data.get('researcher', ''),
            experiment_data.get('model_version', ''),
            experiment_data.get('dataset_version', ''),
            json.dumps(experiment_data.get('parameters', {}))
        ))
        
        self.conn.commit()
        return experiment_id
    
    def insert_prediction_batch(self, experiment_id: str, predictions: List[Dict]) -> int:
        """äºˆæ¸¬çµæœã‚’ãƒãƒƒãƒæŒ¿å…¥"""
        
        cursor = self.conn.cursor()
        
        prediction_data = []
        for pred in predictions:
            prediction_data.append((
                experiment_id,
                pred['image_id'],
                pred['predicted_category_id'],
                pred['confidence_score'],
                pred.get('processing_time', 0.0),
                json.dumps(pred.get('model_output', {}))
            ))
        
        cursor.executemany("""
        INSERT INTO predictions 
        (experiment_id, image_id, predicted_category_id, 
         confidence_score, processing_time, model_output)
        VALUES (?, ?, ?, ?, ?, ?)
        """, prediction_data)
        
        self.conn.commit()
        return len(predictions)
    
    def calculate_experiment_statistics(self, experiment_id: str) -> Dict[str, Any]:
        """å®Ÿé¨“çµ±è¨ˆã‚’è¨ˆç®—ã—ã¦DBã«ä¿å­˜"""
        
        cursor = self.conn.cursor()
        
        # åŸºæœ¬çµ±è¨ˆã‚’è¨ˆç®—
        cursor.execute("""
        SELECT 
            COUNT(*) as total_predictions,
            AVG(confidence_score) as avg_confidence,
            COUNT(CASE WHEN p.predicted_category_id = i.true_category_id THEN 1 END) as correct_predictions
        FROM predictions p
        JOIN images i ON p.image_id = i.image_id
        WHERE p.experiment_id = ?
        """, (experiment_id,))
        
        stats = cursor.fetchone()
        
        if stats and stats['total_predictions'] > 0:
            accuracy = stats['correct_predictions'] / stats['total_predictions']
            
            # çµ±è¨ˆã‚’DBã«ä¿å­˜
            statistics = [
                ('accuracy', accuracy),
                ('avg_confidence', stats['avg_confidence']),
                ('total_predictions', stats['total_predictions']),
                ('correct_predictions', stats['correct_predictions'])
            ]
            
            for metric_name, value in statistics:
                cursor.execute("""
                INSERT INTO experiment_statistics 
                (experiment_id, metric_name, metric_value)
                VALUES (?, ?, ?)
                """, (experiment_id, metric_name, float(value)))
            
            self.conn.commit()
            
            return {
                'experiment_id': experiment_id,
                'accuracy': accuracy,
                'avg_confidence': stats['avg_confidence'],
                'total_predictions': stats['total_predictions'],
                'correct_predictions': stats['correct_predictions']
            }
        
        return {}
    
    def generate_research_report(self, experiment_id: str) -> str:
        """ç ”ç©¶ãƒ¬ãƒãƒ¼ãƒˆã‚’è‡ªå‹•ç”Ÿæˆ"""
        
        # å®Ÿé¨“ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
        cursor = self.conn.cursor()
        
        cursor.execute("""
        SELECT e.*, 
               es.metric_value as accuracy
        FROM experiments e
        LEFT JOIN experiment_statistics es ON e.experiment_id = es.experiment_id 
                                           AND es.metric_name = 'accuracy'
        WHERE e.experiment_id = ?
        """, (experiment_id,))
        
        experiment = cursor.fetchone()
        
        if not experiment:
            return "å®Ÿé¨“ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚"
        
        # ã‚«ãƒ†ã‚´ãƒªåˆ¥æ€§èƒ½ã‚’å–å¾—
        cursor.execute("""
        SELECT 
            c.category_name,
            COUNT(*) as total,
            COUNT(CASE WHEN p.predicted_category_id = i.true_category_id THEN 1 END) as correct,
            AVG(p.confidence_score) as avg_confidence
        FROM predictions p
        JOIN images i ON p.image_id = i.image_id
        JOIN categories c ON i.true_category_id = c.category_id
        WHERE p.experiment_id = ?
        GROUP BY c.category_id, c.category_name
        ORDER BY c.category_name
        """, (experiment_id,))
        
        category_stats = cursor.fetchall()
        
        # ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
        report = f"""
# å®Ÿé¨“ãƒ¬ãƒãƒ¼ãƒˆ: {experiment['experiment_name']}

## å®Ÿé¨“æ¦‚è¦
- **å®Ÿé¨“ID**: {experiment['experiment_id']}
- **ç ”ç©¶è€…**: {experiment['researcher']}
- **ãƒ¢ãƒ‡ãƒ«ãƒãƒ¼ã‚¸ãƒ§ãƒ³**: {experiment['model_version']}
- **å®Ÿæ–½æ—¥æ™‚**: {experiment['created_at']}
- **èª¬æ˜**: {experiment['description']}

## å…¨ä½“çš„ãªæ€§èƒ½
- **åˆ†é¡ç²¾åº¦**: {experiment['accuracy']:.4f} ({experiment['accuracy']*100:.2f}%)

## ã‚«ãƒ†ã‚´ãƒªåˆ¥æ€§èƒ½

| ã‚«ãƒ†ã‚´ãƒª | ç·æ•° | æ­£è§£æ•° | ç²¾åº¦ | å¹³å‡ç¢ºä¿¡åº¦ |
|---------|-----|-------|------|----------|
"""
        
        for cat in category_stats:
            accuracy = cat['correct'] / cat['total'] if cat['total'] > 0 else 0
            report += f"| {cat['category_name']} | {cat['total']} | {cat['correct']} | {accuracy:.4f} | {cat['avg_confidence']:.4f} |\n"
        
        report += f"""
## çµ±è¨ˆçš„åˆ†æ

ç”Ÿæˆæ—¥æ™‚: {datetime.now().isoformat()}
"""
        
        return report
    
    def compare_experiments(self, experiment_ids: List[str], 
                          comparison_name: str = "") -> Dict[str, Any]:
        """å®Ÿé¨“é–“ã®æ¯”è¼ƒåˆ†æ"""
        
        cursor = self.conn.cursor()
        
        comparison_results = {}
        
        for exp_id in experiment_ids:
            cursor.execute("""
            SELECT 
                e.experiment_name,
                es_acc.metric_value as accuracy,
                es_conf.metric_value as avg_confidence,
                es_total.metric_value as total_predictions
            FROM experiments e
            LEFT JOIN experiment_statistics es_acc ON e.experiment_id = es_acc.experiment_id 
                                                   AND es_acc.metric_name = 'accuracy'
            LEFT JOIN experiment_statistics es_conf ON e.experiment_id = es_conf.experiment_id 
                                                    AND es_conf.metric_name = 'avg_confidence'
            LEFT JOIN experiment_statistics es_total ON e.experiment_id = es_total.experiment_id 
                                                     AND es_total.metric_name = 'total_predictions'
            WHERE e.experiment_id = ?
            """, (exp_id,))
            
            result = cursor.fetchone()
            if result:
                comparison_results[exp_id] = {
                    'name': result['experiment_name'],
                    'accuracy': result['accuracy'] or 0,
                    'avg_confidence': result['avg_confidence'] or 0,
                    'total_predictions': result['total_predictions'] or 0
                }
        
        # æ¯”è¼ƒçµæœã‚’DBã«ä¿å­˜
        comparison_data = {
            'comparison_name': comparison_name or f"Comparison_{datetime.now().strftime('%Y%m%d_%H%M%S')}",
            'experiment_ids': experiment_ids,
            'results': comparison_results,
            'best_accuracy': max([r['accuracy'] for r in comparison_results.values()]),
            'worst_accuracy': min([r['accuracy'] for r in comparison_results.values()])
        }
        
        cursor.execute("""
        INSERT INTO experiment_comparisons 
        (comparison_name, experiment_ids, comparison_metrics)
        VALUES (?, ?, ?)
        """, (
            comparison_data['comparison_name'],
            json.dumps(experiment_ids),
            json.dumps(comparison_data)
        ))
        
        self.conn.commit()
        
        return comparison_data
    
    def export_experiment_data(self, experiment_id: str, format: str = 'json') -> str:
        """å®Ÿé¨“ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ"""
        
        cursor = self.conn.cursor()
        
        # å®Ÿé¨“ã®å…¨ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
        cursor.execute("""
        SELECT 
            e.*,
            GROUP_CONCAT(es.metric_name || ':' || es.metric_value) as statistics
        FROM experiments e
        LEFT JOIN experiment_statistics es ON e.experiment_id = es.experiment_id
        WHERE e.experiment_id = ?
        GROUP BY e.experiment_id
        """, (experiment_id,))
        
        experiment_data = cursor.fetchone()
        
        if not experiment_data:
            return "å®Ÿé¨“ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚"
        
        # äºˆæ¸¬ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
        cursor.execute("""
        SELECT p.*, i.image_path, c.category_name as predicted_category
        FROM predictions p
        JOIN images i ON p.image_id = i.image_id
        JOIN categories c ON p.predicted_category_id = c.category_id
        WHERE p.experiment_id = ?
        ORDER BY p.prediction_timestamp
        """, (experiment_id,))
        
        predictions = cursor.fetchall()
        
        export_data = {
            'experiment': dict(experiment_data),
            'predictions': [dict(row) for row in predictions],
            'export_timestamp': datetime.now().isoformat()
        }
        
        if format.lower() == 'json':
            filename = f"experiment_{experiment_id}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
            with open(filename, 'w', encoding='utf-8') as f:
                json.dump(export_data, f, ensure_ascii=False, indent=2)
            return filename
        
        return json.dumps(export_data, ensure_ascii=False, indent=2)
    
    def close(self):
        """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šã‚’é–‰ã˜ã‚‹"""
        if self.conn:
            self.conn.close()


def demo_research_sql():
    """ç ”ç©¶SQLæ©Ÿèƒ½ã®ãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³"""
    
    print("ğŸ”¬ ç ”ç©¶ç‰¹åŒ–SQL ã‚·ã‚¹ãƒ†ãƒ  ãƒ‡ãƒ¢")
    print("=" * 60)
    
    # ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–
    research_sql = ResearchSQLSystem("demo_research.db")
    
    # 1. ã‚µãƒ³ãƒ—ãƒ«å®Ÿé¨“ãƒ‡ãƒ¼ã‚¿ã‚’æŒ¿å…¥
    print("\nğŸ“ ã‚µãƒ³ãƒ—ãƒ«å®Ÿé¨“ãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆä¸­...")
    
    experiment_data = {
        'experiment_name': 'WordNetç‰¹åŒ–åˆ†é¡å®Ÿé¨“v1.0',
        'description': '8ã‚«ãƒ†ã‚´ãƒªç‰¹åŒ–ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ä½¿ç”¨ã—ãŸåˆ†é¡æ€§èƒ½è©•ä¾¡',
        'researcher': 'Research Team',
        'model_version': 'CLIP-ViT-B/32',
        'dataset_version': 'Multi-Dataset-v1.0',
        'parameters': {
            'batch_size': 32,
            'learning_rate': 0.001,
            'epochs': 50
        }
    }
    
    exp_id = research_sql.insert_experiment_data(experiment_data)
    print(f"âœ… å®Ÿé¨“ID: {exp_id}")
    
    # 2. ã‚µãƒ³ãƒ—ãƒ«äºˆæ¸¬çµæœã‚’æŒ¿å…¥
    print("\nğŸ“Š ã‚µãƒ³ãƒ—ãƒ«äºˆæ¸¬çµæœã‚’æŒ¿å…¥ä¸­...")
    
    sample_predictions = [
        {'image_id': 'img_001', 'predicted_category_id': 1, 'confidence_score': 0.95, 'processing_time': 0.12},
        {'image_id': 'img_002', 'predicted_category_id': 2, 'confidence_score': 0.88, 'processing_time': 0.11},
        {'image_id': 'img_003', 'predicted_category_id': 1, 'confidence_score': 0.76, 'processing_time': 0.13},
        {'image_id': 'img_004', 'predicted_category_id': 3, 'confidence_score': 0.92, 'processing_time': 0.10},
        {'image_id': 'img_005', 'predicted_category_id': 2, 'confidence_score': 0.84, 'processing_time': 0.14},
    ]
    
    # ã‚µãƒ³ãƒ—ãƒ«ç”»åƒãƒ‡ãƒ¼ã‚¿ã‚‚æŒ¿å…¥
    cursor = research_sql.conn.cursor()
    for i, pred in enumerate(sample_predictions, 1):
        cursor.execute("""
        INSERT OR IGNORE INTO images (image_id, image_path, true_category_id)
        VALUES (?, ?, ?)
        """, (pred['image_id'], f"/data/images/{pred['image_id']}.jpg", pred['predicted_category_id']))
    
    research_sql.conn.commit()
    
    inserted = research_sql.insert_prediction_batch(exp_id, sample_predictions)
    print(f"âœ… {inserted}ä»¶ã®äºˆæ¸¬çµæœã‚’æŒ¿å…¥")
    
    # 3. çµ±è¨ˆè¨ˆç®—
    print("\nğŸ“ˆ å®Ÿé¨“çµ±è¨ˆã‚’è¨ˆç®—ä¸­...")
    stats = research_sql.calculate_experiment_statistics(exp_id)
    print(f"âœ… åˆ†é¡ç²¾åº¦: {stats.get('accuracy', 0):.4f}")
    
    # 4. è‡ªç„¶è¨€èªã‹ã‚‰SQLç”Ÿæˆã®ãƒ†ã‚¹ãƒˆ
    print("\nğŸ¤– è‡ªç„¶è¨€èªSQLç”Ÿæˆãƒ†ã‚¹ãƒˆ:")
    
    test_queries = [
        "ã“ã®å®Ÿé¨“ã®åˆ†é¡ç²¾åº¦ã‚’å–å¾—",
        "ã‚«ãƒ†ã‚´ãƒªåˆ¥ã®æ€§èƒ½ã‚’åˆ†æ",
        "å‡¦ç†æ™‚é–“ã®çµ±è¨ˆã‚’è¨ˆç®—",
        "ç¢ºä¿¡åº¦ãŒ0.9ä»¥ä¸Šã®äºˆæ¸¬ã‚’å–å¾—"
    ]
    
    for query in test_queries:
        print(f"\nè³ªå•: {query}")
        result = research_sql.generate_research_query(query)
        if result.get('sql'):
            print(f"SQL: {result['sql'][:100]}...")
    
    # 5. ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
    print("\nğŸ“„ å®Ÿé¨“ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆä¸­...")
    report = research_sql.generate_research_report(exp_id)
    print(report[:500] + "...")
    
    # 6. ãƒ‡ãƒ¼ã‚¿ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ
    print("\nğŸ’¾ å®Ÿé¨“ãƒ‡ãƒ¼ã‚¿ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆä¸­...")
    exported_file = research_sql.export_experiment_data(exp_id)
    print(f"âœ… ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆå®Œäº†: {exported_file}")
    
    # ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
    research_sql.close()
    
    print("\nğŸ‰ ç ”ç©¶SQLæ©Ÿèƒ½ãƒ‡ãƒ¢å®Œäº†ï¼")


if __name__ == "__main__":
    demo_research_sql()