#!/usr/bin/env python3
"""
è‡ªå‹•ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚·ã‚¹ãƒ†ãƒ  - é‡è¦ãƒ•ã‚¡ã‚¤ãƒ«ã®è‡ªå‹•ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—
"""

import os
import sys
import json
import shutil
import zipfile
from pathlib import Path
from datetime import datetime, timedelta
from typing import List, Dict

class AutoBackupSystem:
    """è‡ªå‹•ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚·ã‚¹ãƒ†ãƒ """
    
    def __init__(self):
        self.project_root = Path.cwd()
        self.backup_root = self.project_root / "backups"
        self.config_file = self.project_root / "AUTO_BACKUP_CONFIG.json"
        self.log_file = self.project_root / "AUTO_BACKUP_LOG.json"
        self.config = self.load_config()
        
    def load_config(self) -> Dict:
        """è¨­å®šã‚’èª­ã¿è¾¼ã¿"""
        default_config = {
            "backup_files": [
                "public/index.html",
                "vercel.json",
                "*.py",
                "*.md",
                "*.json",
                "*.sh"
            ],
            "exclude_patterns": [
                "__pycache__",
                ".git",
                "node_modules",
                "*.log",
                "backups"
            ],
            "retention_days": 7,
            "max_backups": 50,
            "compress": True,
            "auto_cleanup": True
        }
        
        if self.config_file.exists():
            try:
                with open(self.config_file, 'r', encoding='utf-8') as f:
                    saved_config = json.load(f)
                    default_config.update(saved_config)
            except:
                pass
        
        return default_config
    
    def save_config(self):
        """è¨­å®šã‚’ä¿å­˜"""
        with open(self.config_file, 'w', encoding='utf-8') as f:
            json.dump(self.config, f, indent=2, ensure_ascii=False)
    
    def log_event(self, event_type: str, message: str, status: str = "info"):
        """ã‚¤ãƒ™ãƒ³ãƒˆã‚’ãƒ­ã‚°ã«è¨˜éŒ²"""
        log_entry = {
            "timestamp": datetime.now().isoformat(),
            "event_type": event_type,
            "message": message,
            "status": status
        }
        
        logs = []
        if self.log_file.exists():
            try:
                with open(self.log_file, 'r', encoding='utf-8') as f:
                    logs = json.load(f)
            except:
                pass
        
        logs.append(log_entry)
        logs = logs[-200:]  # æœ€æ–°200ä»¶ã®ã¿ä¿æŒ
        
        with open(self.log_file, 'w', encoding='utf-8') as f:
            json.dump(logs, f, indent=2, ensure_ascii=False)
        
        print(f"[{datetime.now().strftime('%H:%M:%S')}] {event_type}: {message}")
    
    def get_files_to_backup(self) -> List[Path]:
        """ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—å¯¾è±¡ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å–å¾—"""
        files_to_backup = []
        
        for pattern in self.config['backup_files']:
            if '*' in pattern:
                # globãƒ‘ã‚¿ãƒ¼ãƒ³
                files = list(self.project_root.glob(pattern))
                if '**' not in pattern:
                    files.extend(list(self.project_root.glob(f"**/{pattern}")))
            else:
                # å˜ä¸€ãƒ•ã‚¡ã‚¤ãƒ«
                file_path = self.project_root / pattern
                if file_path.exists():
                    files = [file_path]
                else:
                    files = []
            
            for file_path in files:
                if self.should_include_file(file_path):
                    files_to_backup.append(file_path)
        
        return list(set(files_to_backup))  # é‡è¤‡ã‚’é™¤å»
    
    def should_include_file(self, file_path: Path) -> bool:
        """ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å«ã‚ã‚‹ã‹ãƒã‚§ãƒƒã‚¯"""
        # é™¤å¤–ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’ãƒã‚§ãƒƒã‚¯
        for exclude in self.config['exclude_patterns']:
            if exclude in str(file_path):
                return False
        
        # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã¯é™¤å¤–
        if file_path.is_dir():
            return False
        
        return True
    
    def create_backup(self) -> bool:
        """ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚’ä½œæˆ"""
        try:
            # ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆ
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            backup_dir = self.backup_root / timestamp
            backup_dir.mkdir(parents=True, exist_ok=True)
            
            self.log_event("BACKUP", f"ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—é–‹å§‹: {backup_dir}", "info")
            
            # ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—å¯¾è±¡ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å–å¾—
            files_to_backup = self.get_files_to_backup()
            
            if not files_to_backup:
                self.log_event("BACKUP", "ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—å¯¾è±¡ãƒ•ã‚¡ã‚¤ãƒ«ãªã—", "warning")
                return False
            
            # ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚³ãƒ”ãƒ¼
            copied_files = []
            for file_path in files_to_backup:
                try:
                    # ç›¸å¯¾ãƒ‘ã‚¹ã‚’ä¿æŒã—ã¦ã‚³ãƒ”ãƒ¼
                    rel_path = file_path.relative_to(self.project_root)
                    dest_path = backup_dir / rel_path
                    dest_path.parent.mkdir(parents=True, exist_ok=True)
                    
                    shutil.copy2(file_path, dest_path)
                    copied_files.append(str(rel_path))
                    
                except Exception as e:
                    self.log_event("BACKUP", f"ãƒ•ã‚¡ã‚¤ãƒ«ã‚³ãƒ”ãƒ¼ã‚¨ãƒ©ãƒ¼ {file_path}: {e}", "error")
            
            # åœ§ç¸®ï¼ˆè¨­å®šã•ã‚Œã¦ã„ã‚‹å ´åˆï¼‰
            if self.config['compress']:
                zip_path = backup_dir.with_suffix('.zip')
                with zipfile.ZipFile(zip_path, 'w', zipfile.ZIP_DEFLATED) as zipf:
                    for file_path in copied_files:
                        source_path = backup_dir / file_path
                        if source_path.exists():
                            zipf.write(source_path, file_path)
                
                # å…ƒã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’å‰Šé™¤
                shutil.rmtree(backup_dir)
                backup_path = zip_path
            else:
                backup_path = backup_dir
            
            # ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—æƒ…å ±ã‚’è¨˜éŒ²
            backup_info = {
                "timestamp": timestamp,
                "path": str(backup_path),
                "files_count": len(copied_files),
                "files": copied_files,
                "compressed": self.config['compress']
            }
            
            info_file = backup_path.parent / f"{timestamp}_info.json"
            with open(info_file, 'w', encoding='utf-8') as f:
                json.dump(backup_info, f, indent=2, ensure_ascii=False)
            
            self.log_event("BACKUP", f"å®Œäº†: {len(copied_files)}ãƒ•ã‚¡ã‚¤ãƒ« -> {backup_path}", "success")
            return True
            
        except Exception as e:
            self.log_event("BACKUP", f"ã‚¨ãƒ©ãƒ¼: {e}", "error")
            return False
    
    def cleanup_old_backups(self):
        """å¤ã„ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚’å‰Šé™¤"""
        if not self.config['auto_cleanup']:
            return
        
        try:
            self.log_event("CLEANUP", "å¤ã„ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã®å‰Šé™¤é–‹å§‹", "info")
            
            # ä¿æŒæœŸé–“ã‚’è¨ˆç®—
            cutoff_date = datetime.now() - timedelta(days=self.config['retention_days'])
            
            # ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ•ã‚¡ã‚¤ãƒ«/ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’å–å¾—
            backup_items = []
            if self.backup_root.exists():
                for item in self.backup_root.iterdir():
                    if item.is_file() and item.suffix == '.zip':
                        backup_items.append(item)
                    elif item.is_dir():
                        backup_items.append(item)
            
            # æ—¥ä»˜ã§ã‚½ãƒ¼ãƒˆ
            backup_items.sort(key=lambda x: x.stat().st_mtime, reverse=True)
            
            # å¤ã„ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚’å‰Šé™¤
            deleted_count = 0
            for i, item in enumerate(backup_items):
                item_date = datetime.fromtimestamp(item.stat().st_mtime)
                
                # ä¿æŒæœŸé–“ã‚’è¶…ãˆã¦ã„ã‚‹ã€ã¾ãŸã¯æœ€å¤§æ•°ã‚’è¶…ãˆã¦ã„ã‚‹
                if (item_date < cutoff_date or i >= self.config['max_backups']):
                    try:
                        if item.is_file():
                            item.unlink()
                            # å¯¾å¿œã™ã‚‹infoãƒ•ã‚¡ã‚¤ãƒ«ã‚‚å‰Šé™¤
                            info_file = item.with_name(f"{item.stem}_info.json")
                            if info_file.exists():
                                info_file.unlink()
                        else:
                            shutil.rmtree(item)
                        
                        deleted_count += 1
                        self.log_event("CLEANUP", f"å‰Šé™¤: {item.name}", "info")
                        
                    except Exception as e:
                        self.log_event("CLEANUP", f"å‰Šé™¤ã‚¨ãƒ©ãƒ¼ {item.name}: {e}", "error")
            
            if deleted_count > 0:
                self.log_event("CLEANUP", f"{deleted_count}å€‹ã®ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚’å‰Šé™¤", "success")
            else:
                self.log_event("CLEANUP", "å‰Šé™¤å¯¾è±¡ãªã—", "info")
                
        except Exception as e:
            self.log_event("CLEANUP", f"ã‚¨ãƒ©ãƒ¼: {e}", "error")
    
    def list_backups(self):
        """ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ä¸€è¦§ã‚’è¡¨ç¤º"""
        if not self.backup_root.exists():
            print("ğŸ“ ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            return
        
        print("ğŸ“ ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ä¸€è¦§:")
        print("-" * 60)
        
        backup_items = []
        for item in self.backup_root.iterdir():
            if item.is_file() and item.suffix == '.zip':
                backup_items.append(item)
            elif item.is_dir():
                backup_items.append(item)
        
        backup_items.sort(key=lambda x: x.stat().st_mtime, reverse=True)
        
        for item in backup_items:
            mtime = datetime.fromtimestamp(item.stat().st_mtime)
            if item.is_file():
                size = f"{item.stat().st_size / 1024:.1f}KB"
                type_icon = "ğŸ“¦"
            else:
                size = f"{sum(f.stat().st_size for f in item.rglob('*') if f.is_file()) / 1024:.1f}KB"
                type_icon = "ğŸ“"
            
            print(f"{type_icon} {item.name}")
            print(f"   ğŸ“… {mtime.strftime('%Y-%m-%d %H:%M:%S')}")
            print(f"   ğŸ“Š {size}")
            
            # info.jsonãŒã‚ã‚Œã°å†…å®¹è¡¨ç¤º
            info_file = item.parent / f"{item.stem}_info.json"
            if info_file.exists():
                try:
                    with open(info_file, 'r', encoding='utf-8') as f:
                        info = json.load(f)
                        print(f"   ğŸ“ {info['files_count']}ãƒ•ã‚¡ã‚¤ãƒ«")
                except:
                    pass
            
            print()
    
    def restore_backup(self, backup_name: str):
        """ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‹ã‚‰å¾©å…ƒ"""
        backup_path = self.backup_root / backup_name
        
        if not backup_path.exists():
            self.log_event("RESTORE", f"ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {backup_name}", "error")
            return False
        
        try:
            self.log_event("RESTORE", f"å¾©å…ƒé–‹å§‹: {backup_name}", "info")
            
            if backup_path.suffix == '.zip':
                # ZIPãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰å¾©å…ƒ
                with zipfile.ZipFile(backup_path, 'r') as zipf:
                    zipf.extractall(self.project_root)
            else:
                # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‹ã‚‰å¾©å…ƒ
                for item in backup_path.rglob('*'):
                    if item.is_file():
                        rel_path = item.relative_to(backup_path)
                        dest_path = self.project_root / rel_path
                        dest_path.parent.mkdir(parents=True, exist_ok=True)
                        shutil.copy2(item, dest_path)
            
            self.log_event("RESTORE", f"å¾©å…ƒå®Œäº†: {backup_name}", "success")
            return True
            
        except Exception as e:
            self.log_event("RESTORE", f"å¾©å…ƒã‚¨ãƒ©ãƒ¼: {e}", "error")
            return False
    
    def run_backup_cycle(self):
        """ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚µã‚¤ã‚¯ãƒ«ã‚’å®Ÿè¡Œ"""
        print("ğŸ”„ è‡ªå‹•ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚µã‚¤ã‚¯ãƒ«é–‹å§‹")
        
        # ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ä½œæˆ
        success = self.create_backup()
        
        # å¤ã„ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—å‰Šé™¤
        if success:
            self.cleanup_old_backups()
        
        return success

def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    backup_system = AutoBackupSystem()
    
    if len(sys.argv) > 1:
        command = sys.argv[1].lower()
        
        if command == "run":
            backup_system.run_backup_cycle()
        elif command == "create":
            backup_system.create_backup()
        elif command == "list":
            backup_system.list_backups()
        elif command == "cleanup":
            backup_system.cleanup_old_backups()
        elif command == "restore" and len(sys.argv) > 2:
            backup_name = sys.argv[2]
            backup_system.restore_backup(backup_name)
        elif command == "config":
            print(json.dumps(backup_system.config, indent=2, ensure_ascii=False))
        elif command == "log":
            if backup_system.log_file.exists():
                with open(backup_system.log_file, 'r', encoding='utf-8') as f:
                    logs = json.load(f)
                    for log in logs[-20:]:  # æœ€æ–°20ä»¶
                        print(f"[{log['timestamp']}] {log['event_type']}: {log['message']}")
            else:
                print("ğŸ“ ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        else:
            print("ä½¿ç”¨æ–¹æ³•:")
            print("  python3 auto_backup_system.py run                 - ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚µã‚¤ã‚¯ãƒ«å®Ÿè¡Œ")
            print("  python3 auto_backup_system.py create              - ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ä½œæˆ")
            print("  python3 auto_backup_system.py list                - ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ä¸€è¦§")
            print("  python3 auto_backup_system.py cleanup             - å¤ã„ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—å‰Šé™¤")
            print("  python3 auto_backup_system.py restore <name>      - ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‹ã‚‰å¾©å…ƒ")
            print("  python3 auto_backup_system.py config              - è¨­å®šè¡¨ç¤º")
            print("  python3 auto_backup_system.py log                 - ãƒ­ã‚°è¡¨ç¤º")
    else:
        backup_system.run_backup_cycle()

if __name__ == "__main__":
    main()