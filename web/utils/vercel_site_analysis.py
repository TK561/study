#!/usr/bin/env python3
"""
Vercel Webã‚µã‚¤ãƒˆæ§‹æˆè©³ç´°åˆ†æã‚·ã‚¹ãƒ†ãƒ 
"""

import os
import json
from pathlib import Path
from datetime import datetime
import re

class VercelSiteAnalyzer:
    def __init__(self):
        self.public_dir = Path("public")
        self.analysis_result = {}
        
    def analyze_site_structure(self):
        """ã‚µã‚¤ãƒˆæ§‹é€ ã‚’è©³ç´°åˆ†æ"""
        print("ğŸ“Š Vercel Webã‚µã‚¤ãƒˆæ§‹æˆåˆ†æé–‹å§‹...")
        
        structure = {
            "pages": {},
            "assets": {},
            "features": {},
            "total_files": 0,
            "total_size": 0
        }
        
        # å„HTMLãƒšãƒ¼ã‚¸ã‚’åˆ†æ
        for html_file in self.public_dir.rglob("*.html"):
            relative_path = html_file.relative_to(self.public_dir)
            file_size = html_file.stat().st_size
            
            with open(html_file, 'r', encoding='utf-8') as f:
                content = f.read()
                line_count = len(content.split('\n'))
                
            # ã‚³ãƒ³ãƒ†ãƒ³ãƒ„åˆ†æ
            features = self.analyze_page_features(content)
            
            structure["pages"][str(relative_path)] = {
                "size": file_size,
                "lines": line_count,
                "features": features,
                "last_modified": datetime.fromtimestamp(html_file.stat().st_mtime).isoformat()
            }
            
            structure["total_files"] += 1
            structure["total_size"] += file_size
        
        # é™çš„ã‚¢ã‚»ãƒƒãƒˆåˆ†æ
        for asset_file in self.public_dir.rglob("*"):
            if asset_file.is_file() and not asset_file.name.endswith('.html'):
                relative_path = asset_file.relative_to(self.public_dir)
                file_size = asset_file.stat().st_size
                
                extension = asset_file.suffix
                if extension not in structure["assets"]:
                    structure["assets"][extension] = {"count": 0, "total_size": 0}
                
                structure["assets"][extension]["count"] += 1
                structure["assets"][extension]["total_size"] += file_size
        
        self.analysis_result = structure
        return structure
    
    def analyze_page_features(self, content):
        """ãƒšãƒ¼ã‚¸ã®æ©Ÿèƒ½ã‚’åˆ†æ"""
        features = {
            "interactive_elements": 0,
            "charts": False,
            "forms": False,
            "navigation": False,
            "responsive": False,
            "animations": False,
            "external_apis": [],
            "frameworks": []
        }
        
        # ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–è¦ç´ 
        features["interactive_elements"] = len(re.findall(r'onclick|addEventListener|function\s+\w+', content))
        
        # ãƒãƒ£ãƒ¼ãƒˆãƒ»ã‚°ãƒ©ãƒ•
        if "Chart.js" in content or "chart" in content.lower():
            features["charts"] = True
            
        # ãƒ•ã‚©ãƒ¼ãƒ è¦ç´ 
        if "<form" in content or "<input" in content:
            features["forms"] = True
            
        # ãƒŠãƒ“ã‚²ãƒ¼ã‚·ãƒ§ãƒ³
        if "nav" in content.lower() or "menu" in content.lower():
            features["navigation"] = True
            
        # ãƒ¬ã‚¹ãƒãƒ³ã‚·ãƒ–
        if "@media" in content or "viewport" in content:
            features["responsive"] = True
            
        # ã‚¢ãƒ‹ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³
        if "animation" in content or "transition" in content or "@keyframes" in content:
            features["animations"] = True
        
        # å¤–éƒ¨API
        external_apis = re.findall(r'https?://[^"\s]+(?:api|cdn|jsdelivr)[^"\s]*', content)
        features["external_apis"] = list(set(external_apis))
        
        # ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯æ¤œå‡º
        if "Chart.js" in content:
            features["frameworks"].append("Chart.js")
        if "bootstrap" in content.lower():
            features["frameworks"].append("Bootstrap")
        if "react" in content.lower():
            features["frameworks"].append("React")
            
        return features
    
    def generate_analysis_report(self):
        """åˆ†æãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ"""
        report = f"""# ğŸ“Š Vercel Webã‚µã‚¤ãƒˆæ§‹æˆè©³ç´°åˆ†æãƒ¬ãƒãƒ¼ãƒˆ
ç”Ÿæˆæ—¥æ™‚: {datetime.now().strftime('%Yå¹´%mæœˆ%dæ—¥ %H:%M:%S')}

## ğŸŒ ã‚µã‚¤ãƒˆå…¨ä½“æ¦‚è¦
- **ç·ãƒ•ã‚¡ã‚¤ãƒ«æ•°**: {self.analysis_result['total_files']}å€‹
- **ç·ã‚µã‚¤ã‚º**: {self.analysis_result['total_size'] / 1024:.1f} KB
- **ãƒšãƒ¼ã‚¸æ•°**: {len(self.analysis_result['pages'])}ãƒšãƒ¼ã‚¸

## ğŸ“„ ãƒšãƒ¼ã‚¸åˆ¥è©³ç´°åˆ†æ

"""
        
        for page_path, page_info in self.analysis_result['pages'].items():
            report += f"""### ğŸ“‹ {page_path}
- **ã‚µã‚¤ã‚º**: {page_info['size']} bytes ({page_info['lines']} lines)
- **æœ€çµ‚æ›´æ–°**: {page_info['last_modified'][:19]}
- **æ©Ÿèƒ½æ¦‚è¦**:
  - ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–è¦ç´ : {page_info['features']['interactive_elements']}å€‹
  - ãƒãƒ£ãƒ¼ãƒˆ/ã‚°ãƒ©ãƒ•: {'âœ…' if page_info['features']['charts'] else 'âŒ'}
  - ãƒ•ã‚©ãƒ¼ãƒ : {'âœ…' if page_info['features']['forms'] else 'âŒ'}
  - ãƒŠãƒ“ã‚²ãƒ¼ã‚·ãƒ§ãƒ³: {'âœ…' if page_info['features']['navigation'] else 'âŒ'}
  - ãƒ¬ã‚¹ãƒãƒ³ã‚·ãƒ–: {'âœ…' if page_info['features']['responsive'] else 'âŒ'}
  - ã‚¢ãƒ‹ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³: {'âœ…' if page_info['features']['animations'] else 'âŒ'}
  - ä½¿ç”¨ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯: {', '.join(page_info['features']['frameworks']) if page_info['features']['frameworks'] else 'ãªã—'}

"""
        
        report += "## ğŸ“¦ ã‚¢ã‚»ãƒƒãƒˆåˆ†æ\n"
        for ext, info in self.analysis_result['assets'].items():
            report += f"- **{ext}**: {info['count']}ãƒ•ã‚¡ã‚¤ãƒ« ({info['total_size']} bytes)\n"
        
        return report
    
    def identify_improvement_areas(self):
        """æ”¹å–„ã™ã¹ãã‚¨ãƒªã‚¢ã‚’ç‰¹å®š"""
        improvements = {
            "missing_features": [],
            "enhancement_opportunities": [],
            "new_page_suggestions": [],
            "technical_improvements": []
        }
        
        # å„ãƒšãƒ¼ã‚¸ã®æ©Ÿèƒ½ãƒã‚§ãƒƒã‚¯
        for page_path, page_info in self.analysis_result['pages'].items():
            features = page_info['features']
            
            # æ¬ ã‘ã¦ã„ã‚‹æ©Ÿèƒ½ã‚’ç‰¹å®š
            if not features['charts'] and 'experiment' not in page_path:
                improvements["missing_features"].append(f"{page_path}: ã‚°ãƒ©ãƒ•ãƒ»ãƒãƒ£ãƒ¼ãƒˆæ©Ÿèƒ½")
                
            if not features['forms'] and 'main-system' in page_path:
                improvements["missing_features"].append(f"{page_path}: ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›ãƒ•ã‚©ãƒ¼ãƒ ")
                
            if features['interactive_elements'] < 3:
                improvements["enhancement_opportunities"].append(f"{page_path}: ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–æ€§å‘ä¸Š")
        
        # æ–°ãƒšãƒ¼ã‚¸ææ¡ˆ
        existing_pages = set(self.analysis_result['pages'].keys())
        
        suggested_pages = [
            "api-documentation/index.html",
            "research-timeline/index.html", 
            "comparison-tools/index.html",
            "dataset-explorer/index.html",
            "real-time-demo/index.html",
            "publication-tracker/index.html",
            "collaboration-hub/index.html"
        ]
        
        for page in suggested_pages:
            if page not in existing_pages:
                improvements["new_page_suggestions"].append(page)
        
        # æŠ€è¡“çš„æ”¹å–„
        improvements["technical_improvements"] = [
            "Progressive Web App (PWA) å¯¾å¿œ",
            "API ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆè¿½åŠ ",
            "ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒ‡ãƒ¼ã‚¿é€£æº",
            "ãƒ¦ãƒ¼ã‚¶ãƒ¼èªè¨¼ã‚·ã‚¹ãƒ†ãƒ ",
            "ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹çµ±åˆ",
            "æ¤œç´¢æ©Ÿèƒ½è¿½åŠ ",
            "ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°æ©Ÿèƒ½",
            "ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆæ©Ÿèƒ½"
        ]
        
        return improvements

def main():
    analyzer = VercelSiteAnalyzer()
    
    # ã‚µã‚¤ãƒˆæ§‹é€ åˆ†æ
    structure = analyzer.analyze_site_structure()
    
    # åˆ†æãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
    report = analyzer.generate_analysis_report()
    
    # æ”¹å–„ã‚¨ãƒªã‚¢ç‰¹å®š
    improvements = analyzer.identify_improvement_areas()
    
    # ãƒ¬ãƒãƒ¼ãƒˆä¿å­˜
    with open("vercel_site_analysis_report.md", 'w', encoding='utf-8') as f:
        f.write(report)
    
    # æ”¹å–„ææ¡ˆä¿å­˜
    with open("site_improvement_suggestions.json", 'w', encoding='utf-8') as f:
        json.dump(improvements, f, indent=2, ensure_ascii=False)
    
    print("âœ… Vercel ã‚µã‚¤ãƒˆåˆ†æå®Œäº†")
    print(f"ğŸ“„ åˆ†æãƒ¬ãƒãƒ¼ãƒˆ: vercel_site_analysis_report.md")
    print(f"ğŸ’¡ æ”¹å–„ææ¡ˆ: site_improvement_suggestions.json")
    
    # ä¸»è¦çµ±è¨ˆè¡¨ç¤º
    print(f"\nğŸ“Š ä¸»è¦çµ±è¨ˆ:")
    print(f"  - ãƒšãƒ¼ã‚¸æ•°: {len(structure['pages'])}")
    print(f"  - ç·ã‚µã‚¤ã‚º: {structure['total_size'] / 1024:.1f} KB")
    print(f"  - æ”¹å–„ææ¡ˆ: {len(improvements['new_page_suggestions'])}ãƒšãƒ¼ã‚¸")
    
    return structure, improvements

if __name__ == "__main__":
    main()