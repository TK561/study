#!/usr/bin/env python3
"""
å‹•çš„ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆé¸æŠã‚¨ãƒ³ã‚¸ãƒ³ - å®Œå…¨å®Ÿè£…ç‰ˆ
ç”»åƒã®ç‰¹æ€§ã«åŸºã¥ã„ã¦æœ€é©ãªãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’è‡ªå‹•é¸æŠã™ã‚‹ã‚·ã‚¹ãƒ†ãƒ 
"""

import json
import os
from datetime import datetime
from pathlib import Path
import random
from collections import defaultdict

class DynamicDatasetSelector:
    def __init__(self):
        self.name = "å‹•çš„ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆé¸æŠã‚¨ãƒ³ã‚¸ãƒ³"
        self.version = "2.0.0"
        self.datasets = self._initialize_datasets()
        self.selection_history = []
        self.output_dir = Path("output/dataset_selections")
        self.output_dir.mkdir(parents=True, exist_ok=True)
        
    def _initialize_datasets(self):
        """åˆ©ç”¨å¯èƒ½ãªãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆæƒ…å ±ã‚’åˆæœŸåŒ–"""
        return {
            "coco": {
                "name": "COCO Dataset",
                "categories": 80,
                "size": "large",
                "speciality": ["general", "common_objects"],
                "strengths": ["person", "vehicle", "animal", "furniture"],
                "performance_score": 0.85,
                "training_images": 118000,
                "use_cases": ["general_detection", "daily_objects"]
            },
            "imagenet": {
                "name": "ImageNet",
                "categories": 1000,
                "size": "xlarge",
                "speciality": ["classification", "fine_grained"],
                "strengths": ["animals", "plants", "objects", "scenes"],
                "performance_score": 0.82,
                "training_images": 1200000,
                "use_cases": ["detailed_classification", "research"]
            },
            "openimages": {
                "name": "Open Images",
                "categories": 600,
                "size": "large",
                "speciality": ["detection", "segmentation"],
                "strengths": ["complex_scenes", "relationships"],
                "performance_score": 0.87,
                "training_images": 1900000,
                "use_cases": ["complex_detection", "scene_understanding"]
            },
            "cityscapes": {
                "name": "Cityscapes",
                "categories": 30,
                "size": "medium",
                "speciality": ["urban", "autonomous_driving"],
                "strengths": ["road", "vehicle", "pedestrian", "traffic_sign"],
                "performance_score": 0.92,
                "training_images": 25000,
                "use_cases": ["autonomous_driving", "urban_analysis"]
            },
            "ade20k": {
                "name": "ADE20K",
                "categories": 150,
                "size": "medium",
                "speciality": ["scene_parsing", "indoor_outdoor"],
                "strengths": ["furniture", "building", "nature"],
                "performance_score": 0.83,
                "training_images": 25000,
                "use_cases": ["scene_understanding", "interior_design"]
            },
            "medical": {
                "name": "Medical Images",
                "categories": 50,
                "size": "medium",
                "speciality": ["medical", "diagnostic"],
                "strengths": ["organs", "abnormalities", "medical_devices"],
                "performance_score": 0.89,
                "training_images": 100000,
                "use_cases": ["medical_diagnosis", "health_screening"]
            },
            "aerial": {
                "name": "Aerial/Satellite",
                "categories": 40,
                "size": "medium",
                "speciality": ["aerial", "geographic"],
                "strengths": ["buildings", "roads", "vegetation", "water"],
                "performance_score": 0.86,
                "training_images": 50000,
                "use_cases": ["mapping", "environmental_monitoring"]
            },
            "fashion": {
                "name": "Fashion Dataset",
                "categories": 100,
                "size": "medium",
                "speciality": ["fashion", "clothing"],
                "strengths": ["clothing", "accessories", "styles"],
                "performance_score": 0.90,
                "training_images": 80000,
                "use_cases": ["e_commerce", "fashion_recommendation"]
            },
            "food": {
                "name": "Food-101",
                "categories": 101,
                "size": "medium",
                "speciality": ["food", "cuisine"],
                "strengths": ["dishes", "ingredients", "cuisine_types"],
                "performance_score": 0.88,
                "training_images": 101000,
                "use_cases": ["food_recognition", "nutrition_analysis"]
            },
            "wildlife": {
                "name": "Wildlife Dataset",
                "categories": 200,
                "size": "medium",
                "speciality": ["animals", "nature"],
                "strengths": ["wild_animals", "birds", "marine_life"],
                "performance_score": 0.84,
                "training_images": 150000,
                "use_cases": ["wildlife_monitoring", "conservation"]
            }
        }
    
    def analyze_image_characteristics(self, image_data):
        """ç”»åƒã®ç‰¹æ€§ã‚’åˆ†æï¼ˆãƒ¢ãƒƒã‚¯å®Ÿè£…ï¼‰"""
        # å®Ÿéš›ã®å®Ÿè£…ã§ã¯ç”»åƒè§£æã‚’è¡Œã†
        characteristics = {
            "domain": random.choice(["general", "urban", "nature", "indoor", "medical", "aerial"]),
            "complexity": random.uniform(0.3, 1.0),
            "object_density": random.uniform(0.1, 0.9),
            "scene_type": random.choice(["single_object", "multiple_objects", "complex_scene"]),
            "lighting": random.choice(["good", "moderate", "poor"]),
            "detected_categories": self._generate_mock_categories()
        }
        
        return characteristics
    
    def _generate_mock_categories(self):
        """ãƒ¢ãƒƒã‚¯ã‚«ãƒ†ã‚´ãƒªã‚’ç”Ÿæˆ"""
        all_categories = [
            "person", "vehicle", "animal", "furniture", "building",
            "plant", "food", "clothing", "electronics", "nature"
        ]
        num_categories = random.randint(1, 5)
        return random.sample(all_categories, num_categories)
    
    def calculate_dataset_scores(self, image_characteristics):
        """å„ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®é©åˆåº¦ã‚¹ã‚³ã‚¢ã‚’è¨ˆç®—"""
        scores = {}
        
        for dataset_id, dataset_info in self.datasets.items():
            score = 0.0
            
            # ãƒ‰ãƒ¡ã‚¤ãƒ³é©åˆåº¦
            domain_match = self._calculate_domain_match(
                image_characteristics["domain"],
                dataset_info["speciality"]
            )
            score += domain_match * 0.3
            
            # ã‚«ãƒ†ã‚´ãƒªé©åˆåº¦
            category_match = self._calculate_category_match(
                image_characteristics["detected_categories"],
                dataset_info["strengths"]
            )
            score += category_match * 0.3
            
            # è¤‡é›‘åº¦é©åˆåº¦
            complexity_match = self._calculate_complexity_match(
                image_characteristics["complexity"],
                dataset_info["categories"]
            )
            score += complexity_match * 0.2
            
            # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚¹ã‚³ã‚¢
            score += dataset_info["performance_score"] * 0.2
            
            scores[dataset_id] = {
                "total_score": round(score, 3),
                "domain_match": round(domain_match, 3),
                "category_match": round(category_match, 3),
                "complexity_match": round(complexity_match, 3),
                "performance_score": dataset_info["performance_score"]
            }
        
        return scores
    
    def _calculate_domain_match(self, image_domain, dataset_specialities):
        """ãƒ‰ãƒ¡ã‚¤ãƒ³é©åˆåº¦ã‚’è¨ˆç®—"""
        domain_mapping = {
            "general": ["general", "common_objects"],
            "urban": ["urban", "autonomous_driving", "detection"],
            "nature": ["animals", "nature", "scene_parsing"],
            "indoor": ["scene_parsing", "indoor_outdoor", "furniture"],
            "medical": ["medical", "diagnostic"],
            "aerial": ["aerial", "geographic"]
        }
        
        if image_domain in domain_mapping:
            for speciality in dataset_specialities:
                if speciality in domain_mapping[image_domain]:
                    return 1.0
        
        return 0.3  # éƒ¨åˆ†çš„ãªé©åˆ
    
    def _calculate_category_match(self, detected_categories, dataset_strengths):
        """ã‚«ãƒ†ã‚´ãƒªé©åˆåº¦ã‚’è¨ˆç®—"""
        if not detected_categories:
            return 0.5
        
        matches = sum(1 for cat in detected_categories if any(
            strength in cat or cat in strength for strength in dataset_strengths
        ))
        
        return matches / len(detected_categories)
    
    def _calculate_complexity_match(self, image_complexity, dataset_categories):
        """è¤‡é›‘åº¦é©åˆåº¦ã‚’è¨ˆç®—"""
        # ã‚«ãƒ†ã‚´ãƒªæ•°ãŒå¤šã„ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¯è¤‡é›‘ãªç”»åƒã«é©ã—ã¦ã„ã‚‹
        if image_complexity > 0.7:
            return min(dataset_categories / 200, 1.0)
        elif image_complexity < 0.3:
            return 1.0 - min(dataset_categories / 200, 0.7)
        else:
            return 0.7
    
    def select_optimal_dataset(self, image_data, top_k=3):
        """æœ€é©ãªãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’é¸æŠ"""
        # ç”»åƒç‰¹æ€§åˆ†æ
        characteristics = self.analyze_image_characteristics(image_data)
        
        # ã‚¹ã‚³ã‚¢è¨ˆç®—
        scores = self.calculate_dataset_scores(characteristics)
        
        # ã‚¹ã‚³ã‚¢ã§ã‚½ãƒ¼ãƒˆ
        sorted_datasets = sorted(
            scores.items(),
            key=lambda x: x[1]["total_score"],
            reverse=True
        )
        
        # é¸æŠçµæœã‚’æ§‹ç¯‰
        selection_result = {
            "timestamp": datetime.now().isoformat(),
            "image_characteristics": characteristics,
            "recommended_datasets": [],
            "all_scores": scores
        }
        
        # ãƒˆãƒƒãƒ—Kã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’æ¨å¥¨
        for i, (dataset_id, score_info) in enumerate(sorted_datasets[:top_k]):
            dataset_info = self.datasets[dataset_id]
            recommendation = {
                "rank": i + 1,
                "dataset_id": dataset_id,
                "dataset_name": dataset_info["name"],
                "score": score_info["total_score"],
                "score_breakdown": score_info,
                "reason": self._generate_recommendation_reason(
                    characteristics, dataset_info, score_info
                ),
                "use_cases": dataset_info["use_cases"]
            }
            selection_result["recommended_datasets"].append(recommendation)
        
        # å±¥æ­´ã«è¿½åŠ 
        self.selection_history.append(selection_result)
        
        return selection_result
    
    def _generate_recommendation_reason(self, characteristics, dataset_info, score_info):
        """æ¨å¥¨ç†ç”±ã‚’ç”Ÿæˆ"""
        reasons = []
        
        if score_info["domain_match"] > 0.8:
            reasons.append(f"ç”»åƒãƒ‰ãƒ¡ã‚¤ãƒ³ï¼ˆ{characteristics['domain']}ï¼‰ã«æœ€é©")
        
        if score_info["category_match"] > 0.7:
            reasons.append(f"æ¤œå‡ºã‚«ãƒ†ã‚´ãƒªã¨ã®é«˜ã„é©åˆæ€§")
        
        if score_info["performance_score"] > 0.85:
            reasons.append(f"é«˜ã„æ€§èƒ½ã‚¹ã‚³ã‚¢ï¼ˆ{dataset_info['performance_score']}ï¼‰")
        
        if dataset_info["training_images"] > 100000:
            reasons.append(f"è±Šå¯Œãªå­¦ç¿’ãƒ‡ãƒ¼ã‚¿ï¼ˆ{dataset_info['training_images']:,}æšï¼‰")
        
        return " / ".join(reasons) if reasons else "ç·åˆçš„ãªãƒãƒ©ãƒ³ã‚¹ãŒè‰¯ã„"
    
    def generate_selection_report(self):
        """é¸æŠå±¥æ­´ãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆ"""
        if not self.selection_history:
            return "é¸æŠå±¥æ­´ãŒã‚ã‚Šã¾ã›ã‚“"
        
        report = {
            "total_selections": len(self.selection_history),
            "dataset_usage": defaultdict(int),
            "average_scores": defaultdict(list),
            "domain_distribution": defaultdict(int)
        }
        
        for selection in self.selection_history:
            # æ¨å¥¨ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ä½¿ç”¨å›æ•°
            for rec in selection["recommended_datasets"]:
                if rec["rank"] == 1:
                    report["dataset_usage"][rec["dataset_id"]] += 1
                report["average_scores"][rec["dataset_id"]].append(rec["score"])
            
            # ãƒ‰ãƒ¡ã‚¤ãƒ³åˆ†å¸ƒ
            report["domain_distribution"][selection["image_characteristics"]["domain"]] += 1
        
        # å¹³å‡ã‚¹ã‚³ã‚¢ã‚’è¨ˆç®—
        for dataset_id, scores in report["average_scores"].items():
            report["average_scores"][dataset_id] = round(sum(scores) / len(scores), 3)
        
        # ãƒ¬ãƒãƒ¼ãƒˆä½œæˆ
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        report_path = self.output_dir / f"selection_report_{timestamp}.json"
        
        with open(report_path, 'w', encoding='utf-8') as f:
            json.dump(report, f, ensure_ascii=False, indent=2, default=dict)
        
        return report_path
    
    def export_configuration(self):
        """ã‚·ã‚¹ãƒ†ãƒ è¨­å®šã‚’ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ"""
        config = {
            "system_name": self.name,
            "version": self.version,
            "export_date": datetime.now().isoformat(),
            "datasets": self.datasets,
            "selection_algorithm": {
                "weights": {
                    "domain_match": 0.3,
                    "category_match": 0.3,
                    "complexity_match": 0.2,
                    "performance_score": 0.2
                },
                "description": "å¤šè¦ç´ ã‚’è€ƒæ…®ã—ãŸé‡ã¿ä»˜ã‘ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°"
            }
        }
        
        config_path = self.output_dir / "system_configuration.json"
        with open(config_path, 'w', encoding='utf-8') as f:
            json.dump(config, f, ensure_ascii=False, indent=2)
        
        return config_path

def main():
    """å®Ÿè¡Œä¾‹"""
    print("ğŸ¯ å‹•çš„ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆé¸æŠã‚¨ãƒ³ã‚¸ãƒ³ èµ·å‹•")
    print("=" * 50)
    
    selector = DynamicDatasetSelector()
    
    # ã‚·ã‚¹ãƒ†ãƒ è¨­å®šã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ
    config_path = selector.export_configuration()
    print(f"âš™ï¸ ã‚·ã‚¹ãƒ†ãƒ è¨­å®šã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ: {config_path}")
    
    # ãƒ†ã‚¹ãƒˆé¸æŠå®Ÿè¡Œ
    print("\nğŸ” ãƒ†ã‚¹ãƒˆç”»åƒã§ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆé¸æŠå®Ÿè¡Œ...")
    
    # è¤‡æ•°ã®ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹
    test_cases = [
        {"name": "éƒ½å¸‚é¢¨æ™¯", "mock_domain": "urban"},
        {"name": "åŒ»ç™‚ç”»åƒ", "mock_domain": "medical"},
        {"name": "è‡ªç„¶é¢¨æ™¯", "mock_domain": "nature"},
        {"name": "ä¸€èˆ¬ç‰©ä½“", "mock_domain": "general"}
    ]
    
    for test_case in test_cases:
        print(f"\nğŸ“¸ ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹: {test_case['name']}")
        
        # ãƒ¢ãƒƒã‚¯ç”»åƒãƒ‡ãƒ¼ã‚¿
        mock_image = {"test": True, "domain_hint": test_case["mock_domain"]}
        
        # ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆé¸æŠ
        result = selector.select_optimal_dataset(mock_image, top_k=3)
        
        print(f"  ç”»åƒç‰¹æ€§: {result['image_characteristics']['domain']}")
        print(f"  æ¨å¥¨ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ:")
        
        for rec in result["recommended_datasets"]:
            print(f"    {rec['rank']}. {rec['dataset_name']} (ã‚¹ã‚³ã‚¢: {rec['score']})")
            print(f"       ç†ç”±: {rec['reason']}")
    
    # é¸æŠãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
    report_path = selector.generate_selection_report()
    print(f"\nğŸ“Š é¸æŠãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ: {report_path}")
    
    print("\nâœ¨ ã‚·ã‚¹ãƒ†ãƒ æº–å‚™å®Œäº†")

if __name__ == "__main__":
    main()