#!/usr/bin/env python3
"""
å®Œå…¨ç‰ˆä½œæ¥­çµ‚äº†æ™‚è‡ªå‹•æ•´ç†ã‚·ã‚¹ãƒ†ãƒ 
ä½œæ¥­çµ‚äº†ã®æ„å›³ã‚’èª­ã¿å–ã£ã¦åŒ…æ‹¬çš„ãªæ•´ç†ãƒ»ä¿è­·ãƒ»æœ€é©åŒ–ã‚’å®Ÿè¡Œ
"""

import os
import shutil
import glob
import psutil
import subprocess
import json
import hashlib
import requests
import time
from datetime import datetime, timedelta
from pathlib import Path
from auto_save_today import auto_save_today_work

class CompleteAutoCleanup:
    """å®Œå…¨ç‰ˆè‡ªå‹•æ•´ç†ã‚·ã‚¹ãƒ†ãƒ """
    
    def __init__(self):
        self.base_dir = "/mnt/c/Desktop/Research"
        self.results = {
            "start_time": datetime.now(),
            "actions": [],
            "warnings": [],
            "errors": []
        }
    
    def execute_complete_cleanup(self):
        """å®Œå…¨ç‰ˆè‡ªå‹•æ•´ç†ã®å®Ÿè¡Œ"""
        print("ğŸš€ å®Œå…¨ç‰ˆä½œæ¥­çµ‚äº†æ™‚è‡ªå‹•æ•´ç†ã‚’é–‹å§‹...")
        print("="*60)
        
        # åŸºæœ¬æ•´ç†
        self._basic_cleanup()
        
        # ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒ»å®‰å…¨æ€§
        self._security_checks()
        
        # ãƒ‡ãƒ¼ã‚¿ä¿è­·ãƒ»ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—
        self._data_protection()
        
        # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ»ãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹
        self._performance_maintenance()
        
        # ä½œæ¥­ç¶™ç¶šæ€§
        self._continuity_checks()
        
        # ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆãƒ»å±¥æ­´
        self._documentation_update()
        
        # æ¬¡å›æº–å‚™
        self._next_session_preparation()
        
        # æœ€çµ‚ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
        self._generate_complete_report()
        
        print("\n" + "="*60)
        print("âœ… å®Œå…¨ç‰ˆè‡ªå‹•æ•´ç†å®Œäº†ï¼")
        print("ğŸ“Š ã™ã¹ã¦ã®ã‚·ã‚¹ãƒ†ãƒ ãŒæœ€é©åŒ–ã•ã‚Œã¾ã—ãŸ")
    
    def _basic_cleanup(self):
        """åŸºæœ¬çš„ãªæ•´ç†"""
        print("\nğŸ“ 1. åŸºæœ¬æ•´ç†...")
        
        # ä½œæ¥­å†…å®¹ä¿å­˜
        auto_save_today_work()
        self.results["actions"].append("ä½œæ¥­å†…å®¹ä¿å­˜å®Œäº†")
        
        # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤
        deleted = self._cleanup_temp_files()
        self.results["actions"].append(f"ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«{deleted}ä»¶å‰Šé™¤")
        
        # ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«æ•´ç†
        deleted = self._cleanup_old_logs()
        self.results["actions"].append(f"å¤ã„ãƒ­ã‚°{deleted}ä»¶å‰Šé™¤")
    
    def _security_checks(self):
        """ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒ»å®‰å…¨æ€§ãƒã‚§ãƒƒã‚¯"""
        print("\nğŸ”’ 2. ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒã‚§ãƒƒã‚¯...")
        
        # APIã‚­ãƒ¼ãƒ»èªè¨¼æƒ…å ±ãƒã‚§ãƒƒã‚¯
        security_issues = self._check_api_keys()
        if security_issues:
            self.results["warnings"].extend(security_issues)
        
        # æ©Ÿå¯†ãƒ•ã‚¡ã‚¤ãƒ«ã®æ¨©é™ç¢ºèª
        permission_issues = self._check_file_permissions()
        if permission_issues:
            self.results["warnings"].extend(permission_issues)
        
        # å…¬é–‹ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®å®‰å…¨æ€§ç¢ºèª
        public_safety = self._check_public_safety()
        self.results["actions"].append(f"ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒã‚§ãƒƒã‚¯å®Œäº†: {len(security_issues)}ä»¶ã®æ³¨æ„äº‹é …")
    
    def _data_protection(self):
        """ãƒ‡ãƒ¼ã‚¿ä¿è­·ãƒ»ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—"""
        print("\nğŸ’¾ 3. ãƒ‡ãƒ¼ã‚¿ä¿è­·...")
        
        # é‡è¦ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—
        backup_count = self._backup_critical_files()
        self.results["actions"].append(f"é‡è¦ãƒ•ã‚¡ã‚¤ãƒ«{backup_count}ä»¶ã‚’ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—")
        
        # ç ”ç©¶ãƒ‡ãƒ¼ã‚¿ã®æ•´åˆæ€§ãƒã‚§ãƒƒã‚¯
        integrity_check = self._verify_research_data_integrity()
        self.results["actions"].append("ç ”ç©¶ãƒ‡ãƒ¼ã‚¿æ•´åˆæ€§ç¢ºèªå®Œäº†")
        
        # Gitã®å®‰å…¨ãªã‚³ãƒŸãƒƒãƒˆ
        git_status = self._safe_git_operations()
        if git_status:
            self.results["actions"].append(git_status)
    
    def _performance_maintenance(self):
        """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ»ãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹"""
        print("\nâš¡ 4. ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–...")
        
        # ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ãƒã‚§ãƒƒã‚¯
        memory_info = self._check_memory_usage()
        self.results["actions"].append(f"ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡: {memory_info}")
        
        # ãƒ‡ã‚£ã‚¹ã‚¯å®¹é‡ãƒã‚§ãƒƒã‚¯
        disk_info = self._check_disk_space()
        self.results["actions"].append(f"ãƒ‡ã‚£ã‚¹ã‚¯ä½¿ç”¨é‡: {disk_info}")
        
        # ãƒ—ãƒ­ã‚»ã‚¹æœ€é©åŒ–
        optimized_processes = self._optimize_processes()
        self.results["actions"].append(f"ãƒ—ãƒ­ã‚»ã‚¹æœ€é©åŒ–: {optimized_processes}")
    
    def _continuity_checks(self):
        """ä½œæ¥­ç¶™ç¶šæ€§ãƒã‚§ãƒƒã‚¯"""
        print("\nğŸ”— 5. ä½œæ¥­ç¶™ç¶šæ€§ç¢ºèª...")
        
        # ä¾å­˜é–¢ä¿‚ãƒã‚§ãƒƒã‚¯
        deps_status = self._check_dependencies()
        self.results["actions"].append(f"ä¾å­˜é–¢ä¿‚ãƒã‚§ãƒƒã‚¯: {deps_status}")
        
        # ç’°å¢ƒè¨­å®šæ¤œè¨¼
        env_status = self._verify_environment()
        self.results["actions"].append(f"ç’°å¢ƒè¨­å®šæ¤œè¨¼: {env_status}")
        
        # ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯æ¥ç¶šãƒ†ã‚¹ãƒˆ
        network_status = self._test_network_connections()
        self.results["actions"].append(f"ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯æ¥ç¶š: {network_status}")
    
    def _documentation_update(self):
        """ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆãƒ»å±¥æ­´æ›´æ–°"""
        print("\nğŸ“š 6. ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæ›´æ–°...")
        
        # ä½œæ¥­ãƒ­ã‚°ã®è©³ç´°è¨˜éŒ²
        self._create_detailed_work_log()
        self.results["actions"].append("è©³ç´°ä½œæ¥­ãƒ­ã‚°ä½œæˆå®Œäº†")
        
        # ã‚¨ãƒ©ãƒ¼ãƒ­ã‚°è¦ç´„
        error_summary = self._summarize_error_logs()
        self.results["actions"].append(f"ã‚¨ãƒ©ãƒ¼ãƒ­ã‚°è¦ç´„: {error_summary}")
        
        # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹çµ±è¨ˆ
        perf_stats = self._generate_performance_stats()
        self.results["actions"].append("ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹çµ±è¨ˆç”Ÿæˆå®Œäº†")
    
    def _next_session_preparation(self):
        """æ¬¡å›ã‚»ãƒƒã‚·ãƒ§ãƒ³æº–å‚™"""
        print("\nğŸš€ 7. æ¬¡å›ã‚»ãƒƒã‚·ãƒ§ãƒ³æº–å‚™...")
        
        # èµ·å‹•ã‚¹ã‚¯ãƒªãƒ—ãƒˆæº–å‚™
        self._prepare_startup_script()
        self.results["actions"].append("èµ·å‹•ã‚¹ã‚¯ãƒªãƒ—ãƒˆæº–å‚™å®Œäº†")
        
        # è¨­å®šæœ€é©åŒ–
        optimizations = self._optimize_configurations()
        self.results["actions"].append(f"è¨­å®šæœ€é©åŒ–: {optimizations}")
        
        # äº‹å‰ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
        preload_status = self._preload_dependencies()
        self.results["actions"].append(f"ä¾å­˜é–¢ä¿‚äº‹å‰æº–å‚™: {preload_status}")
    
    # === å®Ÿè£…ãƒ¡ã‚½ãƒƒãƒ‰ ===
    
    def _cleanup_temp_files(self):
        """ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤"""
        patterns = ["*.tmp", "*.temp", "*~", "*.bak", "*.swp", ".DS_Store", "Thumbs.db"]
        deleted = 0
        for pattern in patterns:
            for file_path in glob.glob(pattern, recursive=True):
                try:
                    os.remove(file_path)
                    deleted += 1
                except:
                    pass
        return deleted
    
    def _cleanup_old_logs(self):
        """å¤ã„ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤"""
        patterns = ["*.log", "debug_*.txt", "error_*.txt"]
        current_time = time.time()
        deleted = 0
        
        for pattern in patterns:
            for file_path in glob.glob(pattern):
                try:
                    if current_time - os.path.getmtime(file_path) > 7 * 24 * 3600:
                        os.remove(file_path)
                        deleted += 1
                except:
                    pass
        return deleted
    
    def _check_api_keys(self):
        """APIã‚­ãƒ¼ãƒ»èªè¨¼æƒ…å ±ãƒã‚§ãƒƒã‚¯"""
        issues = []
        
        # .envãƒ•ã‚¡ã‚¤ãƒ«ã®å ´æ‰€ç¢ºèª
        env_files = glob.glob("**/.env", recursive=True)
        for env_file in env_files:
            if not env_file.startswith('./.claude_sessions'):
                issues.append(f"âš ï¸ APIã‚­ãƒ¼ãƒ•ã‚¡ã‚¤ãƒ«ãŒå…¬é–‹ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«: {env_file}")
        
        # ã‚½ãƒ¼ã‚¹ã‚³ãƒ¼ãƒ‰å†…ã®APIã‚­ãƒ¼æ¤œç´¢
        py_files = glob.glob("**/*.py", recursive=True)
        for py_file in py_files:
            try:
                with open(py_file, 'r', encoding='utf-8') as f:
                    content = f.read()
                    if 'api_key' in content.lower() and ('=' in content and '"' in content):
                        issues.append(f"âš ï¸ ã‚½ãƒ¼ã‚¹ã‚³ãƒ¼ãƒ‰ã«APIã‚­ãƒ¼ã®å¯èƒ½æ€§: {py_file}")
            except:
                pass
        
        return issues
    
    def _check_file_permissions(self):
        """ãƒ•ã‚¡ã‚¤ãƒ«æ¨©é™ãƒã‚§ãƒƒã‚¯"""
        issues = []
        sensitive_files = ['.env', 'private_key', 'credentials']
        
        for root, dirs, files in os.walk('.'):
            for file in files:
                file_path = os.path.join(root, file)
                if any(sensitive in file.lower() for sensitive in sensitive_files):
                    try:
                        stat = os.stat(file_path)
                        mode = oct(stat.st_mode)[-3:]
                        if mode != '600':  # æ‰€æœ‰è€…ã®ã¿èª­ã¿æ›¸ã
                            issues.append(f"âš ï¸ ãƒ•ã‚¡ã‚¤ãƒ«æ¨©é™è¦ç¢ºèª: {file_path} ({mode})")
                    except:
                        pass
        
        return issues
    
    def _check_public_safety(self):
        """å…¬é–‹ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå®‰å…¨æ€§ç¢ºèª"""
        public_dirs = ['api/', 'public/', 'static/']
        issues = []
        
        for pub_dir in public_dirs:
            if os.path.exists(pub_dir):
                for root, dirs, files in os.walk(pub_dir):
                    for file in files:
                        if file.startswith('.env') or 'key' in file.lower():
                            issues.append(f"âš ï¸ å…¬é–‹ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«æ©Ÿå¯†ãƒ•ã‚¡ã‚¤ãƒ«: {os.path.join(root, file)}")
        
        return len(issues) == 0
    
    def _backup_critical_files(self):
        """é‡è¦ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—"""
        critical_files = [
            'api/index.py',
            'vercel_api_setup.py',
            '.env',
            'deep_consultation_system.py',
            'session_recovery_system.py'
        ]
        
        backup_dir = f".backups/{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        os.makedirs(backup_dir, exist_ok=True)
        
        backed_up = 0
        for file_path in critical_files:
            if os.path.exists(file_path):
                try:
                    shutil.copy2(file_path, backup_dir)
                    backed_up += 1
                except:
                    pass
        
        return backed_up
    
    def _verify_research_data_integrity(self):
        """ç ”ç©¶ãƒ‡ãƒ¼ã‚¿æ•´åˆæ€§ãƒã‚§ãƒƒã‚¯"""
        study_dir = "study/"
        if not os.path.exists(study_dir):
            return False
        
        # é‡è¦ãªç ”ç©¶ãƒ•ã‚¡ã‚¤ãƒ«ã®å­˜åœ¨ç¢ºèª
        critical_research_files = [
            "study/research_content/",
            "study/analysis_reports/",
            "study/references/"
        ]
        
        for path in critical_research_files:
            if not os.path.exists(path):
                self.results["warnings"].append(f"âš ï¸ é‡è¦ãªç ”ç©¶ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {path}")
        
        return True
    
    def _safe_git_operations(self):
        """å®‰å…¨ãªGitæ“ä½œï¼ˆç ”ç©¶é–¢é€£ãƒ•ã‚¡ã‚¤ãƒ«ã®ã¿ï¼‰"""
        try:
            # ç ”ç©¶é–¢é€£ãƒ•ã‚¡ã‚¤ãƒ«ã®ã¿ã‚’å¯¾è±¡
            research_files = [
                'api/index.py',
                'vercel_api_setup.py', 
                'index.html',
                'study/',
                'vercel.json'
            ]
            
            # ç ”ç©¶é–¢é€£ãƒ•ã‚¡ã‚¤ãƒ«ã®å¤‰æ›´ã‚’ãƒã‚§ãƒƒã‚¯
            changed_research_files = []
            
            result = subprocess.run(['git', 'status', '--porcelain'], 
                                  capture_output=True, text=True, cwd=self.base_dir)
            
            if result.returncode == 0:
                changes = result.stdout.strip().split('\n') if result.stdout.strip() else []
                
                for change in changes:
                    if len(change) > 3:
                        file_path = change[3:]  # ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹æ–‡å­—ã‚’é™¤å»
                        
                        # ç ”ç©¶é–¢é€£ãƒ•ã‚¡ã‚¤ãƒ«ã‹ãƒã‚§ãƒƒã‚¯
                        for research_file in research_files:
                            if file_path.startswith(research_file):
                                changed_research_files.append(file_path)
                                break
                
                if changed_research_files:
                    # ç ”ç©¶é–¢é€£ãƒ•ã‚¡ã‚¤ãƒ«ã®ã¿ã‚’ã‚¹ãƒ†ãƒ¼ã‚¸ãƒ³ã‚°
                    for file_path in changed_research_files:
                        try:
                            subprocess.run(['git', 'add', file_path], 
                                         cwd=self.base_dir, check=True)
                        except:
                            pass
                    
                    # å‰Šé™¤ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã‚‚è¿½åŠ 
                    subprocess.run(['git', 'add', '-u'] + research_files, 
                                 cwd=self.base_dir, capture_output=True)
                    
                    return f"ç ”ç©¶é–¢é€£ãƒ•ã‚¡ã‚¤ãƒ« {len(changed_research_files)}ä»¶ã‚’ã‚¹ãƒ†ãƒ¼ã‚¸ãƒ³ã‚°å®Œäº†"
                else:
                    return "ç ”ç©¶é–¢é€£ãƒ•ã‚¡ã‚¤ãƒ«ã«å¤‰æ›´ãªã—"
            else:
                return "GitçŠ¶æ…‹ç¢ºèªå¤±æ•—"
        except Exception as e:
            return f"Gitæ“ä½œã‚¨ãƒ©ãƒ¼: {str(e)}"
    
    def _check_memory_usage(self):
        """ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ãƒã‚§ãƒƒã‚¯"""
        memory = psutil.virtual_memory()
        return f"{memory.percent:.1f}% ({memory.available / 1024**3:.1f}GBåˆ©ç”¨å¯èƒ½)"
    
    def _check_disk_space(self):
        """ãƒ‡ã‚£ã‚¹ã‚¯å®¹é‡ãƒã‚§ãƒƒã‚¯"""
        disk = psutil.disk_usage('.')
        free_gb = disk.free / 1024**3
        used_percent = (disk.used / disk.total) * 100
        
        if free_gb < 1.0:  # 1GBæœªæº€
            self.results["warnings"].append("âš ï¸ ãƒ‡ã‚£ã‚¹ã‚¯å®¹é‡ä¸è¶³: 1GBæœªæº€")
        
        return f"{used_percent:.1f}% ä½¿ç”¨ä¸­ ({free_gb:.1f}GBç©ºã)"
    
    def _optimize_processes(self):
        """ãƒ—ãƒ­ã‚»ã‚¹æœ€é©åŒ–"""
        python_processes = 0
        for proc in psutil.process_iter(['pid', 'name', 'cpu_percent']):
            try:
                if 'python' in proc.info['name'].lower():
                    python_processes += 1
            except:
                pass
        
        return f"Pythoné–¢é€£ãƒ—ãƒ­ã‚»ã‚¹ {python_processes}å€‹å®Ÿè¡Œä¸­"
    
    def _check_dependencies(self):
        """ä¾å­˜é–¢ä¿‚ãƒã‚§ãƒƒã‚¯"""
        try:
            # requirements.txtã®ç¢ºèª
            if os.path.exists('requirements.txt'):
                result = subprocess.run(['pip', 'check'], capture_output=True, text=True)
                if result.returncode == 0:
                    return "ä¾å­˜é–¢ä¿‚OK"
                else:
                    self.results["warnings"].append("âš ï¸ ä¾å­˜é–¢ä¿‚ã«å•é¡ŒãŒã‚ã‚Šã¾ã™")
                    return "ä¾å­˜é–¢ä¿‚ã«å•é¡Œ"
            return "requirements.txt ãªã—"
        except:
            return "ä¾å­˜é–¢ä¿‚ãƒã‚§ãƒƒã‚¯å¤±æ•—"
    
    def _verify_environment(self):
        """ç’°å¢ƒè¨­å®šæ¤œè¨¼"""
        checks = []
        
        # Python ãƒãƒ¼ã‚¸ãƒ§ãƒ³
        import sys
        python_version = f"{sys.version_info.major}.{sys.version_info.minor}"
        checks.append(f"Python {python_version}")
        
        # é‡è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒª
        try:
            import requests
            checks.append("requests OK")
        except:
            checks.append("requests NG")
        
        return ", ".join(checks)
    
    def _test_network_connections(self):
        """ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯æ¥ç¶šãƒ†ã‚¹ãƒˆ"""
        tests = []
        
        # ã‚¤ãƒ³ã‚¿ãƒ¼ãƒãƒƒãƒˆæ¥ç¶š
        try:
            response = requests.get('https://httpbin.org/ip', timeout=5)
            if response.status_code == 200:
                tests.append("ã‚¤ãƒ³ã‚¿ãƒ¼ãƒãƒƒãƒˆOK")
            else:
                tests.append("ã‚¤ãƒ³ã‚¿ãƒ¼ãƒãƒƒãƒˆNG")
        except:
            tests.append("ã‚¤ãƒ³ã‚¿ãƒ¼ãƒãƒƒãƒˆæ¥ç¶šå¤±æ•—")
        
        # Gemini API (ç’°å¢ƒå¤‰æ•°ãŒã‚ã‚Œã°)
        if os.path.exists('.env'):
            tests.append("Gemini APIè¨­å®šæ¸ˆã¿")
        
        return ", ".join(tests) if tests else "æ¥ç¶šãƒ†ã‚¹ãƒˆå®Ÿè¡Œã›ãš"
    
    def _create_detailed_work_log(self):
        """è©³ç´°ä½œæ¥­ãƒ­ã‚°ä½œæˆ"""
        from session_recovery_system import get_recovery_system
        
        system = get_recovery_system()
        session = system._load_current_session()
        
        log_content = f"""# è©³ç´°ä½œæ¥­ãƒ­ã‚° - {datetime.now().strftime('%Yå¹´%mæœˆ%dæ—¥')}

## ã‚»ãƒƒã‚·ãƒ§ãƒ³æƒ…å ±
- ã‚»ãƒƒã‚·ãƒ§ãƒ³ID: {session.get('session_id', 'Unknown')}
- é–‹å§‹æ™‚åˆ»: {session.get('start_time', 'Unknown')}
- çµ‚äº†æ™‚åˆ»: {datetime.now().isoformat()}
- ç·ã‚¢ã‚¯ã‚·ãƒ§ãƒ³æ•°: {len(session.get('actions', []))}

## ã‚¢ã‚¯ã‚·ãƒ§ãƒ³è©³ç´°
"""
        
        for i, action in enumerate(session.get('actions', [])[-20:], 1):
            log_content += f"### {i}. {action['timestamp']}\n"
            log_content += f"- ã‚¿ã‚¤ãƒ—: {action['type']}\n"
            if action['type'] == 'file_operation':
                log_content += f"- ãƒ•ã‚¡ã‚¤ãƒ«: {action['details']['file_path']}\n"
                log_content += f"- æ“ä½œ: {action['details']['operation']}\n"
            log_content += "\n"
        
        with open(f"detailed_work_log_{datetime.now().strftime('%Y%m%d')}.md", 'w', encoding='utf-8') as f:
            f.write(log_content)
    
    def _summarize_error_logs(self):
        """ã‚¨ãƒ©ãƒ¼ãƒ­ã‚°è¦ç´„"""
        error_files = glob.glob("*error*.log") + glob.glob("*exception*.log")
        if error_files:
            return f"{len(error_files)}ä»¶ã®ã‚¨ãƒ©ãƒ¼ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ç™ºè¦‹"
        return "ã‚¨ãƒ©ãƒ¼ãƒ­ã‚°ãªã—"
    
    def _generate_performance_stats(self):
        """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹çµ±è¨ˆç”Ÿæˆ"""
        stats = {
            "files_processed": len(glob.glob("**/*.py", recursive=True)),
            "total_size_mb": sum(os.path.getsize(f) for f in glob.glob("**/*", recursive=True) if os.path.isfile(f)) / 1024**2,
            "session_duration": datetime.now() - self.results["start_time"]
        }
        
        with open(f"performance_stats_{datetime.now().strftime('%Y%m%d')}.json", 'w') as f:
            json.dump({
                "date": datetime.now().isoformat(),
                "stats": {
                    "files_processed": stats["files_processed"],
                    "total_size_mb": round(stats["total_size_mb"], 1),
                    "session_duration_minutes": round(stats["session_duration"].total_seconds() / 60, 1)
                }
            }, f, indent=2)
        
        return True
    
    def _prepare_startup_script(self):
        """èµ·å‹•ã‚¹ã‚¯ãƒªãƒ—ãƒˆæº–å‚™"""
        startup_script = f"""#!/bin/bash
# Claude Code è‡ªå‹•èµ·å‹•ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
# ç”Ÿæˆæ—¥æ™‚: {datetime.now().isoformat()}

echo "ğŸš€ Claude Codeç’°å¢ƒã‚’æº–å‚™ä¸­..."

# ç’°å¢ƒå¤‰æ•°èª­ã¿è¾¼ã¿
if [ -f .env ]; then
    export $(cat .env | grep -v '^#' | xargs)
fi

# Pythonç’°å¢ƒç¢ºèª
python3 --version

# ä¾å­˜é–¢ä¿‚ç¢ºèª
if [ -f requirements.txt ]; then
    echo "ğŸ“¦ ä¾å­˜é–¢ä¿‚ã‚’ç¢ºèªä¸­..."
    pip check
fi

# ã‚»ãƒƒã‚·ãƒ§ãƒ³å¾©å…ƒç¢ºèª
echo "ğŸ”„ å‰å›ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’ãƒã‚§ãƒƒã‚¯ä¸­..."
if python3 -c "from auto_handover_check import auto_check_handover; auto_check_handover()"; then
    echo "âœ… å‰å›ã‚»ãƒƒã‚·ãƒ§ãƒ³æƒ…å ±ã‚’è¡¨ç¤ºã—ã¾ã—ãŸ"
fi

echo "âœ… æº–å‚™å®Œäº†ï¼Claude Codeã‚’é–‹å§‹ã—ã¦ãã ã•ã„"
"""
        
        with open('claude_startup.sh', 'w') as f:
            f.write(startup_script)
        
        os.chmod('claude_startup.sh', 0o755)
    
    def _optimize_configurations(self):
        """è¨­å®šæœ€é©åŒ–"""
        optimizations = []
        
        # Gitè¨­å®šã®ç¢ºèª
        try:
            result = subprocess.run(['git', 'config', '--get', 'user.name'], 
                                  capture_output=True, text=True)
            if result.returncode != 0:
                optimizations.append("Gitè¨­å®šè¦ç¢ºèª")
        except:
            pass
        
        # Pythonç’°å¢ƒã®æœ€é©åŒ–
        if os.path.exists('requirements.txt'):
            optimizations.append("requirements.txt ç¢ºèªæ¸ˆã¿")
        
        return f"{len(optimizations)}é …ç›®æœ€é©åŒ–"
    
    def _preload_dependencies(self):
        """ä¾å­˜é–¢ä¿‚äº‹å‰æº–å‚™"""
        preloaded = []
        
        # ã‚ˆãä½¿ã†ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®äº‹å‰ã‚¤ãƒ³ãƒãƒ¼ãƒˆãƒ†ã‚¹ãƒˆ
        test_imports = ['requests', 'json', 'os', 'datetime']
        for lib in test_imports:
            try:
                __import__(lib)
                preloaded.append(lib)
            except:
                self.results["warnings"].append(f"âš ï¸ ãƒ©ã‚¤ãƒ–ãƒ©ãƒª {lib} ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“")
        
        return f"{len(preloaded)}/{len(test_imports)}ãƒ©ã‚¤ãƒ–ãƒ©ãƒªåˆ©ç”¨å¯èƒ½"
    
    def _generate_complete_report(self):
        """å®Œå…¨ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ"""
        end_time = datetime.now()
        duration = end_time - self.results["start_time"]
        
        report = f"""# å®Œå…¨ç‰ˆä½œæ¥­çµ‚äº†æ™‚æ•´ç†ãƒ¬ãƒãƒ¼ãƒˆ

**å®Ÿè¡Œæ—¥æ™‚**: {end_time.strftime('%Yå¹´%mæœˆ%dæ—¥ %H:%M:%S')}  
**å‡¦ç†æ™‚é–“**: {duration.total_seconds():.1f}ç§’

## å®Ÿè¡Œçµæœ

### âœ… å®Œäº†ã—ãŸã‚¢ã‚¯ã‚·ãƒ§ãƒ³ ({len(self.results['actions'])}ä»¶)
"""
        
        for action in self.results["actions"]:
            report += f"- {action}\n"
        
        if self.results["warnings"]:
            report += f"\n### âš ï¸ æ³¨æ„äº‹é … ({len(self.results['warnings'])}ä»¶)\n"
            for warning in self.results["warnings"]:
                report += f"- {warning}\n"
        
        if self.results["errors"]:
            report += f"\n### âŒ ã‚¨ãƒ©ãƒ¼ ({len(self.results['errors'])}ä»¶)\n"
            for error in self.results["errors"]:
                report += f"- {error}\n"
        
        report += f"""

## æ¬¡å›èµ·å‹•æ™‚ã®æº–å‚™

### ã‚¯ã‚¤ãƒƒã‚¯ã‚¹ã‚¿ãƒ¼ãƒˆ
1. `./claude_startup.sh` ã‚’å®Ÿè¡Œï¼ˆæ¨å¥¨ï¼‰
2. ã¾ãŸã¯ã€Œå‰å›ã®ç¶šãã‹ã‚‰ã‚„ã‚ŠãŸã„ã€

### ã‚·ã‚¹ãƒ†ãƒ çŠ¶æ…‹
- âœ… ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒã‚§ãƒƒã‚¯å®Œäº†
- âœ… ãƒ‡ãƒ¼ã‚¿ä¿è­·å®Œäº†
- âœ… ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–å®Œäº†
- âœ… ä½œæ¥­ç¶™ç¶šæ€§ç¢ºèªå®Œäº†
- âœ… ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæ›´æ–°å®Œäº†
- âœ… æ¬¡å›æº–å‚™å®Œäº†

---
**è‡ªå‹•ç”Ÿæˆ**: Claude Code å®Œå…¨ç‰ˆè‡ªå‹•æ•´ç†ã‚·ã‚¹ãƒ†ãƒ  v2.0
"""
        
        report_file = f"complete_cleanup_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.md"
        with open(report_file, 'w', encoding='utf-8') as f:
            f.write(report)
        
        print(f"\nğŸ“„ å®Œå…¨ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ: {report_file}")
        print(f"â±ï¸ å‡¦ç†æ™‚é–“: {duration.total_seconds():.1f}ç§’")
        print(f"âœ… ã‚¢ã‚¯ã‚·ãƒ§ãƒ³: {len(self.results['actions'])}ä»¶")
        if self.results["warnings"]:
            print(f"âš ï¸ æ³¨æ„äº‹é …: {len(self.results['warnings'])}ä»¶")

def complete_auto_cleanup():
    """å®Œå…¨ç‰ˆè‡ªå‹•æ•´ç†ã®å®Ÿè¡Œ"""
    cleanup_system = CompleteAutoCleanup()
    cleanup_system.execute_complete_cleanup()

if __name__ == "__main__":
    complete_auto_cleanup()