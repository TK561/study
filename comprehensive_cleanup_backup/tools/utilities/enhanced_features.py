#!/usr/bin/env python3
"""
çµ±åˆã‚·ã‚¹ãƒ†ãƒ å¼·åŒ–æ©Ÿèƒ½
Geminiã¨ã®ç›¸è«‡ã§æ˜ã‚‰ã‹ã«ãªã£ãŸæ”¹å–„ç‚¹ã‚’å®Ÿè£…
"""

import os
import json
import time
from datetime import datetime, timedelta
from typing import Dict, List
from collections import defaultdict

class WorkflowAnalyzer:
    """ä½œæ¥­ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æãƒ»æœ€é©åŒ–ã‚¨ãƒ³ã‚¸ãƒ³"""
    
    def __init__(self):
        self.analytics_dir = ".workflow_analytics"
        os.makedirs(self.analytics_dir, exist_ok=True)
        self.work_log_file = os.path.join(self.analytics_dir, "work_log.json")
        self.patterns_file = os.path.join(self.analytics_dir, "patterns.json")
        
    def log_work_action(self, action_type: str, details: Dict):
        """ä½œæ¥­ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚’ãƒ­ã‚°è¨˜éŒ²"""
        log_entry = {
            "timestamp": datetime.now().isoformat(),
            "action_type": action_type,
            "details": details,
            "day_of_week": datetime.now().strftime("%A"),
            "hour": datetime.now().hour
        }
        
        # ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã«è¿½è¨˜
        work_log = self._load_work_log()
        work_log.append(log_entry)
        
        # æœ€æ–°1000ä»¶ã®ã¿ä¿æŒ
        if len(work_log) > 1000:
            work_log = work_log[-1000:]
        
        with open(self.work_log_file, 'w', encoding='utf-8') as f:
            json.dump(work_log, f, ensure_ascii=False, indent=2)
    
    def analyze_work_patterns(self) -> Dict:
        """ä½œæ¥­ãƒ‘ã‚¿ãƒ¼ãƒ³ã®åˆ†æ"""
        work_log = self._load_work_log()
        
        if not work_log:
            return {"patterns": [], "insights": "ãƒ‡ãƒ¼ã‚¿ä¸è¶³"}
        
        patterns = {
            "time_patterns": self._analyze_time_patterns(work_log),
            "action_sequences": self._analyze_action_sequences(work_log),
            "efficiency_periods": self._identify_efficiency_periods(work_log),
            "common_workflows": self._extract_common_workflows(work_log)
        }
        
        return patterns
    
    def _analyze_time_patterns(self, work_log: List[Dict]) -> Dict:
        """æ™‚é–“ãƒ‘ã‚¿ãƒ¼ãƒ³ã®åˆ†æ"""
        hourly_activity = defaultdict(int)
        daily_activity = defaultdict(int)
        
        for entry in work_log:
            hour = entry["hour"]
            day = entry["day_of_week"]
            
            hourly_activity[hour] += 1
            daily_activity[day] += 1
        
        # æœ€ã‚‚æ´»ç™ºãªæ™‚é–“å¸¯
        peak_hour = max(hourly_activity.items(), key=lambda x: x[1])[0] if hourly_activity else 12
        peak_day = max(daily_activity.items(), key=lambda x: x[1])[0] if daily_activity else "Monday"
        
        return {
            "peak_hour": peak_hour,
            "peak_day": peak_day,
            "hourly_distribution": dict(hourly_activity),
            "daily_distribution": dict(daily_activity)
        }
    
    def _analyze_action_sequences(self, work_log: List[Dict]) -> List[Dict]:
        """ã‚¢ã‚¯ã‚·ãƒ§ãƒ³é †åºãƒ‘ã‚¿ãƒ¼ãƒ³ã®åˆ†æ"""
        sequences = []
        
        for i in range(len(work_log) - 1):
            current = work_log[i]
            next_action = work_log[i + 1]
            
            time_diff = (
                datetime.fromisoformat(next_action["timestamp"]) - 
                datetime.fromisoformat(current["timestamp"])
            ).total_seconds()
            
            if time_diff < 3600:  # 1æ™‚é–“ä»¥å†…ã®é€£ç¶šã‚¢ã‚¯ã‚·ãƒ§ãƒ³
                sequences.append({
                    "from": current["action_type"],
                    "to": next_action["action_type"],
                    "duration": time_diff
                })
        
        # é »å‡ºé †åºãƒ‘ã‚¿ãƒ¼ãƒ³
        sequence_counts = defaultdict(int)
        for seq in sequences:
            key = f"{seq['from']} â†’ {seq['to']}"
            sequence_counts[key] += 1
        
        common_sequences = sorted(sequence_counts.items(), key=lambda x: x[1], reverse=True)[:5]
        
        return [{"pattern": pattern, "count": count} for pattern, count in common_sequences]
    
    def _identify_efficiency_periods(self, work_log: List[Dict]) -> Dict:
        """åŠ¹ç‡çš„ãªæ™‚é–“å¸¯ã®ç‰¹å®š"""
        # ã‚¢ã‚¯ã‚·ãƒ§ãƒ³å¯†åº¦ã§åŠ¹ç‡æ€§ã‚’æ¸¬å®š
        hourly_efficiency = defaultdict(list)
        
        # 1æ™‚é–“ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã§ã®ã‚¢ã‚¯ã‚·ãƒ§ãƒ³æ•°ã‚’è¨ˆç®—
        for entry in work_log:
            hour = entry["hour"]
            hourly_efficiency[hour].append(1)
        
        efficiency_scores = {}
        for hour, actions in hourly_efficiency.items():
            efficiency_scores[hour] = len(actions)
        
        if efficiency_scores:
            best_hour = max(efficiency_scores.items(), key=lambda x: x[1])[0]
            worst_hour = min(efficiency_scores.items(), key=lambda x: x[1])[0]
        else:
            best_hour = worst_hour = 12
        
        return {
            "most_efficient_hour": best_hour,
            "least_efficient_hour": worst_hour,
            "efficiency_by_hour": efficiency_scores
        }
    
    def _extract_common_workflows(self, work_log: List[Dict]) -> List[Dict]:
        """å…±é€šãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã®æŠ½å‡º"""
        # ç°¡æ˜“å®Ÿè£…ï¼šã‚ˆãä½¿ã‚ã‚Œã‚‹ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚¿ã‚¤ãƒ—
        action_counts = defaultdict(int)
        
        for entry in work_log:
            action_counts[entry["action_type"]] += 1
        
        common_actions = sorted(action_counts.items(), key=lambda x: x[1], reverse=True)[:5]
        
        return [{"action": action, "frequency": count} for action, count in common_actions]
    
    def _load_work_log(self) -> List[Dict]:
        """ä½œæ¥­ãƒ­ã‚°ã®èª­ã¿è¾¼ã¿"""
        if os.path.exists(self.work_log_file):
            with open(self.work_log_file, 'r', encoding='utf-8') as f:
                return json.load(f)
        return []

class PerformanceTracker:
    """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹è¿½è·¡ãƒ»æœ€é©åŒ–ã‚·ã‚¹ãƒ†ãƒ """
    
    def __init__(self):
        self.metrics_file = ".workflow_analytics/performance_metrics.json"
        self.baseline_metrics = self._load_baseline_metrics()
    
    def track_session_performance(self, session_data: Dict) -> Dict:
        """ã‚»ãƒƒã‚·ãƒ§ãƒ³ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã®è¿½è·¡"""
        metrics = {
            "session_duration": self._calculate_session_duration(session_data),
            "actions_per_hour": self._calculate_actions_per_hour(session_data),
            "file_operations_ratio": self._calculate_file_ops_ratio(session_data),
            "efficiency_score": self._calculate_efficiency_score(session_data)
        }
        
        # ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã¨ã®æ¯”è¼ƒ
        improvements = self._compare_with_baseline(metrics)
        
        # ãƒ¡ãƒˆãƒªã‚¯ã‚¹ä¿å­˜
        self._save_metrics(metrics)
        
        return {
            "current_metrics": metrics,
            "improvements": improvements,
            "recommendations": self._generate_performance_recommendations(metrics)
        }
    
    def _calculate_session_duration(self, session_data: Dict) -> float:
        """ã‚»ãƒƒã‚·ãƒ§ãƒ³æ™‚é–“ã®è¨ˆç®—"""
        if not session_data.get('actions'):
            return 0
        
        start_time = datetime.fromisoformat(session_data.get('start_time', datetime.now().isoformat()))
        end_time = datetime.now()
        
        return (end_time - start_time).total_seconds() / 3600  # æ™‚é–“å˜ä½
    
    def _calculate_actions_per_hour(self, session_data: Dict) -> float:
        """æ™‚é–“ã‚ãŸã‚Šã‚¢ã‚¯ã‚·ãƒ§ãƒ³æ•°"""
        duration = self._calculate_session_duration(session_data)
        actions_count = len(session_data.get('actions', []))
        
        return actions_count / max(duration, 0.1)  # ã‚¼ãƒ­é™¤ç®—ã‚’é¿ã‘ã‚‹
    
    def _calculate_file_ops_ratio(self, session_data: Dict) -> float:
        """ãƒ•ã‚¡ã‚¤ãƒ«æ“ä½œã®å‰²åˆ"""
        actions = session_data.get('actions', [])
        if not actions:
            return 0
        
        file_ops = sum(1 for action in actions if action.get('type') == 'file_operation')
        return file_ops / len(actions)
    
    def _calculate_efficiency_score(self, session_data: Dict) -> float:
        """åŠ¹ç‡æ€§ã‚¹ã‚³ã‚¢ï¼ˆ0-10ï¼‰"""
        actions_per_hour = self._calculate_actions_per_hour(session_data)
        file_ops_ratio = self._calculate_file_ops_ratio(session_data)
        
        # ç°¡æ˜“ã‚¹ã‚³ã‚¢è¨ˆç®—
        score = min(10, (actions_per_hour * 0.5) + (file_ops_ratio * 5))
        return round(score, 1)
    
    def _compare_with_baseline(self, current_metrics: Dict) -> Dict:
        """ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã¨ã®æ¯”è¼ƒ"""
        improvements = {}
        
        for metric, current_value in current_metrics.items():
            baseline_value = self.baseline_metrics.get(metric, current_value)
            
            if baseline_value > 0:
                improvement_pct = ((current_value - baseline_value) / baseline_value) * 100
                improvements[metric] = round(improvement_pct, 1)
            else:
                improvements[metric] = 0
        
        return improvements
    
    def _generate_performance_recommendations(self, metrics: Dict) -> List[str]:
        """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æ”¹å–„ææ¡ˆ"""
        recommendations = []
        
        if metrics["actions_per_hour"] < 10:
            recommendations.append("âš¡ ä½œæ¥­ãƒšãƒ¼ã‚¹ãŒä½ä¸‹ã—ã¦ã„ã¾ã™ã€‚ä¼‘æ†©ã‚’å–ã‚‹ã‹ã€ã‚¿ã‚¹ã‚¯ã‚’ç´°åˆ†åŒ–ã—ã¦ã¿ã¦ãã ã•ã„")
        
        if metrics["file_operations_ratio"] < 0.3:
            recommendations.append("ğŸ“„ ãƒ•ã‚¡ã‚¤ãƒ«æ“ä½œãŒå°‘ãªã„ã§ã™ã€‚å®Ÿè£…ä½œæ¥­ã‚’é€²ã‚ã‚‹ã“ã¨ã‚’æ¤œè¨ã—ã¦ãã ã•ã„")
        
        if metrics["efficiency_score"] < 5:
            recommendations.append("ğŸ¯ åŠ¹ç‡æ€§ã‚¹ã‚³ã‚¢ãŒä½ã„ã§ã™ã€‚ä½œæ¥­ãƒ•ãƒ­ãƒ¼ã®è¦‹ç›´ã—ã‚’æ¨å¥¨ã—ã¾ã™")
        
        if not recommendations:
            recommendations.append("âœ… è‰¯å¥½ãªãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã§ã™ï¼ã“ã®èª¿å­ã§ç¶šã‘ã¦ãã ã•ã„")
        
        return recommendations
    
    def _load_baseline_metrics(self) -> Dict:
        """ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã®èª­ã¿è¾¼ã¿"""
        if os.path.exists(self.metrics_file):
            with open(self.metrics_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
                return data.get('baseline', {})
        
        # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³
        return {
            "session_duration": 1.0,
            "actions_per_hour": 15.0,
            "file_operations_ratio": 0.4,
            "efficiency_score": 6.0
        }
    
    def _save_metrics(self, metrics: Dict):
        """ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã®ä¿å­˜"""
        data = {"baseline": self.baseline_metrics, "latest": metrics, "updated": datetime.now().isoformat()}
        
        with open(self.metrics_file, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)

class AutomationEngine:
    """è‡ªå‹•åŒ–ã‚¨ãƒ³ã‚¸ãƒ³"""
    
    def __init__(self):
        self.automation_rules = []
        self.automation_log = []
    
    def suggest_automations(self, work_patterns: Dict) -> List[Dict]:
        """è‡ªå‹•åŒ–ææ¡ˆã®ç”Ÿæˆ"""
        suggestions = []
        
        # é »å‡ºã‚¢ã‚¯ã‚·ãƒ§ãƒ³é †åºãƒ‘ã‚¿ãƒ¼ãƒ³ã‹ã‚‰è‡ªå‹•åŒ–ã‚’ææ¡ˆ
        for sequence in work_patterns.get("action_sequences", []):
            if sequence["count"] >= 3:  # 3å›ä»¥ä¸Šã®ãƒ‘ã‚¿ãƒ¼ãƒ³
                suggestions.append({
                    "type": "sequence_automation",
                    "pattern": sequence["pattern"],
                    "frequency": sequence["count"],
                    "suggestion": f"ã€Œ{sequence['pattern']}ã€ã®è‡ªå‹•åŒ–ã‚’æ¤œè¨",
                    "estimated_time_saved": sequence["count"] * 2  # åˆ†å˜ä½
                })
        
        # æ™‚é–“ãƒ‘ã‚¿ãƒ¼ãƒ³ã‹ã‚‰é€šçŸ¥ææ¡ˆ
        time_patterns = work_patterns.get("time_patterns", {})
        if time_patterns.get("peak_hour"):
            suggestions.append({
                "type": "time_optimization",
                "peak_hour": time_patterns["peak_hour"],
                "suggestion": f"{time_patterns['peak_hour']}æ™‚ãŒæœ€ã‚‚æ´»ç™ºã§ã™ã€‚é‡è¦ãªä½œæ¥­ã‚’ã“ã®æ™‚é–“ã«é›†ä¸­ã•ã›ã‚‹ã“ã¨ã‚’æ¨å¥¨",
                "estimated_productivity_gain": "15-20%"
            })
        
        return suggestions
    
    def implement_automation(self, automation_config: Dict):
        """è‡ªå‹•åŒ–ã®å®Ÿè£…"""
        # å®Ÿéš›ã®è‡ªå‹•åŒ–å®Ÿè£…ã¯ã“ã“ã§è¡Œã†
        self.automation_rules.append(automation_config)
        
        log_entry = {
            "timestamp": datetime.now().isoformat(),
            "automation": automation_config,
            "status": "implemented"
        }
        self.automation_log.append(log_entry)

# çµ±åˆæ©Ÿèƒ½ã®ãƒ†ã‚¹ãƒˆç”¨é–¢æ•°
def test_enhanced_features():
    """å¼·åŒ–æ©Ÿèƒ½ã®ãƒ†ã‚¹ãƒˆ"""
    print("ğŸ§ª å¼·åŒ–æ©Ÿèƒ½ãƒ†ã‚¹ãƒˆé–‹å§‹")
    
    # ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼åˆ†æãƒ†ã‚¹ãƒˆ
    analyzer = WorkflowAnalyzer()
    
    # ã‚µãƒ³ãƒ—ãƒ«ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚’ãƒ­ã‚°
    sample_actions = [
        {"action_type": "file_create", "details": {"file": "test1.py"}},
        {"action_type": "file_edit", "details": {"file": "test1.py"}},
        {"action_type": "consultation", "details": {"query": "ãƒ†ã‚¹ãƒˆç›¸è«‡"}},
        {"action_type": "file_create", "details": {"file": "test2.py"}}
    ]
    
    for action in sample_actions:
        analyzer.log_work_action(action["action_type"], action["details"])
        time.sleep(0.1)  # æ™‚é–“å·®ã‚’ã¤ã‘ã‚‹
    
    # ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æ
    patterns = analyzer.analyze_work_patterns()
    print(f"ğŸ“Š åˆ†æçµæœ: {len(patterns.get('action_sequences', []))}å€‹ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æ¤œå‡º")
    
    # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹è¿½è·¡ãƒ†ã‚¹ãƒˆ
    tracker = PerformanceTracker()
    
    session_data = {
        "start_time": (datetime.now() - timedelta(hours=1)).isoformat(),
        "actions": sample_actions
    }
    
    performance = tracker.track_session_performance(session_data)
    print(f"âš¡ åŠ¹ç‡æ€§ã‚¹ã‚³ã‚¢: {performance['current_metrics']['efficiency_score']}/10")
    
    # è‡ªå‹•åŒ–ææ¡ˆãƒ†ã‚¹ãƒˆ
    automation = AutomationEngine()
    suggestions = automation.suggest_automations(patterns)
    print(f"ğŸ¤– è‡ªå‹•åŒ–ææ¡ˆ: {len(suggestions)}ä»¶")
    
    return {
        "patterns": patterns,
        "performance": performance,
        "automation_suggestions": suggestions
    }

if __name__ == "__main__":
    results = test_enhanced_features()
    print("\nâœ… å¼·åŒ–æ©Ÿèƒ½ãƒ†ã‚¹ãƒˆå®Œäº†")