#!/usr/bin/env python3
"""
è‡ªå‹•æ•´ç†ãƒ»ä¿å­˜ã‚·ã‚¹ãƒ†ãƒ 
ã€Œãƒ•ã‚¡ã‚¤ãƒ«ã¨ãƒ•ã‚©ãƒ«ãƒ€æ•´ç†ã€ã€Œã‚„ã£ãŸã“ã¨ã®ä¿å­˜ã€ã®ã©ã¡ã‚‰ã®è¦æ±‚ã§ã‚‚ä¸¡æ–¹ã‚’è‡ªå‹•å®Ÿè¡Œ
"""

import os
import shutil
import json
from datetime import datetime
from pathlib import Path
from collections import defaultdict
import subprocess

class AutoOrganizeAndSave:
    def __init__(self):
        self.name = "è‡ªå‹•æ•´ç†ãƒ»ä¿å­˜ã‚·ã‚¹ãƒ†ãƒ "
        self.version = "1.0.0"
        self.root_path = Path("/mnt/c/Desktop/Research")
        self.timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # ä»Šæ—¥ã®æ—¥ä»˜
        self.today = datetime.now().strftime("%Y-%m-%d")
        
        # æ•´ç†ãƒ»ä¿å­˜ã®å®Ÿè¡Œãƒ­ã‚°
        self.execution_log = {
            "timestamp": datetime.now().isoformat(),
            "actions_performed": [],
            "files_organized": [],
            "files_saved": [],
            "backup_created": [],
            "errors": []
        }
        
    def detect_user_intent(self, user_request=""):
        """ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è¦æ±‚ã‚’è§£æžã—ã€å®Ÿè¡Œã™ã¹ãã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚’æ±ºå®š"""
        # ã©ã¡ã‚‰ã®è¦æ±‚ã§ã‚‚ä¸¡æ–¹å®Ÿè¡Œã™ã‚‹ãŒã€å„ªå…ˆåº¦ã‚’æ±ºå®š
        keywords_organize = ["æ•´ç†", "ãƒ•ã‚¡ã‚¤ãƒ«", "ãƒ•ã‚©ãƒ«ãƒ€", "å‰Šé™¤", "cleanup", "organize"]
        keywords_save = ["ä¿å­˜", "è¨˜éŒ²", "ã‚„ã£ãŸã“ã¨", "ä½œæ¥­", "save", "è¨˜éŒ²"]
        
        organize_priority = any(keyword in user_request for keyword in keywords_organize)
        save_priority = any(keyword in user_request for keyword in keywords_save)
        
        # ä¸¡æ–¹å®Ÿè¡Œã™ã‚‹ãŒã€é †åºã‚’æ±ºå®š
        if organize_priority and save_priority:
            return "both_equal"  # ä¸¡æ–¹åŒå„ªå…ˆåº¦
        elif organize_priority:
            return "organize_first"  # æ•´ç†å„ªå…ˆ
        elif save_priority:
            return "save_first"  # ä¿å­˜å„ªå…ˆ
        else:
            return "both_equal"  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯ä¸¡æ–¹å®Ÿè¡Œ
    
    def quick_organize_files(self):
        """ãƒ•ã‚¡ã‚¤ãƒ«ãƒ»ãƒ•ã‚©ãƒ«ãƒ€ã®ã‚¯ã‚¤ãƒƒã‚¯æ•´ç†"""
        print("ðŸ§¹ ãƒ•ã‚¡ã‚¤ãƒ«ãƒ»ãƒ•ã‚©ãƒ«ãƒ€è‡ªå‹•æ•´ç†é–‹å§‹...")
        
        # ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
        backup_dir = self.root_path / f"auto_backup_{self.timestamp}"
        backup_dir.mkdir(exist_ok=True)
        
        # æ•´ç†å¯¾è±¡ã®ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ãƒ»ãƒ•ã‚©ãƒ«ãƒ€ã‚’å®šç¾©
        temp_items = [
            # ä¸€æ™‚çš„ãªPythonãƒ•ã‚¡ã‚¤ãƒ«
            "temp_*.py",
            "test_*.py", 
            "*_temp.py",
            "*_backup.py",
            # ä¸€æ™‚çš„ãªJSONãƒ•ã‚¡ã‚¤ãƒ«  
            "temp_*.json",
            "*_temp.json",
            # é‡è¤‡ãƒ»å¤ã„ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—
            "old_*",
            "*_old.*",
            # ç©ºã®cacheãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
            "cache",
            "__pycache__",
            # ä¸€æ™‚çš„ãªãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«
            "*.tmp",
            "*.log.old"
        ]
        
        organized_count = 0
        
        # systemç›´ä¸‹ã®ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒã‚§ãƒƒã‚¯
        system_dir = self.root_path / "system"
        if system_dir.exists():
            for item in system_dir.iterdir():
                if item.name.startswith(("temp_", "test_", "old_")) and item.is_file():
                    try:
                        # ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—
                        backup_target = backup_dir / "system" / item.name
                        backup_target.parent.mkdir(parents=True, exist_ok=True)
                        shutil.copy2(item, backup_target)
                        
                        # å‰Šé™¤
                        item.unlink()
                        organized_count += 1
                        self.execution_log["files_organized"].append(str(item.relative_to(self.root_path)))
                        print(f"  âœ… å‰Šé™¤: {item.relative_to(self.root_path)}")
                    except Exception as e:
                        self.execution_log["errors"].append(f"æ•´ç†ã‚¨ãƒ©ãƒ¼ {item.name}: {e}")
        
        # ç©ºãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®å‰Šé™¤
        self._remove_empty_directories()
        
        # é‡è¤‡ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ•ã‚©ãƒ«ãƒ€ã®çµ±åˆ
        self._consolidate_backup_folders()
        
        print(f"âœ… ãƒ•ã‚¡ã‚¤ãƒ«æ•´ç†å®Œäº†: {organized_count}ä»¶å‡¦ç†")
        self.execution_log["actions_performed"].append(f"ãƒ•ã‚¡ã‚¤ãƒ«æ•´ç†: {organized_count}ä»¶")
        
        return organized_count
    
    def _remove_empty_directories(self):
        """ç©ºãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’å‰Šé™¤"""
        removed_dirs = []
        
        # ä¿è­·ã™ã¹ããƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
        protected_dirs = [
            "system/implementations",
            "study", 
            "sessions",
            "public",
            "config",
            "logs"
        ]
        
        for root, dirs, files in os.walk(self.root_path, topdown=False):
            for dir_name in dirs:
                dir_path = Path(root) / dir_name
                try:
                    # ç©ºã‹ã¤ä¿è­·å¯¾è±¡å¤–ã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’å‰Šé™¤
                    if not any(dir_path.iterdir()):
                        rel_path = dir_path.relative_to(self.root_path)
                        if not any(str(rel_path).startswith(protected) for protected in protected_dirs):
                            dir_path.rmdir()
                            removed_dirs.append(str(rel_path))
                except:
                    pass
        
        if removed_dirs:
            print(f"  ðŸ—‚ï¸ ç©ºãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå‰Šé™¤: {len(removed_dirs)}ä»¶")
            self.execution_log["files_organized"].extend(removed_dirs)
    
    def _consolidate_backup_folders(self):
        """é‡è¤‡ã™ã‚‹ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ•ã‚©ãƒ«ãƒ€ã‚’çµ±åˆ"""
        backup_folders = [
            "quick_backup",
            "cleanup_archive", 
            "comprehensive_cleanup_backup"
        ]
        
        # çµ±åˆãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ•ã‚©ãƒ«ãƒ€ã‚’ä½œæˆ
        consolidated_backup = self.root_path / "consolidated_backups"
        
        for folder_name in backup_folders:
            folder_path = self.root_path / folder_name
            if folder_path.exists() and folder_path.is_dir():
                # çµ±åˆå…ˆã«ã‚³ãƒ”ãƒ¼
                target_path = consolidated_backup / folder_name
                if not target_path.exists():
                    try:
                        shutil.copytree(folder_path, target_path)
                        print(f"  ðŸ“¦ ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—çµ±åˆ: {folder_name}")
                    except Exception as e:
                        self.execution_log["errors"].append(f"ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—çµ±åˆã‚¨ãƒ©ãƒ¼ {folder_name}: {e}")
    
    def auto_save_session_work(self):
        """ä»Šæ—¥ã®ä½œæ¥­ã‚’è‡ªå‹•ä¿å­˜"""
        print("ðŸ’¾ ã‚»ãƒƒã‚·ãƒ§ãƒ³ä½œæ¥­è‡ªå‹•ä¿å­˜é–‹å§‹...")
        
        # ä»Šæ—¥ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç”Ÿæˆ
        session_file = self.root_path / "sessions" / f"AUTO_SESSION_SAVE_{self.today}.md"
        
        # git statusã¨diffã§å¤‰æ›´å†…å®¹ã‚’å–å¾—
        changes_info = self._get_git_changes()
        
        # ä»Šæ—¥ä½œæˆãƒ»æ›´æ–°ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¤œç´¢
        recent_files = self._find_recent_files()
        
        # ã‚·ã‚¹ãƒ†ãƒ å‡ºåŠ›çµæžœã‚’åŽé›†
        system_outputs = self._collect_system_outputs()
        
        # ã‚»ãƒƒã‚·ãƒ§ãƒ³ä¿å­˜å†…å®¹ã‚’ç”Ÿæˆ
        session_content = self._generate_session_content(changes_info, recent_files, system_outputs)
        
        # ã‚»ãƒƒã‚·ãƒ§ãƒ³ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜
        with open(session_file, 'w', encoding='utf-8') as f:
            f.write(session_content)
        
        self.execution_log["files_saved"].append(str(session_file.relative_to(self.root_path)))
        print(f"âœ… ã‚»ãƒƒã‚·ãƒ§ãƒ³ä¿å­˜å®Œäº†: {session_file.name}")
        
        # è¿½åŠ ã§é‡è¦ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—
        self._backup_important_files()
        
        return str(session_file)
    
    def _get_git_changes(self):
        """Gitå¤‰æ›´æƒ…å ±ã‚’å–å¾—"""
        try:
            # git status
            status_result = subprocess.run(
                ["git", "status", "--porcelain"], 
                cwd=self.root_path, 
                capture_output=True, 
                text=True
            )
            
            # git diff (staged and unstaged)
            diff_result = subprocess.run(
                ["git", "diff", "HEAD"], 
                cwd=self.root_path,
                capture_output=True, 
                text=True
            )
            
            return {
                "status": status_result.stdout if status_result.returncode == 0 else "Git statuså–å¾—å¤±æ•—",
                "diff_summary": f"{len(diff_result.stdout.splitlines())}è¡Œã®å¤‰æ›´" if diff_result.returncode == 0 else "Git diffå–å¾—å¤±æ•—"
            }
        except Exception as e:
            return {"status": f"Gitæƒ…å ±å–å¾—ã‚¨ãƒ©ãƒ¼: {e}", "diff_summary": "å–å¾—å¤±æ•—"}
    
    def _find_recent_files(self):
        """ä»Šæ—¥ä½œæˆãƒ»æ›´æ–°ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¤œç´¢"""
        recent_files = []
        today_start = datetime.now().replace(hour=0, minute=0, second=0, microsecond=0)
        
        for root, dirs, files in os.walk(self.root_path):
            for file in files:
                file_path = Path(root) / file
                try:
                    mtime = datetime.fromtimestamp(file_path.stat().st_mtime)
                    if mtime >= today_start:
                        rel_path = file_path.relative_to(self.root_path)
                        recent_files.append({
                            "path": str(rel_path),
                            "modified": mtime.strftime("%H:%M:%S")
                        })
                except:
                    pass
        
        # æ›´æ–°æ™‚åˆ»ã§ã‚½ãƒ¼ãƒˆ
        recent_files.sort(key=lambda x: x["modified"], reverse=True)
        return recent_files[:20]  # æœ€æ–°20ä»¶
    
    def _collect_system_outputs(self):
        """ã‚·ã‚¹ãƒ†ãƒ å‡ºåŠ›çµæžœã‚’åŽé›†"""
        output_dir = self.root_path / "system" / "implementations" / "output"
        outputs = {
            "benchmarks": [],
            "detections": [], 
            "integrated_research": [],
            "visualizations": [],
            "dataset_selections": [],
            "realtime_processing": []
        }
        
        if output_dir.exists():
            for category in outputs.keys():
                category_dir = output_dir / category
                if category_dir.exists():
                    for file in category_dir.iterdir():
                        if file.is_file():
                            outputs[category].append({
                                "name": file.name,
                                "size": f"{file.stat().st_size // 1024}KB" if file.stat().st_size > 1024 else f"{file.stat().st_size}B"
                            })
        
        return outputs
    
    def _generate_session_content(self, changes_info, recent_files, system_outputs):
        """ã‚»ãƒƒã‚·ãƒ§ãƒ³ä¿å­˜å†…å®¹ã‚’ç”Ÿæˆ"""
        content = f"""# ðŸ”„ è‡ªå‹•ã‚»ãƒƒã‚·ãƒ§ãƒ³ä¿å­˜ - {self.today}

## ðŸ“… ä¿å­˜æƒ…å ±
- **ä¿å­˜æ—¥æ™‚**: {datetime.now().strftime('%Yå¹´%mæœˆ%dæ—¥ %H:%M:%S')}
- **ä¿å­˜ã‚·ã‚¹ãƒ†ãƒ **: {self.name} v{self.version}
- **ä¿å­˜ãƒˆãƒªã‚¬ãƒ¼**: è‡ªå‹•å®Ÿè¡Œ

## ðŸ“Š Gitå¤‰æ›´çŠ¶æ³
```
{changes_info['status']}
```
- **å¤‰æ›´ã‚µãƒžãƒªãƒ¼**: {changes_info['diff_summary']}

## ðŸ“ ä»Šæ—¥æ›´æ–°ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ« ({len(recent_files)}ä»¶)
"""
        
        for file_info in recent_files[:10]:  # ä¸Šä½10ä»¶è¡¨ç¤º
            content += f"- `{file_info['path']}` (æ›´æ–°: {file_info['modified']})\n"
        
        if len(recent_files) > 10:
            content += f"- ... ä»–{len(recent_files) - 10}ä»¶\n"
        
        content += f"""
## ðŸ”§ ã‚·ã‚¹ãƒ†ãƒ å‡ºåŠ›çµæžœ
"""
        
        for category, files in system_outputs.items():
            if files:
                content += f"""
### {category.replace('_', ' ').title()} ({len(files)}ä»¶)
"""
                for file_info in files[:5]:  # å„ã‚«ãƒ†ã‚´ãƒªä¸Šä½5ä»¶
                    content += f"- `{file_info['name']}` ({file_info['size']})\n"
                if len(files) > 5:
                    content += f"- ... ä»–{len(files) - 5}ä»¶\n"
        
        content += f"""
## ðŸŽ¯ å®Ÿè¡Œã•ã‚ŒãŸã‚¢ã‚¯ã‚·ãƒ§ãƒ³
"""
        for action in self.execution_log["actions_performed"]:
            content += f"- âœ… {action}\n"
        
        content += f"""
## ðŸ’¾ ä¿å­˜ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«
"""
        for file in self.execution_log["files_saved"]:
            content += f"- ðŸ“„ {file}\n"
        
        content += f"""
## ðŸ—‘ï¸ æ•´ç†ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«
"""
        for file in self.execution_log["files_organized"]:
            content += f"- ðŸ§¹ {file}\n"
        
        if self.execution_log["errors"]:
            content += f"""
## âš ï¸ ã‚¨ãƒ©ãƒ¼ãƒ»è­¦å‘Š
"""
            for error in self.execution_log["errors"]:
                content += f"- âŒ {error}\n"
        
        content += f"""
## ðŸ“‹ æ¬¡å›žã‚»ãƒƒã‚·ãƒ§ãƒ³å¼•ãç¶™ãŽäº‹é …
- **é‡è¦ãƒ•ã‚¡ã‚¤ãƒ«**: è‡ªå‹•ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—æ¸ˆã¿
- **ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ§‹é€ **: æœ€é©åŒ–å®Œäº†
- **ã‚·ã‚¹ãƒ†ãƒ å‡ºåŠ›**: å…¨ã¦ä¿æŒ
- **ä½œæ¥­ç¶™ç¶š**: æº–å‚™å®Œäº†

---
*è‡ªå‹•ä¿å­˜ã‚·ã‚¹ãƒ†ãƒ ã«ã‚ˆã‚Šç”Ÿæˆ - {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}*
"""
        
        return content
    
    def _backup_important_files(self):
        """é‡è¦ãƒ•ã‚¡ã‚¤ãƒ«ã®è‡ªå‹•ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—"""
        important_files = [
            "CLAUDE.md",
            "README.md", 
            "WordNet-Based_Semantic_Image_Classification_Research_Presentation.pptx",
            "system/implementations/integrated_research_system.py",
            "study/research_discussions/WEEKLY_DISCUSSION_SUMMARY.md"
        ]
        
        backup_dir = self.root_path / f"important_backup_{self.timestamp}"
        backup_dir.mkdir(exist_ok=True)
        
        for file_path in important_files:
            source = self.root_path / file_path
            if source.exists():
                target = backup_dir / file_path
                target.parent.mkdir(parents=True, exist_ok=True)
                try:
                    shutil.copy2(source, target)
                    self.execution_log["backup_created"].append(file_path)
                except Exception as e:
                    self.execution_log["errors"].append(f"ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚¨ãƒ©ãƒ¼ {file_path}: {e}")
        
        # Obsidianãƒœãƒ«ãƒˆã®ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—
        obsidian_path = Path("/mnt/c/Desktop/Obsidian/study")
        if obsidian_path.exists():
            print("  ðŸ“š Obsidianãƒœãƒ«ãƒˆã®ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—é–‹å§‹...")
            obsidian_backup_dir = backup_dir / "Obsidian_Vault_Backup"
            obsidian_backup_dir.mkdir(exist_ok=True)
            
            # é‡è¦ãªObsidianãƒ•ã‚¡ã‚¤ãƒ«ã®ã¿ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—
            obsidian_important = [
                "Research/WordNet-Based Semantic Image Classification.md",
                "Research/Weekly-Discussion-Summary.md",
                "Research/Research Index.md",
                "Daily/2025-07-02.md",
                "Research MOC.md",
                "Study MOC.md",
                "Naming-Convention-Guide.md",
                ".obsidian/app.json",
                ".obsidian/core-plugins.json"
            ]
            
            for file_path in obsidian_important:
                source = obsidian_path / file_path
                if source.exists():
                    target = obsidian_backup_dir / file_path
                    target.parent.mkdir(parents=True, exist_ok=True)
                    try:
                        shutil.copy2(source, target)
                        self.execution_log["backup_created"].append(f"Obsidian/{file_path}")
                    except Exception as e:
                        self.execution_log["errors"].append(f"Obsidianãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚¨ãƒ©ãƒ¼ {file_path}: {e}")
            
            print(f"  ðŸ“š Obsidianãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—å®Œäº†")
        
        print(f"  ðŸ’¾ é‡è¦ãƒ•ã‚¡ã‚¤ãƒ«ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—: {len(self.execution_log['backup_created'])}ä»¶")
    
    def execute_auto_organize_and_save(self, user_request=""):
        """è‡ªå‹•æ•´ç†ãƒ»ä¿å­˜ã®å®Ÿè¡Œ"""
        print("ðŸš€ è‡ªå‹•æ•´ç†ãƒ»ä¿å­˜ã‚·ã‚¹ãƒ†ãƒ  èµ·å‹•")
        print("=" * 60)
        
        # ãƒ¦ãƒ¼ã‚¶ãƒ¼æ„å›³ã®è§£æž
        intent = self.detect_user_intent(user_request)
        print(f"ðŸ“‹ æ¤œå‡ºã•ã‚ŒãŸè¦æ±‚: {intent}")
        
        # ã©ã®è¦æ±‚ã§ã‚‚å¸¸ã«æ•´ç†â†’ä¿å­˜ã®é †åºã§å®Ÿè¡Œ
        print("\nðŸ“ å®Ÿè¡Œé †åº: ãƒ•ã‚¡ã‚¤ãƒ«æ•´ç† â†’ ã‚»ãƒƒã‚·ãƒ§ãƒ³ä¿å­˜")
        organized_count = self.quick_organize_files()
        session_file = self.auto_save_session_work()
        
        # å®Ÿè¡Œãƒ­ã‚°ã®ä¿å­˜
        log_file = self.root_path / f"auto_execution_log_{self.timestamp}.json"
        with open(log_file, 'w', encoding='utf-8') as f:
            json.dump(self.execution_log, f, ensure_ascii=False, indent=2)
        
        # å®Œäº†ã‚µãƒžãƒªãƒ¼
        print("\n" + "=" * 60)
        print("ðŸŽ‰ è‡ªå‹•æ•´ç†ãƒ»ä¿å­˜å®Œäº†")
        print("=" * 60)
        print("ðŸ“Š å®Ÿè¡Œã‚µãƒžãƒªãƒ¼:")
        print(f"  ðŸ§¹ æ•´ç†: {organized_count}ä»¶å‡¦ç†")
        print(f"  ðŸ’¾ ä¿å­˜: {len(self.execution_log['files_saved'])}ä»¶")
        print(f"  ðŸ“¦ ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—: {len(self.execution_log['backup_created'])}ä»¶") 
        print(f"  âš ï¸ ã‚¨ãƒ©ãƒ¼: {len(self.execution_log['errors'])}ä»¶")
        print(f"\nðŸ“„ è©³ç´°ãƒ­ã‚°: {log_file.name}")
        
        print(f"ðŸ“‹ ã‚»ãƒƒã‚·ãƒ§ãƒ³è¨˜éŒ²: {Path(session_file).name}")
        
        print("\nâœ… æ¬¡å›žã¯ã€Œãƒ•ã‚¡ã‚¤ãƒ«ã¨ãƒ•ã‚©ãƒ«ãƒ€æ•´ç†ã€ã€Œã‚„ã£ãŸã“ã¨ã®ä¿å­˜ã€ã©ã¡ã‚‰ã®è¦æ±‚ã§ã‚‚è‡ªå‹•å®Ÿè¡Œã•ã‚Œã¾ã™")
        
        return {
            "organized_files": organized_count,
            "saved_files": len(self.execution_log["files_saved"]),
            "backup_files": len(self.execution_log["backup_created"]),
            "errors": len(self.execution_log["errors"]),
            "log_file": str(log_file),
            "session_file": session_file if 'session_file' in locals() else None
        }

def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    organizer = AutoOrganizeAndSave()
    
    # ã‚³ãƒžãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³å¼•æ•°ã‹ã‚‰è¦æ±‚ã‚’å–å¾—ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
    import sys
    user_request = " ".join(sys.argv[1:]) if len(sys.argv) > 1 else ""
    
    result = organizer.execute_auto_organize_and_save(user_request)
    return result

if __name__ == "__main__":
    main()