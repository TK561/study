#!/usr/bin/env python3
"""
Vercelçµ±åˆç®¡ç†ã‚·ã‚¹ãƒ†ãƒ 
å…¨ã¦ã®Vercelé–¢é€£æ©Ÿèƒ½ã‚’ä¸€å…ƒåŒ–ã—ãŸé«˜æº€è¶³åº¦ã‚·ã‚¹ãƒ†ãƒ 
"""

import os
import json
import asyncio
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Tuple
import subprocess

# æ—¢å­˜ã‚·ã‚¹ãƒ†ãƒ ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from vercel_deployment_manager import VercelDeploymentManager
from vercel_update_tracker import VercelUpdateTracker
from vercel_fix_assistant import VercelFixAssistant
from vercel_gemini_integration import VercelGeminiIntegration

class VercelUnifiedSystem:
    """
    Vercelé–¢é€£ã®å…¨æ©Ÿèƒ½ã‚’çµ±åˆã—ãŸåŒ…æ‹¬çš„ãªã‚·ã‚¹ãƒ†ãƒ 
    """
    
    def __init__(self):
        # ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆåˆæœŸåŒ–
        self.deployment_manager = VercelDeploymentManager()
        self.update_tracker = VercelUpdateTracker()
        self.fix_assistant = VercelFixAssistant()
        self.ai_integration = VercelGeminiIntegration()
        
        # çµ±åˆè¨­å®š
        self.unified_config_file = "VERCEL_UNIFIED_CONFIG.json"
        self.workflow_history_file = "VERCEL_WORKFLOW_HISTORY.json"
        self.config = self._load_unified_config()
        
        # ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼å±¥æ­´
        self.workflow_history = self._load_workflow_history()
    
    def _load_unified_config(self) -> Dict:
        """çµ±åˆè¨­å®šã‚’èª­ã¿è¾¼ã‚€"""
        if os.path.exists(self.unified_config_file):
            with open(self.unified_config_file, 'r', encoding='utf-8') as f:
                return json.load(f)
        
        # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®š
        default_config = {
            "auto_optimize": True,
            "auto_backup": True,
            "ai_analysis": True,
            "user_preferences": {
                "preferred_type": "static_html",
                "auto_fix_errors": True,
                "detailed_reports": True
            },
            "deployment_rules": {
                "require_backup": True,
                "min_success_rate": 70,
                "max_retry_attempts": 3
            }
        }
        
        self._save_unified_config(default_config)
        return default_config
    
    def _save_unified_config(self, config: Dict = None):
        """çµ±åˆè¨­å®šã‚’ä¿å­˜"""
        if config:
            self.config = config
        with open(self.unified_config_file, 'w', encoding='utf-8') as f:
            json.dump(self.config, f, ensure_ascii=False, indent=2)
    
    def _load_workflow_history(self) -> List[Dict]:
        """ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼å±¥æ­´ã‚’èª­ã¿è¾¼ã‚€"""
        if os.path.exists(self.workflow_history_file):
            with open(self.workflow_history_file, 'r', encoding='utf-8') as f:
                return json.load(f)
        return []
    
    def _save_workflow_history(self):
        """ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼å±¥æ­´ã‚’ä¿å­˜"""
        with open(self.workflow_history_file, 'w', encoding='utf-8') as f:
            json.dump(self.workflow_history, f, ensure_ascii=False, indent=2)
    
    def _record_workflow(self, action: str, result: Dict, duration: float):
        """ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚’è¨˜éŒ²"""
        workflow = {
            "timestamp": datetime.now().isoformat(),
            "action": action,
            "result": result,
            "duration_seconds": duration,
            "config_snapshot": self.config.copy()
        }
        self.workflow_history.append(workflow)
        self._save_workflow_history()
    
    async def smart_deploy_workflow(self) -> Dict:
        """
        ã‚¹ãƒãƒ¼ãƒˆãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼
        AIã¨æ—¢å­˜ã‚·ã‚¹ãƒ†ãƒ ã‚’çµ„ã¿åˆã‚ã›ãŸæœ€é©ãªãƒ‡ãƒ—ãƒ­ã‚¤ãƒ—ãƒ­ã‚»ã‚¹
        """
        start_time = datetime.now()
        print("ğŸ¯ Vercelçµ±åˆã‚¹ãƒãƒ¼ãƒˆãƒ‡ãƒ—ãƒ­ã‚¤ã‚’é–‹å§‹")
        print("=" * 60)
        
        result = {
            "workflow_id": f"workflow_{datetime.now().strftime('%Y%m%d_%H%M%S')}",
            "steps": [],
            "success": False,
            "satisfaction_score": None
        }
        
        try:
            # Step 1: ç’°å¢ƒè¨ºæ–­
            print("\nğŸ“‹ Step 1: ç’°å¢ƒè¨ºæ–­")
            diagnosis = self._diagnose_environment()
            result["steps"].append({
                "name": "ç’°å¢ƒè¨ºæ–­",
                "status": "completed",
                "details": diagnosis
            })
            
            # Step 2: AIåˆ†æï¼ˆæœ‰åŠ¹ãªå ´åˆï¼‰
            if self.config["ai_analysis"]:
                print("\nğŸ¤– Step 2: AIåˆ†æ")
                ai_result = await self._ai_analysis_step()
                result["steps"].append({
                    "name": "AIåˆ†æ",
                    "status": "completed",
                    "details": ai_result
                })
            
            # Step 3: è‡ªå‹•æœ€é©åŒ–
            if self.config["auto_optimize"]:
                print("\nğŸ”§ Step 3: è‡ªå‹•æœ€é©åŒ–")
                optimization = self._optimize_configuration()
                result["steps"].append({
                    "name": "æ§‹æˆæœ€é©åŒ–",
                    "status": "completed",
                    "details": optimization
                })
            
            # Step 4: ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—
            if self.config["auto_backup"]:
                print("\nğŸ’¾ Step 4: ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ä½œæˆ")
                backup = self.deployment_manager.backup_current_deployment()
                result["steps"].append({
                    "name": "ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—",
                    "status": "completed",
                    "details": {"backup_path": backup}
                })
            
            # Step 5: ãƒ‡ãƒ—ãƒ­ã‚¤å®Ÿè¡Œ
            print("\nğŸš€ Step 5: ãƒ‡ãƒ—ãƒ­ã‚¤å®Ÿè¡Œ")
            deploy_result = await self._execute_deployment()
            result["steps"].append({
                "name": "ãƒ‡ãƒ—ãƒ­ã‚¤",
                "status": "completed" if deploy_result["success"] else "failed",
                "details": deploy_result
            })
            
            if deploy_result["success"]:
                result["success"] = True
                
                # Step 6: æˆåŠŸãƒ‘ã‚¿ãƒ¼ãƒ³è¨˜éŒ²
                print("\nğŸ“ Step 6: æˆåŠŸãƒ‘ã‚¿ãƒ¼ãƒ³è¨˜éŒ²")
                pattern = self._record_success_pattern(deploy_result)
                result["steps"].append({
                    "name": "ãƒ‘ã‚¿ãƒ¼ãƒ³è¨˜éŒ²",
                    "status": "completed",
                    "details": pattern
                })
            else:
                # ã‚¨ãƒ©ãƒ¼ä¿®å¾©
                if self.config["user_preferences"]["auto_fix_errors"]:
                    print("\nğŸ”§ ã‚¨ãƒ©ãƒ¼è‡ªå‹•ä¿®å¾©")
                    fix_result = await self._auto_fix_errors(deploy_result.get("error"))
                    result["steps"].append({
                        "name": "ã‚¨ãƒ©ãƒ¼ä¿®å¾©",
                        "status": "completed" if fix_result["fixed"] else "failed",
                        "details": fix_result
                    })
            
            # Step 7: ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
            if self.config["user_preferences"]["detailed_reports"]:
                print("\nğŸ“Š Step 7: è©³ç´°ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ")
                report = self._generate_comprehensive_report(result)
                result["report"] = report
                print(report)
            
        except Exception as e:
            result["error"] = str(e)
            print(f"\nâŒ ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚¨ãƒ©ãƒ¼: {e}")
        
        # ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼è¨˜éŒ²
        duration = (datetime.now() - start_time).total_seconds()
        self._record_workflow("smart_deploy", result, duration)
        
        # ãƒ¦ãƒ¼ã‚¶ãƒ¼æº€è¶³åº¦åé›†
        if result["success"]:
            satisfaction = await self._collect_user_satisfaction(result)
            result["satisfaction_score"] = satisfaction
        
        return result
    
    def _diagnose_environment(self) -> Dict:
        """ç’°å¢ƒè¨ºæ–­"""
        diagnosis = {
            "timestamp": datetime.now().isoformat(),
            "checks": []
        }
        
        # ãƒ•ã‚¡ã‚¤ãƒ«æ§‹é€ ãƒã‚§ãƒƒã‚¯
        if os.path.exists("public/index.html"):
            diagnosis["checks"].append({
                "item": "é™çš„HTMLãƒ•ã‚¡ã‚¤ãƒ«",
                "status": "OK",
                "path": "public/index.html"
            })
        elif os.path.exists("index.html"):
            diagnosis["checks"].append({
                "item": "HTMLãƒ•ã‚¡ã‚¤ãƒ«",
                "status": "è¦ç§»å‹•",
                "path": "index.html",
                "action": "public/ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã¸ã®ç§»å‹•æ¨å¥¨"
            })
        
        # vercel.json ãƒã‚§ãƒƒã‚¯
        if os.path.exists("vercel.json"):
            with open("vercel.json", 'r') as f:
                vercel_config = json.load(f)
                if vercel_config == {"version": 2}:
                    diagnosis["checks"].append({
                        "item": "vercel.json",
                        "status": "æœ€é©",
                        "config": vercel_config
                    })
                else:
                    diagnosis["checks"].append({
                        "item": "vercel.json",
                        "status": "è¦æœ€é©åŒ–",
                        "config": vercel_config,
                        "recommendation": {"version": 2}
                    })
        
        # éå»ã®ã‚¨ãƒ©ãƒ¼ç¢ºèª
        error_count = len([h for h in self.workflow_history 
                          if not h.get("result", {}).get("success", True)
                          and h.get("timestamp", "") > 
                          (datetime.now() - timedelta(days=7)).isoformat()])
        
        diagnosis["error_rate_7days"] = error_count
        diagnosis["health_score"] = 100 - (error_count * 10)  # ã‚¨ãƒ©ãƒ¼1ä»¶ã«ã¤ã-10ç‚¹
        
        return diagnosis
    
    async def _ai_analysis_step(self) -> Dict:
        """AIåˆ†æã‚¹ãƒ†ãƒƒãƒ—"""
        current_config = {
            "type": "static_html" if os.path.exists("public/index.html") else "unknown",
            "files": self._get_deployment_files()
        }
        
        # æˆåŠŸç‡äºˆæ¸¬
        success_rate, factors = self.ai_integration.predict_deployment_success(current_config)
        
        # AIè©³ç´°åˆ†æï¼ˆå¯èƒ½ãªå ´åˆï¼‰
        ai_insights = {}
        if self.ai_integration.model:
            try:
                ai_insights = await self.ai_integration.analyze_deployment_with_ai(current_config)
            except:
                ai_insights = {"available": False}
        
        return {
            "predicted_success_rate": success_rate,
            "success_factors": factors,
            "ai_insights": ai_insights
        }
    
    def _optimize_configuration(self) -> Dict:
        """æ§‹æˆã‚’æœ€é©åŒ–"""
        optimizations = []
        
        # index.htmlã®é…ç½®æœ€é©åŒ–
        if os.path.exists("index.html") and not os.path.exists("public/index.html"):
            os.makedirs("public", exist_ok=True)
            subprocess.run(["mv", "index.html", "public/"], check=True)
            optimizations.append("index.htmlã‚’public/ã«ç§»å‹•")
        
        # vercel.jsonæœ€é©åŒ–
        optimal_vercel = {"version": 2}
        with open("vercel.json", "w") as f:
            json.dump(optimal_vercel, f, indent=2)
        optimizations.append("vercel.jsonæœ€é©åŒ–")
        
        # .gitignoreç¢ºèª
        if not os.path.exists(".gitignore"):
            with open(".gitignore", "w") as f:
                f.write(".env\n.vercel/\nnode_modules/\n")
            optimizations.append(".gitignoreä½œæˆ")
        
        return {
            "optimizations": optimizations,
            "timestamp": datetime.now().isoformat()
        }
    
    async def _execute_deployment(self) -> Dict:
        """ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆå®Ÿè¡Œ"""
        try:
            # direct_vercel_deploy.pyã‚’ä½¿ç”¨
            from direct_vercel_deploy import deploy_to_vercel
            success = deploy_to_vercel()
            
            if success:
                return {
                    "success": True,
                    "timestamp": datetime.now().isoformat(),
                    "url": "https://study-research-final.vercel.app"
                }
            else:
                return {
                    "success": False,
                    "error": "ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆå¤±æ•—"
                }
        except Exception as e:
            return {
                "success": False,
                "error": str(e)
            }
    
    def _record_success_pattern(self, deploy_result: Dict) -> Dict:
        """æˆåŠŸãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’è¨˜éŒ²"""
        pattern = self.deployment_manager.record_success_pattern(
            deployment_type="static_html",
            files_changed=self._get_deployment_files(),
            config_used=self.config,
            success_reason="çµ±åˆã‚·ã‚¹ãƒ†ãƒ ã«ã‚ˆã‚‹æœ€é©åŒ–ãƒ‡ãƒ—ãƒ­ã‚¤",
            deploy_id=f"unified_{datetime.now().strftime('%Y%m%d_%H%M%S')}",
            url=deploy_result.get("url", "")
        )
        return pattern
    
    async def _auto_fix_errors(self, error: str) -> Dict:
        """ã‚¨ãƒ©ãƒ¼è‡ªå‹•ä¿®å¾©"""
        try:
            # ä¿®æ­£ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã‚’ä½¿ç”¨
            self.fix_assistant.apply_fix("static_html")
            
            # å†ãƒ‡ãƒ—ãƒ­ã‚¤è©¦è¡Œ
            retry_result = await self._execute_deployment()
            
            return {
                "fixed": retry_result["success"],
                "method": "static_html_conversion",
                "retry_result": retry_result
            }
        except Exception as e:
            return {
                "fixed": False,
                "error": str(e)
            }
    
    def _generate_comprehensive_report(self, workflow_result: Dict) -> str:
        """åŒ…æ‹¬çš„ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ"""
        report = [f"# Vercelçµ±åˆã‚·ã‚¹ãƒ†ãƒ ãƒ¬ãƒãƒ¼ãƒˆ"]
        report.append(f"**ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ID**: {workflow_result['workflow_id']}")
        report.append(f"**å®Ÿè¡Œæ—¥æ™‚**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        report.append(f"**çµæœ**: {'âœ… æˆåŠŸ' if workflow_result['success'] else 'âŒ å¤±æ•—'}\n")
        
        # ã‚¹ãƒ†ãƒƒãƒ—ã‚µãƒãƒªãƒ¼
        report.append("## å®Ÿè¡Œã‚¹ãƒ†ãƒƒãƒ—")
        for step in workflow_result["steps"]:
            status_icon = "âœ…" if step["status"] == "completed" else "âŒ"
            report.append(f"- {status_icon} {step['name']}")
        
        # è©³ç´°æƒ…å ±
        report.append("\n## è©³ç´°æƒ…å ±")
        
        # ç’°å¢ƒè¨ºæ–­çµæœ
        diagnosis = next((s["details"] for s in workflow_result["steps"] 
                         if s["name"] == "ç’°å¢ƒè¨ºæ–­"), None)
        if diagnosis:
            report.append(f"\n### ç’°å¢ƒå¥å…¨æ€§ã‚¹ã‚³ã‚¢: {diagnosis.get('health_score', 0)}%")
        
        # AIåˆ†æçµæœ
        ai_analysis = next((s["details"] for s in workflow_result["steps"] 
                           if s["name"] == "AIåˆ†æ"), None)
        if ai_analysis:
            report.append(f"\n### AIäºˆæ¸¬æˆåŠŸç‡: {ai_analysis.get('predicted_success_rate', 0)}%")
        
        # çµ±è¨ˆæƒ…å ±
        report.append("\n## çµ±è¨ˆæƒ…å ±")
        total_deployments = len(self.update_tracker.get_all_updates())
        report.append(f"- ç·ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆæ•°: {total_deployments}")
        
        recent_workflows = [w for w in self.workflow_history 
                           if w["timestamp"] > 
                           (datetime.now() - timedelta(days=30)).isoformat()]
        if recent_workflows:
            success_count = sum(1 for w in recent_workflows 
                               if w.get("result", {}).get("success", False))
            success_rate = (success_count / len(recent_workflows)) * 100
            report.append(f"- 30æ—¥é–“ã®æˆåŠŸç‡: {success_rate:.1f}%")
        
        return "\n".join(report)
    
    async def _collect_user_satisfaction(self, result: Dict) -> int:
        """ãƒ¦ãƒ¼ã‚¶ãƒ¼æº€è¶³åº¦ã‚’åé›†"""
        print("\nğŸ˜Š ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆã®æº€è¶³åº¦ã‚’æ•™ãˆã¦ãã ã•ã„")
        print("5: ã¨ã¦ã‚‚æº€è¶³")
        print("4: æº€è¶³") 
        print("3: æ™®é€š")
        print("2: ä¸æº€")
        print("1: ã¨ã¦ã‚‚ä¸æº€")
        
        try:
            score = int(input("\nã‚¹ã‚³ã‚¢ (1-5): "))
            score = max(1, min(5, score))  # 1-5ã®ç¯„å›²ã«åˆ¶é™
            
            # ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯åé›†
            feedback = input("æ”¹å–„ç‚¹ãŒã‚ã‚Œã°æ•™ãˆã¦ãã ã•ã„ï¼ˆä»»æ„ï¼‰: ")
            
            # è¨˜éŒ²
            self.ai_integration.record_user_satisfaction(
                deployment_id=result["workflow_id"],
                satisfaction_score=score,
                feedback=feedback
            )
            
            # ä½è©•ä¾¡ã®å ´åˆã¯æ”¹å–„ç­–ã‚’æç¤º
            if score < 3:
                print("\nğŸ“ ã”æ„è¦‹ã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã™ã€‚ä»¥ä¸‹ã®æ”¹å–„ã‚’æ¤œè¨ã—ã¾ã™ï¼š")
                print("- ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ—ãƒ­ã‚»ã‚¹ã®ç°¡ç´ åŒ–")
                print("- ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®æ”¹å–„")
                print("- ã‚ˆã‚Šè©³ç´°ãªã‚¬ã‚¤ãƒ€ãƒ³ã‚¹æä¾›")
            
            return score
            
        except:
            return 3  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤
    
    def _get_deployment_files(self) -> List[str]:
        """ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ãƒªã‚¹ãƒˆã‚’å–å¾—"""
        files = []
        if os.path.exists("public/index.html"):
            files.append("public/index.html")
        if os.path.exists("vercel.json"):
            files.append("vercel.json")
        return files
    
    def show_dashboard(self):
        """çµ±åˆãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰è¡¨ç¤º"""
        print("\n" + "=" * 60)
        print("ğŸ“Š Vercelçµ±åˆã‚·ã‚¹ãƒ†ãƒ ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰")
        print("=" * 60)
        
        # æœ€æ–°ã®æ›´æ–°æƒ…å ±
        latest_update = self.update_tracker.get_latest_update()
        if latest_update:
            print(f"\nğŸ“… æœ€æ–°ãƒ‡ãƒ—ãƒ­ã‚¤: {latest_update['date']}")
            print(f"   ãƒãƒ¼ã‚¸ãƒ§ãƒ³: {latest_update['version']}")
            print(f"   URL: {latest_update['url']}")
        
        # æˆåŠŸç‡
        recent_workflows = [w for w in self.workflow_history[-10:]]
        if recent_workflows:
            success_count = sum(1 for w in recent_workflows 
                               if w.get("result", {}).get("success", False))
            print(f"\nğŸ“ˆ ç›´è¿‘10å›ã®æˆåŠŸç‡: {(success_count/10)*100:.0f}%")
        
        # æº€è¶³åº¦
        if os.path.exists(self.ai_integration.user_satisfaction_file):
            with open(self.ai_integration.user_satisfaction_file, 'r') as f:
                satisfaction = json.load(f)
                if satisfaction.get("average_score"):
                    stars = "â­" * int(satisfaction["average_score"])
                    print(f"\nğŸ˜Š å¹³å‡æº€è¶³åº¦: {satisfaction['average_score']:.1f}/5.0 {stars}")
        
        # åˆ©ç”¨å¯èƒ½ãªã‚³ãƒãƒ³ãƒ‰
        print("\nğŸ”§ åˆ©ç”¨å¯èƒ½ãªã‚³ãƒãƒ³ãƒ‰:")
        print("1. ã‚¹ãƒãƒ¼ãƒˆãƒ‡ãƒ—ãƒ­ã‚¤: python3 vercel_unified_system.py deploy")
        print("2. è¨ºæ–­ãƒ¬ãƒãƒ¼ãƒˆ: python3 vercel_unified_system.py diagnose")
        print("3. ä¿®å¾©ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆ: python3 vercel_fix_assistant.py")
        print("4. å±¥æ­´ç¢ºèª: python3 vercel_update_tracker.py")
        
        print("\n" + "=" * 60)

async def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    import sys
    
    system = VercelUnifiedSystem()
    
    if len(sys.argv) > 1:
        command = sys.argv[1]
        
        if command == "deploy":
            # ã‚¹ãƒãƒ¼ãƒˆãƒ‡ãƒ—ãƒ­ã‚¤å®Ÿè¡Œ
            result = await system.smart_deploy_workflow()
            if result["success"]:
                print("\nâœ… ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆæˆåŠŸï¼")
            else:
                print("\nâŒ ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆå¤±æ•—")
                
        elif command == "diagnose":
            # è¨ºæ–­ã®ã¿
            diagnosis = system._diagnose_environment()
            print(json.dumps(diagnosis, ensure_ascii=False, indent=2))
            
        elif command == "dashboard":
            # ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰è¡¨ç¤º
            system.show_dashboard()
            
        else:
            print(f"ä¸æ˜ãªã‚³ãƒãƒ³ãƒ‰: {command}")
            print("ä½¿ç”¨æ–¹æ³•: python3 vercel_unified_system.py [deploy|diagnose|dashboard]")
    else:
        # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰è¡¨ç¤º
        system.show_dashboard()

if __name__ == "__main__":
    asyncio.run(main())