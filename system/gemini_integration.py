#!/usr/bin/env python3
"""
Gemini AI çµ±åˆã‚·ã‚¹ãƒ†ãƒ 
ç ”ç©¶ãƒ‡ã‚£ã‚¹ã‚«ãƒƒã‚·ãƒ§ãƒ³è¨˜éŒ²ã®åˆ†æã¨ææ¡ˆç”Ÿæˆ
"""

import os
import json
import requests
from pathlib import Path
from datetime import datetime

class GeminiIntegration:
    def __init__(self):
        self.research_root = Path(__file__).parent
        self.env_file = self.research_root / ".env"
        self.api_key = self.load_api_key()
        self.base_url = "https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent"
        
    def load_api_key(self):
        """ç’°å¢ƒå¤‰æ•°ã‹ã‚‰Gemini APIã‚­ãƒ¼ã‚’èª­ã¿è¾¼ã¿"""
        # .envãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰èª­ã¿è¾¼ã¿
        if self.env_file.exists():
            with open(self.env_file, 'r', encoding='utf-8') as f:
                for line in f:
                    if line.startswith('GEMINI_API_KEY='):
                        return line.split('=', 1)[1].strip().strip('"')
        
        # ç’°å¢ƒå¤‰æ•°ã‹ã‚‰èª­ã¿è¾¼ã¿
        return os.getenv('GEMINI_API_KEY', '')
    
    def generate_content(self, prompt, max_tokens=8192):
        """Gemini APIã§ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ç”Ÿæˆ"""
        if not self.api_key:
            return {"error": "Gemini API ã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“"}
        
        headers = {
            "Content-Type": "application/json"
        }
        
        data = {
            "contents": [{
                "parts": [{
                    "text": prompt
                }]
            }],
            "generationConfig": {
                "temperature": 0.7,
                "topK": 40,
                "topP": 0.95,
                "maxOutputTokens": max_tokens,
            }
        }
        
        try:
            response = requests.post(
                f"{self.base_url}?key={self.api_key}",
                headers=headers,
                json=data,
                timeout=30
            )
            
            if response.status_code == 200:
                result = response.json()
                if 'candidates' in result and len(result['candidates']) > 0:
                    return {
                        "content": result['candidates'][0]['content']['parts'][0]['text'],
                        "usage": result.get('usageMetadata', {}),
                        "success": True
                    }
                else:
                    return {"error": "æœ‰åŠ¹ãªå¿œç­”ãŒç”Ÿæˆã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ"}
            else:
                return {
                    "error": f"APIå‘¼ã³å‡ºã—ã‚¨ãƒ©ãƒ¼: {response.status_code} - {response.text}"
                }
                
        except Exception as e:
            return {"error": f"ãƒªã‚¯ã‚¨ã‚¹ãƒˆå¤±æ•—: {str(e)}"}
    
    def analyze_research_progress(self):
        """ç ”ç©¶é€²æ—ã‚’åˆ†æ"""
        summary_file = self.research_root / "study/research_discussions/WEEKLY_DISCUSSION_SUMMARY.md"
        
        if not summary_file.exists():
            return {"error": "ç ”ç©¶è¨˜éŒ²ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“"}
        
        with open(summary_file, 'r', encoding='utf-8') as f:
            research_content = f.read()
        
        prompt = f"""
ä»¥ä¸‹ã®ç ”ç©¶é€²æ—è¨˜éŒ²ã‚’åˆ†æã—ã¦ã€è©³ç´°ãªãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã¨ææ¡ˆã‚’æ—¥æœ¬èªã§æä¾›ã—ã¦ãã ã•ã„ï¼š

{research_content}

åˆ†æé …ç›®ï¼š
1. ç ”ç©¶ã®å­¦è¡“çš„ä¾¡å€¤ã¨ç‹¬å‰µæ€§
2. æŠ€è¡“çš„æˆæœã®è©•ä¾¡
3. ä»Šå¾Œã®ç ”ç©¶æ–¹å‘æ€§ã®ææ¡ˆ
4. è«–æ–‡æŠ•ç¨¿æˆ¦ç•¥
5. æ”¹å–„ã™ã¹ãç‚¹

å„é …ç›®ã«ã¤ã„ã¦å…·ä½“çš„ã§å»ºè¨­çš„ãªãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’æä¾›ã—ã¦ãã ã•ã„ã€‚
"""
        
        return self.generate_content(prompt)
    
    def suggest_next_session_agenda(self):
        """æ¬¡å›ã‚»ãƒƒã‚·ãƒ§ãƒ³ã®è­°é¡Œææ¡ˆ"""
        summary_file = self.research_root / "study/research_discussions/WEEKLY_DISCUSSION_SUMMARY.md"
        
        if not summary_file.exists():
            return {"error": "ç ”ç©¶è¨˜éŒ²ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“"}
        
        with open(summary_file, 'r', encoding='utf-8') as f:
            research_content = f.read()
        
        # ç¾åœ¨ã®æ—¥ä»˜ã‚’å–å¾—
        current_date = datetime.now().strftime('%Yå¹´%mæœˆ%dæ—¥')
        
        prompt = f"""
ä»¥ä¸‹ã®ç ”ç©¶é€²æ—è¨˜éŒ²ã«åŸºã¥ã„ã¦ã€æ¬¡å›ãƒ‡ã‚£ã‚¹ã‚«ãƒƒã‚·ãƒ§ãƒ³ï¼ˆ{current_date}ä»¥é™ï¼‰ã®è©³ç´°ãªè­°é¡Œã‚’ææ¡ˆã—ã¦ãã ã•ã„ï¼š

{research_content}

ææ¡ˆå½¢å¼ï¼š
1. ä¸»è¦è­°é¡Œï¼ˆ3-5é …ç›®ï¼‰
2. æº–å‚™ã™ã¹ãè³‡æ–™ãƒ»ãƒ‡ãƒ¼ã‚¿
3. æ¤œè¨ã™ã¹ãæŠ€è¡“çš„èª²é¡Œ
4. å­¦è¡“ç™ºè¡¨ã«å‘ã‘ãŸæº–å‚™é …ç›®
5. å…·ä½“çš„ãªToDoãƒªã‚¹ãƒˆ

å®Ÿç”¨çš„ã§å®Ÿè¡Œå¯èƒ½ãªææ¡ˆã‚’æ—¥æœ¬èªã§æä¾›ã—ã¦ãã ã•ã„ã€‚
"""
        
        return self.generate_content(prompt)
    
    def evaluate_presentation_strategy(self):
        """ç™ºè¡¨æˆ¦ç•¥ã®è©•ä¾¡ã¨ææ¡ˆ"""
        summary_file = self.research_root / "study/research_discussions/WEEKLY_DISCUSSION_SUMMARY.md"
        
        if not summary_file.exists():
            return {"error": "ç ”ç©¶è¨˜éŒ²ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“"}
        
        with open(summary_file, 'r', encoding='utf-8') as f:
            research_content = f.read()
        
        prompt = f"""
ä»¥ä¸‹ã®ç ”ç©¶è¨˜éŒ²ã«åŸºã¥ã„ã¦ã€å­¦è¡“ç™ºè¡¨æˆ¦ç•¥ã‚’è©•ä¾¡ãƒ»ææ¡ˆã—ã¦ãã ã•ã„ï¼š

{research_content}

è©•ä¾¡ãƒ»ææ¡ˆé …ç›®ï¼š
1. ä¸­é–“ç™ºè¡¨ï¼ˆ8æœˆï¼‰ã®ç™ºè¡¨å†…å®¹ãƒ»æ§‹æˆææ¡ˆ
2. å’æ¥­ç™ºè¡¨ï¼ˆ2æœˆï¼‰ã«å‘ã‘ãŸæº–å‚™æˆ¦ç•¥
3. å›½éš›ä¼šè­°æŠ•ç¨¿ã®å¯èƒ½æ€§ã¨å¯¾è±¡ä¼šè­°
4. ç ”ç©¶ã®å·®åˆ¥åŒ–ãƒã‚¤ãƒ³ãƒˆã¨å¼·èª¿ã™ã¹ãç‚¹
5. æƒ³å®šã•ã‚Œã‚‹è³ªå•ã¨å›ç­”æº–å‚™

å­¦è¡“çš„ãªè¦³ç‚¹ã‹ã‚‰å®Ÿè·µçš„ãªã‚¢ãƒ‰ãƒã‚¤ã‚¹ã‚’æ—¥æœ¬èªã§æä¾›ã—ã¦ãã ã•ã„ã€‚
"""
        
        return self.generate_content(prompt)
    
    def analyze_technical_achievements(self):
        """æŠ€è¡“çš„æˆæœã®è©³ç´°åˆ†æ"""
        summary_file = self.research_root / "study/research_discussions/WEEKLY_DISCUSSION_SUMMARY.md"
        
        if not summary_file.exists():
            return {"error": "ç ”ç©¶è¨˜éŒ²ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“"}
        
        with open(summary_file, 'r', encoding='utf-8') as f:
            research_content = f.read()
        
        prompt = f"""
ä»¥ä¸‹ã®ç ”ç©¶è¨˜éŒ²ã®æŠ€è¡“çš„æˆæœã‚’è©³ç´°åˆ†æã—ã¦ãã ã•ã„ï¼š

{research_content}

åˆ†æé …ç›®ï¼š
1. æŠ€è¡“çš„ãƒ–ãƒ¬ãƒ¼ã‚¯ã‚¹ãƒ«ãƒ¼ã®è©•ä¾¡
2. ç²¾åº¦å‘ä¸Šï¼ˆ87.1%ã€27.3%å‘ä¸Šï¼‰ã®æŠ€è¡“çš„æ„ç¾©
3. WordNetéšå±¤ã‚·ã‚¹ãƒ†ãƒ ã®ç‹¬å‰µæ€§
4. AIæŠ€è¡“çµ±åˆã®æŠ€è¡“çš„ä¾¡å€¤
5. ä»–ç ”ç©¶ã¨ã®å·®åˆ¥åŒ–è¦å› 
6. æŠ€è¡“çš„é™ç•Œã¨æ”¹å–„ã®æ–¹å‘æ€§

æŠ€è¡“çš„å°‚é–€æ€§ã‚’é‡è¦–ã—ãŸåˆ†æã‚’æ—¥æœ¬èªã§æä¾›ã—ã¦ãã ã•ã„ã€‚
"""
        
        return self.generate_content(prompt)
    
    def chat_with_gemini(self, user_question):
        """Geminiã¨ã®å¯¾è©±"""
        summary_file = self.research_root / "study/research_discussions/WEEKLY_DISCUSSION_SUMMARY.md"
        
        context = ""
        if summary_file.exists():
            with open(summary_file, 'r', encoding='utf-8') as f:
                context = f.read()[:3000]  # æ–‡è„ˆã¨ã—ã¦æœ€åˆã®3000æ–‡å­—
        
        prompt = f"""
ç ”ç©¶ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆï¼š
{context}

è³ªå•ï¼š{user_question}

ä¸Šè¨˜ã®ç ”ç©¶è¨˜éŒ²ã‚’å‚è€ƒã«ã—ã¦ã€è³ªå•ã«å¯¾ã—ã¦å°‚é–€çš„ã§å»ºè¨­çš„ãªå›ç­”ã‚’æ—¥æœ¬èªã§æä¾›ã—ã¦ãã ã•ã„ã€‚
"""
        
        return self.generate_content(prompt)
    
    def save_analysis_result(self, analysis_type, result):
        """åˆ†æçµæœã‚’ä¿å­˜"""
        if not result.get('success'):
            return False
        
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        filename = f"gemini_analysis_{analysis_type}_{timestamp}.md"
        output_file = self.research_root / f"ai_analysis/{filename}"
        
        # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
        output_file.parent.mkdir(exist_ok=True)
        
        content = f"""# Gemini AI åˆ†æçµæœ - {analysis_type}

**ç”Ÿæˆæ—¥æ™‚**: {datetime.now().strftime('%Yå¹´%mæœˆ%dæ—¥ %H:%M:%S')}  
**åˆ†æã‚¿ã‚¤ãƒ—**: {analysis_type}

---

{result['content']}

---

**ä½¿ç”¨é‡æƒ…å ±**:
- ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒˆãƒ¼ã‚¯ãƒ³: {result.get('usage', {}).get('promptTokenCount', 'N/A')}
- ç”Ÿæˆãƒˆãƒ¼ã‚¯ãƒ³: {result.get('usage', {}).get('candidatesTokenCount', 'N/A')}
- åˆè¨ˆãƒˆãƒ¼ã‚¯ãƒ³: {result.get('usage', {}).get('totalTokenCount', 'N/A')}
"""
        
        with open(output_file, 'w', encoding='utf-8') as f:
            f.write(content)
        
        return str(output_file)

def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    import sys
    
    gemini = GeminiIntegration()
    
    if not gemini.api_key:
        print("âŒ Gemini APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
        print("ğŸ“ .envãƒ•ã‚¡ã‚¤ãƒ«ã«GEMINI_API_KEY=<your_key>ã‚’è¿½åŠ ã—ã¦ãã ã•ã„")
        return
    
    if len(sys.argv) > 1:
        command = sys.argv[1]
        
        if command == "progress":
            print("ğŸ” ç ”ç©¶é€²æ—ã‚’åˆ†æä¸­...")
            result = gemini.analyze_research_progress()
            
        elif command == "agenda":
            print("ğŸ“‹ æ¬¡å›ã‚»ãƒƒã‚·ãƒ§ãƒ³è­°é¡Œã‚’ç”Ÿæˆä¸­...")
            result = gemini.suggest_next_session_agenda()
            
        elif command == "presentation":
            print("ğŸ¯ ç™ºè¡¨æˆ¦ç•¥ã‚’è©•ä¾¡ä¸­...")
            result = gemini.evaluate_presentation_strategy()
            
        elif command == "technical":
            print("ğŸ”¬ æŠ€è¡“çš„æˆæœã‚’åˆ†æä¸­...")
            result = gemini.analyze_technical_achievements()
            
        elif command == "chat":
            if len(sys.argv) > 2:
                question = " ".join(sys.argv[2:])
                print(f"ğŸ’¬ è³ªå•: {question}")
                result = gemini.chat_with_gemini(question)
            else:
                print("âŒ è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
                print("ä½¿ç”¨ä¾‹: python3 gemini_integration.py chat 'ç ”ç©¶ã®æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—ã¯ï¼Ÿ'")
                return
                
        else:
            print("âŒ ä¸æ˜ãªã‚³ãƒãƒ³ãƒ‰")
            print_usage()
            return
    else:
        print_usage()
        return
    
    # çµæœè¡¨ç¤º
    if result.get('success'):
        print("âœ… åˆ†æå®Œäº†\n")
        print("=" * 80)
        print(result['content'])
        print("=" * 80)
        
        # çµæœä¿å­˜
        if len(sys.argv) > 1:
            saved_file = gemini.save_analysis_result(sys.argv[1], result)
            if saved_file:
                print(f"\nğŸ“„ åˆ†æçµæœã‚’ä¿å­˜: {saved_file}")
        
        # ä½¿ç”¨é‡è¡¨ç¤º
        if 'usage' in result:
            usage = result['usage']
            print(f"\nğŸ“Š ä½¿ç”¨é‡: ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ{usage.get('promptTokenCount', 0)} + "
                  f"ç”Ÿæˆ{usage.get('candidatesTokenCount', 0)} = "
                  f"åˆè¨ˆ{usage.get('totalTokenCount', 0)}ãƒˆãƒ¼ã‚¯ãƒ³")
    else:
        print(f"âŒ ã‚¨ãƒ©ãƒ¼: {result.get('error')}")

def print_usage():
    """ä½¿ç”¨æ–¹æ³•ã‚’è¡¨ç¤º"""
    print("ğŸ¤– Gemini AI çµ±åˆã‚·ã‚¹ãƒ†ãƒ ")
    print("=" * 40)
    print("ä½¿ç”¨æ³•:")
    print("  python3 gemini_integration.py <command> [args]")
    print("")
    print("ã‚³ãƒãƒ³ãƒ‰:")
    print("  progress     # ç ”ç©¶é€²æ—åˆ†æ")
    print("  agenda       # æ¬¡å›ã‚»ãƒƒã‚·ãƒ§ãƒ³è­°é¡Œææ¡ˆ")
    print("  presentation # ç™ºè¡¨æˆ¦ç•¥è©•ä¾¡")
    print("  technical    # æŠ€è¡“çš„æˆæœåˆ†æ")
    print("  chat <è³ªå•>   # å¯¾è©±å½¢å¼è³ªå•")
    print("")
    print("ä¾‹:")
    print("  python3 gemini_integration.py progress")
    print("  python3 gemini_integration.py chat 'ç ”ç©¶ã®å¼·ã¿ã¯ä½•ã§ã™ã‹ï¼Ÿ'")

if __name__ == "__main__":
    main()