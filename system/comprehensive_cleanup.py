#!/usr/bin/env python3
"""
åŒ…æ‹¬çš„ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ•´ç†ã‚·ã‚¹ãƒ†ãƒ 
ç¾åœ¨ã®æ§‹é€ ã‚’åˆ†æã—ã€æœ€é©åŒ–ã•ã‚ŒãŸæ§‹é€ ã«æ•´ç†ã™ã‚‹
"""

import os
import shutil
from pathlib import Path
from datetime import datetime
import json

class ComprehensiveCleanup:
    def __init__(self):
        self.root_path = Path("/mnt/c/Desktop/Research")
        self.backup_path = self.root_path / "comprehensive_cleanup_backup"
        self.report = {
            "timestamp": datetime.now().isoformat(),
            "actions": [],
            "moved_items": [],
            "deleted_items": [],
            "preserved_items": []
        }
    
    def analyze_current_structure(self):
        """ç¾åœ¨ã®æ§‹é€ ã‚’åˆ†æ"""
        analysis = {
            "duplicates": [],
            "old_backups": [],
            "redundant_tools": [],
            "unused_configs": [],
            "outdated_docs": []
        }
        
        # temp_cleanup_backupå†…ã®é‡è¤‡åˆ†æ
        temp_backup = self.root_path / "temp_cleanup_backup"
        if temp_backup.exists():
            analysis["old_backups"].append(str(temp_backup))
        
        # tools ãƒ•ã‚©ãƒ«ãƒ€ã®é‡è¤‡åˆ†æ
        tools_path = self.root_path / "tools"
        if tools_path.exists():
            # ç ”ç©¶é–¢é€£ãƒ„ãƒ¼ãƒ«ã¯å¤šã™ãã‚‹å¯èƒ½æ€§
            research_tools = list(tools_path.glob("*research*"))
            sql_tools = list(tools_path.glob("*sql*"))
            vercel_tools = list(tools_path.glob("*vercel*"))
            
            if len(research_tools) > 5:
                analysis["redundant_tools"].extend([str(t) for t in research_tools[5:]])
            if len(sql_tools) > 3:
                analysis["redundant_tools"].extend([str(t) for t in sql_tools[3:]])
            if len(vercel_tools) > 2:
                analysis["redundant_tools"].extend([str(t) for t in vercel_tools[2:]])
        
        return analysis
    
    def create_optimal_structure(self):
        """æœ€é©åŒ–ã•ã‚ŒãŸæ§‹é€ ã‚’ä½œæˆ"""
        optimal_structure = {
            # å¿…é ˆã‚·ã‚¹ãƒ†ãƒ ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆãƒ«ãƒ¼ãƒˆï¼‰
            "root_files": [
                "CLAUDE.md",
                "README.md", 
                "package.json",
                "requirements.txt",
                "vercel.json"
            ],
            
            # ã‚³ã‚¢ã‚·ã‚¹ãƒ†ãƒ 
            "system/": [
                "auto_cleanup.py",
                "auto_update_system.py", 
                "gemini_integration.py",
                "session_save_protocol.py",
                "setup_auto_update.py"
            ],
            
            # ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ
            "docs/": [
                "AUTO_UPDATE_GUIDE.md",
                "SESSION_SAVE_GUIDE.md",
                "PROJECT_STRUCTURE.md"
            ],
            
            # ã‚»ãƒƒã‚·ãƒ§ãƒ³è¨˜éŒ²
            "sessions/": [
                "daily_session_*.md",
                "COMPLETE_SESSION_*.md"
            ],
            
            # AIåˆ†æçµæœ
            "ai_analysis/": [
                "gemini_analysis_*.md"
            ],
            
            # å…¬é–‹ã‚µã‚¤ãƒˆ
            "public/": [
                "discussion-site/",
                "main-system/"
            ],
            
            # ç ”ç©¶å†…å®¹ï¼ˆsubmoduleï¼‰
            "study/": "preserve_as_is",
            
            # æœ€å°é™ã®ãƒ„ãƒ¼ãƒ«
            "tools/": [
                "direct_vercel_deploy.py",
                "research_analysis_system.py"
            ]
        }
        
        return optimal_structure
    
    def execute_cleanup(self):
        """æ•´ç†ã‚’å®Ÿè¡Œ"""
        print("ğŸ§¹ åŒ…æ‹¬çš„ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ•´ç†ã‚’é–‹å§‹...")
        
        # ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
        self.backup_path.mkdir(exist_ok=True)
        
        # 1. temp_cleanup_backup ã‚’çµ±åˆãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã«ç§»å‹•
        temp_backup = self.root_path / "temp_cleanup_backup"
        if temp_backup.exists():
            dest = self.backup_path / "previous_temp_backup"
            shutil.move(str(temp_backup), str(dest))
            self.report["moved_items"].append(f"{temp_backup} â†’ {dest}")
        
        # 2. éå‰°ãªãƒ„ãƒ¼ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã®æ•´ç†
        self.cleanup_tools_directory()
        
        # 3. é‡è¤‡ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®æ•´ç†
        self.cleanup_duplicate_docs()
        
        # 4. å¤ã„ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ»ãƒ­ã‚°ã®æ•´ç†
        self.cleanup_old_files()
        
        # 5. ãƒ¬ãƒãƒ¼ãƒˆä½œæˆ
        self.create_cleanup_report()
        
        print("âœ… åŒ…æ‹¬çš„æ•´ç†å®Œäº†")
    
    def cleanup_tools_directory(self):
        """toolsãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®æ•´ç†"""
        tools_path = self.root_path / "tools"
        if not tools_path.exists():
            return
        
        # ä¿æŒã™ã‚‹ãƒ„ãƒ¼ãƒ«
        keep_tools = [
            "direct_vercel_deploy.py",
            "research_analysis_system.py",
            "vercel_quick_deploy.sh"
        ]
        
        # ç§»å‹•å¯¾è±¡ã®ç‰¹å®š
        for item in tools_path.iterdir():
            if item.name not in keep_tools:
                dest = self.backup_path / "tools" / item.name
                dest.parent.mkdir(parents=True, exist_ok=True)
                shutil.move(str(item), str(dest))
                self.report["moved_items"].append(f"{item} â†’ {dest}")
    
    def cleanup_duplicate_docs(self):
        """é‡è¤‡ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®æ•´ç†"""
        # CLEANUP_REPORT.md ã¯æ—¢å­˜ãªã®ã§çµ±åˆ
        cleanup_report = self.root_path / "CLEANUP_REPORT.md"
        if cleanup_report.exists():
            dest = self.backup_path / "old_reports" / "CLEANUP_REPORT.md"
            dest.parent.mkdir(parents=True, exist_ok=True)
            shutil.move(str(cleanup_report), str(dest))
            self.report["moved_items"].append(f"{cleanup_report} â†’ {dest}")
    
    def cleanup_old_files(self):
        """å¤ã„ãƒ•ã‚¡ã‚¤ãƒ«ãƒ»ãƒ•ã‚©ãƒ«ãƒ€ã®æ•´ç†"""
        # archiveãƒ•ã‚©ãƒ«ãƒ€
        archive_path = self.root_path / "archive"
        if archive_path.exists():
            dest = self.backup_path / "archive"
            shutil.move(str(archive_path), str(dest))
            self.report["moved_items"].append(f"{archive_path} â†’ {dest}")
    
    def create_cleanup_report(self):
        """æ•´ç†ãƒ¬ãƒãƒ¼ãƒˆã®ä½œæˆ"""
        report_content = f"""# åŒ…æ‹¬çš„ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ•´ç†ãƒ¬ãƒãƒ¼ãƒˆ - {datetime.now().strftime('%Yå¹´%mæœˆ%dæ—¥')}

## ğŸ“‹ æ•´ç†æ¦‚è¦
**å®Ÿè¡Œæ—¥æ™‚**: {self.report['timestamp']}
**æ•´ç†é …ç›®**: {len(self.report['moved_items'])}é …ç›®ç§»å‹•

## ğŸ—‚ï¸ æœ€é©åŒ–å¾Œã®æ§‹é€ 

### ãƒ«ãƒ¼ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªï¼ˆå¿…é ˆãƒ•ã‚¡ã‚¤ãƒ«ã®ã¿ï¼‰
- CLAUDE.md - ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆè¨­å®š
- README.md - ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ¦‚è¦  
- package.json, requirements.txt - ä¾å­˜é–¢ä¿‚
- vercel.json - ãƒ‡ãƒ—ãƒ­ã‚¤è¨­å®š

### ã‚·ã‚¹ãƒ†ãƒ ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªï¼ˆ/system/ï¼‰
- è‡ªå‹•æ›´æ–°ã‚·ã‚¹ãƒ†ãƒ 
- Gemini AIçµ±åˆ
- ã‚»ãƒƒã‚·ãƒ§ãƒ³ä¿å­˜ãƒ—ãƒ­ãƒˆã‚³ãƒ«
- ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ•´ç†ã‚·ã‚¹ãƒ†ãƒ 

### ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆï¼ˆ/docs/ï¼‰
- ä½¿ç”¨ã‚¬ã‚¤ãƒ‰
- ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ§‹é€ 
- ã‚»ãƒƒã‚·ãƒ§ãƒ³ä¿å­˜ã‚¬ã‚¤ãƒ‰

### ã‚»ãƒƒã‚·ãƒ§ãƒ³è¨˜éŒ²ï¼ˆ/sessions/ï¼‰
- æ—¥æ¬¡ã‚»ãƒƒã‚·ãƒ§ãƒ³è¨˜éŒ²
- åŒ…æ‹¬ã‚»ãƒƒã‚·ãƒ§ãƒ³è¨˜éŒ²

### å…¬é–‹ã‚µã‚¤ãƒˆï¼ˆ/public/ï¼‰
- discussion-site - ç ”ç©¶ãƒ‡ã‚£ã‚¹ã‚«ãƒƒã‚·ãƒ§ãƒ³ã‚µã‚¤ãƒˆ
- main-system - ãƒ¡ã‚¤ãƒ³ã‚·ã‚¹ãƒ†ãƒ 

### ç ”ç©¶å†…å®¹ï¼ˆ/study/ï¼‰
- Git submodule ã¨ã—ã¦ä¿æŒ
- ç ”ç©¶ãƒ‡ãƒ¼ã‚¿ãƒ»åˆ†æçµæœ

### æœ€å°é™ãƒ„ãƒ¼ãƒ«ï¼ˆ/tools/ï¼‰
- direct_vercel_deploy.py - ç›´æ¥ãƒ‡ãƒ—ãƒ­ã‚¤
- research_analysis_system.py - ç ”ç©¶åˆ†æ

## ğŸ“¦ ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—å†…å®¹

### comprehensive_cleanup_backup/
"""

        for item in self.report["moved_items"]:
            report_content += f"- {item}\n"

        report_content += f"""
## ğŸ¯ æ•´ç†åŠ¹æœ

### æ§‹é€ æ˜ç¢ºåŒ–
- ãƒ«ãƒ¼ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: å¿…é ˆãƒ•ã‚¡ã‚¤ãƒ«ã®ã¿
- æ©Ÿèƒ½åˆ¥ãƒ•ã‚©ãƒ«ãƒ€: æ˜ç¢ºãªå½¹å‰²åˆ†æ‹…
- é‡è¤‡æ’é™¤: é¡ä¼¼æ©Ÿèƒ½ã®çµ±åˆ

### ä¿å®ˆæ€§å‘ä¸Š
- å¿…è¦ãƒ•ã‚¡ã‚¤ãƒ«ã®ç‰¹å®šå®¹æ˜“
- æ©Ÿèƒ½è¿½åŠ æ™‚ã®é…ç½®æ˜ç¢º
- ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã«ã‚ˆã‚‹å®‰å…¨æ€§ç¢ºä¿

### åŠ¹ç‡å‘ä¸Š  
- ãƒ•ã‚¡ã‚¤ãƒ«æ¤œç´¢æ™‚é–“çŸ­ç¸®
- ã‚·ã‚¹ãƒ†ãƒ ç†è§£ã®å®¹æ˜“åŒ–
- é–‹ç™ºåŠ¹ç‡ã®å‘ä¸Š

## âš ï¸ æ³¨æ„äº‹é …
- ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã¯1é€±é–“å¾Œã«å‰Šé™¤æ¤œè¨
- å¿…è¦ãªãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚ã‚Œã°å¾©å…ƒå¯èƒ½
- study/ãƒ•ã‚©ãƒ«ãƒ€ã¯submoduleã¨ã—ã¦ä¿æŒ

---
**ä½œæˆè€…**: åŒ…æ‹¬çš„æ•´ç†ã‚·ã‚¹ãƒ†ãƒ 
**æ¬¡å›æ•´ç†**: 1ãƒ¶æœˆå¾Œæ¨å¥¨
"""

        with open(self.root_path / "docs" / "COMPREHENSIVE_CLEANUP_REPORT.md", "w", encoding="utf-8") as f:
            f.write(report_content)
        
        # JSONãƒ¬ãƒãƒ¼ãƒˆã‚‚ä½œæˆ
        with open(self.backup_path / "cleanup_log.json", "w", encoding="utf-8") as f:
            json.dump(self.report, f, ensure_ascii=False, indent=2)

if __name__ == "__main__":
    cleanup = ComprehensiveCleanup()
    cleanup.execute_cleanup()