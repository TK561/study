{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸ“Š æ„å‘³ã‚«ãƒ†ã‚´ãƒªç”»åƒåˆ†é¡ç ”ç©¶ - Colabç‰ˆ\n",
    "\n",
    "WordNetãƒ™ãƒ¼ã‚¹ã®æ„å‘³ã‚«ãƒ†ã‚´ãƒªç”»åƒåˆ†é¡ã‚·ã‚¹ãƒ†ãƒ ã®ç ”ç©¶ã‚’Google Colabã§å®Ÿè¡Œã—ã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. ç’°å¢ƒã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Colabç’°å¢ƒç¢ºèª\n",
    "try:\n",
    "    import google.colab\n",
    "    IN_COLAB = True\n",
    "    print(\"âœ… Google Colabã§å®Ÿè¡Œä¸­\")\n",
    "except:\n",
    "    IN_COLAB = False\n",
    "    print(\"âŒ ãƒ­ãƒ¼ã‚«ãƒ«ç’°å¢ƒã§å®Ÿè¡Œä¸­\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«\n",
    "if IN_COLAB:\n",
    "    !pip install -q torch torchvision torchaudio\n",
    "    !pip install -q transformers\n",
    "    !pip install -q ultralytics\n",
    "    !pip install -q opencv-python\n",
    "    !pip install -q pillow\n",
    "    !pip install -q matplotlib\n",
    "    !pip install -q seaborn\n",
    "    !pip install -q pandas\n",
    "    !pip install -q numpy\n",
    "    !pip install -q nltk\n",
    "    !pip install -q scipy\n",
    "    !pip install -q scikit-learn\n",
    "    print(\"âœ… ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«å®Œäº†\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# åŸºæœ¬ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "from transformers import BlipProcessor, BlipForConditionalGeneration\n",
    "from transformers import CLIPProcessor, CLIPModel\n",
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import nltk\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from sklearn.metrics import accuracy_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"âœ… ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚¤ãƒ³ãƒãƒ¼ãƒˆå®Œäº†\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NLTK ãƒ‡ãƒ¼ã‚¿ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰\n",
    "import nltk\n",
    "nltk.download('wordnet', quiet=True)\n",
    "nltk.download('omw-1.4', quiet=True)\n",
    "from nltk.corpus import wordnet as wn\n",
    "print(\"âœ… WordNetæº–å‚™å®Œäº†\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Google Driveãƒã‚¦ãƒ³ãƒˆï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰\n",
    "if IN_COLAB:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    print(\"âœ… Google Driveæ¥ç¶šå®Œäº†\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. ç ”ç©¶ã‚·ã‚¹ãƒ†ãƒ ã®åˆæœŸåŒ–"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ãƒ‡ãƒã‚¤ã‚¹è¨­å®š\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"ä½¿ç”¨ãƒ‡ãƒã‚¤ã‚¹: {device}\")\n",
    "\n",
    "# ä½œæ¥­ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªè¨­å®š\n",
    "import os\n",
    "work_dir = '/content/research' if IN_COLAB else './research'\n",
    "os.makedirs(work_dir, exist_ok=True)\n",
    "os.chdir(work_dir)\n",
    "print(f\"ä½œæ¥­ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {work_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ãƒ¢ãƒ‡ãƒ«ã®åˆæœŸåŒ–\n",
    "print(\"ğŸ¤– AIãƒ¢ãƒ‡ãƒ«ã‚’åˆæœŸåŒ–ä¸­...\")\n",
    "\n",
    "# BLIP (ç”»åƒã‚­ãƒ£ãƒ—ã‚·ãƒ§ãƒ³ç”Ÿæˆ)\n",
    "blip_processor = BlipProcessor.from_pretrained(\"Salesforce/blip-image-captioning-base\")\n",
    "blip_model = BlipForConditionalGeneration.from_pretrained(\"Salesforce/blip-image-captioning-base\").to(device)\n",
    "\n",
    "# CLIP (ç”»åƒ-ãƒ†ã‚­ã‚¹ãƒˆåˆ†é¡)\n",
    "clip_processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "clip_model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\").to(device)\n",
    "\n",
    "# YOLO (ç‰©ä½“æ¤œå‡º)\n",
    "yolo_model = YOLO('yolov8n.pt')\n",
    "\n",
    "print(\"âœ… AIãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–å®Œäº†\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. ç ”ç©¶ç”¨ç”»åƒåˆ†é¡ã‚·ã‚¹ãƒ†ãƒ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ„å‘³ã‚«ãƒ†ã‚´ãƒªå®šç¾©\n",
    "SEMANTIC_CATEGORIES = {\n",
    "    'person': ['person', 'man', 'woman', 'child', 'people', 'human', 'face'],\n",
    "    'animal': ['dog', 'cat', 'bird', 'horse', 'cow', 'elephant', 'bear', 'zebra'],\n",
    "    'food': ['pizza', 'hamburger', 'cake', 'apple', 'banana', 'sandwich', 'donut'],\n",
    "    'vehicle': ['car', 'bus', 'truck', 'motorcycle', 'bicycle', 'airplane', 'boat'],\n",
    "    'building': ['house', 'building', 'bridge', 'castle', 'church', 'tower'],\n",
    "    'furniture': ['chair', 'table', 'sofa', 'bed', 'desk', 'bench'],\n",
    "    'plant': ['tree', 'flower', 'grass', 'plant', 'garden', 'forest'],\n",
    "    'landscape': ['mountain', 'beach', 'lake', 'river', 'sky', 'sunset']\n",
    "}\n",
    "\n",
    "print(\"âœ… æ„å‘³ã‚«ãƒ†ã‚´ãƒªå®šç¾©å®Œäº†\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SemanticImageClassifier:\n",
    "    def __init__(self):\n",
    "        self.results = []\n",
    "        \n",
    "    def generate_caption(self, image):\n",
    "        \"\"\"ç”»åƒã‚­ãƒ£ãƒ—ã‚·ãƒ§ãƒ³ã‚’ç”Ÿæˆ\"\"\"\n",
    "        inputs = blip_processor(image, return_tensors=\"pt\").to(device)\n",
    "        out = blip_model.generate(**inputs, max_length=50)\n",
    "        caption = blip_processor.decode(out[0], skip_special_tokens=True)\n",
    "        return caption\n",
    "    \n",
    "    def detect_semantic_category(self, caption):\n",
    "        \"\"\"æ„å‘³ã‚«ãƒ†ã‚´ãƒªã‚’æ¤œå‡º\"\"\"\n",
    "        caption_lower = caption.lower()\n",
    "        \n",
    "        # å„ã‚«ãƒ†ã‚´ãƒªã¨ã®ä¸€è‡´åº¦ã‚’è¨ˆç®—\n",
    "        category_scores = {}\n",
    "        for category, keywords in SEMANTIC_CATEGORIES.items():\n",
    "            score = sum(1 for keyword in keywords if keyword in caption_lower)\n",
    "            if score > 0:\n",
    "                category_scores[category] = score\n",
    "        \n",
    "        if category_scores:\n",
    "            return max(category_scores, key=category_scores.get)\n",
    "        return 'general'\n",
    "    \n",
    "    def classify_with_clip(self, image, labels, prefix=\"\"):\n",
    "        \"\"\"CLIP ã«ã‚ˆã‚‹åˆ†é¡\"\"\"\n",
    "        text_labels = [f\"{prefix}{label}\" for label in labels]\n",
    "        inputs = clip_processor(text=text_labels, images=image, return_tensors=\"pt\", padding=True).to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = clip_model(**inputs)\n",
    "            logits_per_image = outputs.logits_per_image\n",
    "            probs = logits_per_image.softmax(dim=1)\n",
    "            \n",
    "        max_prob_idx = probs.argmax().item()\n",
    "        confidence = probs[0][max_prob_idx].item()\n",
    "        predicted_label = labels[max_prob_idx]\n",
    "        \n",
    "        return predicted_label, confidence\n",
    "    \n",
    "    def get_specialized_approach(self, category):\n",
    "        \"\"\"ã‚«ãƒ†ã‚´ãƒªç‰¹åŒ–ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’å–å¾—\"\"\"\n",
    "        specialized_prompts = {\n",
    "            'person': 'a photo of a person: ',\n",
    "            'animal': 'a photo of an animal: ',\n",
    "            'food': 'a photo of food: ',\n",
    "            'vehicle': 'a photo of a vehicle: ',\n",
    "            'building': 'a photo of architecture: ',\n",
    "            'furniture': 'a photo of furniture: ',\n",
    "            'plant': 'a photo of a plant: ',\n",
    "            'landscape': 'a photo of a landscape: '\n",
    "        }\n",
    "        return specialized_prompts.get(category, '')\n",
    "    \n",
    "    def process_image(self, image_path):\n",
    "        \"\"\"ç”»åƒã‚’å‡¦ç†ã—ã¦ç ”ç©¶ãƒ‡ãƒ¼ã‚¿ã‚’åé›†\"\"\"\n",
    "        # ç”»åƒèª­ã¿è¾¼ã¿\n",
    "        image = Image.open(image_path).convert('RGB')\n",
    "        \n",
    "        # 1. ã‚­ãƒ£ãƒ—ã‚·ãƒ§ãƒ³ç”Ÿæˆ\n",
    "        caption = self.generate_caption(image)\n",
    "        \n",
    "        # 2. æ„å‘³ã‚«ãƒ†ã‚´ãƒªæ¤œå‡º\n",
    "        semantic_category = self.detect_semantic_category(caption)\n",
    "        \n",
    "        # 3. YOLOç‰©ä½“æ¤œå‡º\n",
    "        yolo_results = yolo_model(image_path)\n",
    "        detected_objects = []\n",
    "        for r in yolo_results:\n",
    "            for box in r.boxes:\n",
    "                class_id = int(box.cls[0])\n",
    "                class_name = yolo_model.names[class_id]\n",
    "                confidence = float(box.conf[0])\n",
    "                detected_objects.append({'class': class_name, 'confidence': confidence})\n",
    "        \n",
    "        # 4. åˆ†é¡å®Ÿé¨“\n",
    "        if semantic_category in SEMANTIC_CATEGORIES:\n",
    "            category_labels = SEMANTIC_CATEGORIES[semantic_category]\n",
    "            \n",
    "            # æ±ç”¨ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ\n",
    "            general_label, general_confidence = self.classify_with_clip(image, category_labels)\n",
    "            \n",
    "            # ç‰¹åŒ–ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ\n",
    "            specialized_prefix = self.get_specialized_approach(semantic_category)\n",
    "            specialized_label, specialized_confidence = self.classify_with_clip(\n",
    "                image, category_labels, specialized_prefix\n",
    "            )\n",
    "            \n",
    "            # æ”¹å–„ç‡è¨ˆç®—\n",
    "            improvement_rate = (specialized_confidence - general_confidence) / general_confidence * 100\n",
    "        else:\n",
    "            general_label = general_confidence = specialized_label = specialized_confidence = None\n",
    "            improvement_rate = 0\n",
    "        \n",
    "        # çµæœè¨˜éŒ²\n",
    "        result = {\n",
    "            'image_path': image_path,\n",
    "            'caption': caption,\n",
    "            'semantic_category': semantic_category,\n",
    "            'detected_objects': detected_objects,\n",
    "            'general_label': general_label,\n",
    "            'general_confidence': general_confidence,\n",
    "            'specialized_label': specialized_label,\n",
    "            'specialized_confidence': specialized_confidence,\n",
    "            'improvement_rate': improvement_rate\n",
    "        }\n",
    "        \n",
    "        self.results.append(result)\n",
    "        return result\n",
    "\n",
    "# åˆ†é¡å™¨åˆæœŸåŒ–\n",
    "classifier = SemanticImageClassifier()\n",
    "print(\"âœ… ç”»åƒåˆ†é¡ã‚·ã‚¹ãƒ†ãƒ æº–å‚™å®Œäº†\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. ç”»åƒã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã¨å‡¦ç†"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ç”»åƒã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰\n",
    "if IN_COLAB:\n",
    "    from google.colab import files\n",
    "    print(\"ğŸ“¸ ç ”ç©¶ç”¨ç”»åƒã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ï¼ˆè¤‡æ•°é¸æŠå¯èƒ½ï¼‰:\")\n",
    "    uploaded = files.upload()\n",
    "    \n",
    "    uploaded_files = list(uploaded.keys())\n",
    "    print(f\"âœ… {len(uploaded_files)}å€‹ã®ç”»åƒãŒã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚Œã¾ã—ãŸ\")\n",
    "    \n",
    "    for filename in uploaded_files:\n",
    "        print(f\"  - {filename}\")\n",
    "else:\n",
    "    # ãƒ­ãƒ¼ã‚«ãƒ«ç’°å¢ƒç”¨ã®ã‚µãƒ³ãƒ—ãƒ«\n",
    "    uploaded_files = ['sample1.jpg', 'sample2.jpg']  # å®Ÿéš›ã®ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã«å¤‰æ›´\n",
    "    print(\"ãƒ­ãƒ¼ã‚«ãƒ«ç’°å¢ƒ: ã‚µãƒ³ãƒ—ãƒ«ç”»åƒã‚’ä½¿ç”¨\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ç”»åƒå‡¦ç†å®Ÿè¡Œ\n",
    "print(\"ğŸ”¬ ç”»åƒåˆ†æã‚’é–‹å§‹...\")\n",
    "\n",
    "for i, filename in enumerate(uploaded_files):\n",
    "    print(f\"\\nğŸ“Š å‡¦ç†ä¸­ ({i+1}/{len(uploaded_files)}): {filename}\")\n",
    "    \n",
    "    try:\n",
    "        result = classifier.process_image(filename)\n",
    "        \n",
    "        # çµæœè¡¨ç¤º\n",
    "        print(f\"  ğŸ“ ã‚­ãƒ£ãƒ—ã‚·ãƒ§ãƒ³: {result['caption']}\")\n",
    "        print(f\"  ğŸ“‚ æ„å‘³ã‚«ãƒ†ã‚´ãƒª: {result['semantic_category']}\")\n",
    "        print(f\"  ğŸ¯ æ¤œå‡ºç‰©ä½“æ•°: {len(result['detected_objects'])}\")\n",
    "        \n",
    "        if result['general_confidence']:\n",
    "            print(f\"  ğŸ“ˆ æ±ç”¨ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ: {result['general_label']} ({result['general_confidence']:.3f})\")\n",
    "            print(f\"  ğŸš€ ç‰¹åŒ–ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ: {result['specialized_label']} ({result['specialized_confidence']:.3f})\")\n",
    "            print(f\"  ğŸ“Š æ”¹å–„ç‡: {result['improvement_rate']:.2f}%\")\n",
    "        \n",
    "        # ç”»åƒè¡¨ç¤º\n",
    "        img = Image.open(filename)\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        plt.imshow(img)\n",
    "        plt.title(f\"{filename}\\n{result['caption']}\")\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"  âŒ ã‚¨ãƒ©ãƒ¼: {e}\")\n",
    "\n",
    "print(f\"\\nâœ… å…¨{len(uploaded_files)}ç”»åƒã®å‡¦ç†å®Œäº†\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. ç ”ç©¶çµæœã®åˆ†æ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# çµæœã‚’DataFrameã«å¤‰æ›\n",
    "if classifier.results:\n",
    "    df = pd.DataFrame(classifier.results)\n",
    "    \n",
    "    # åŸºæœ¬çµ±è¨ˆ\n",
    "    print(\"ğŸ“Š ç ”ç©¶çµæœçµ±è¨ˆ:\")\n",
    "    print(f\"  - å‡¦ç†ç”»åƒæ•°: {len(df)}\")\n",
    "    print(f\"  - æ¤œå‡ºã‚«ãƒ†ã‚´ãƒªæ•°: {df['semantic_category'].nunique()}\")\n",
    "    \n",
    "    # æ”¹å–„ç‡ã®çµ±è¨ˆ\n",
    "    valid_improvements = df[df['improvement_rate'] != 0]['improvement_rate']\n",
    "    if len(valid_improvements) > 0:\n",
    "        print(f\"  - å¹³å‡æ”¹å–„ç‡: {valid_improvements.mean():.2f}%\")\n",
    "        print(f\"  - æ”¹å–„ç‡æ¨™æº–åå·®: {valid_improvements.std():.2f}%\")\n",
    "        print(f\"  - æœ€å¤§æ”¹å–„ç‡: {valid_improvements.max():.2f}%\")\n",
    "        print(f\"  - æœ€å°æ”¹å–„ç‡: {valid_improvements.min():.2f}%\")\n",
    "    \n",
    "    # ã‚«ãƒ†ã‚´ãƒªåˆ¥çµ±è¨ˆ\n",
    "    print(\"\\nğŸ“ˆ ã‚«ãƒ†ã‚´ãƒªåˆ¥åˆ†æ:\")\n",
    "    category_stats = df.groupby('semantic_category').agg({\n",
    "        'improvement_rate': ['count', 'mean', 'std'],\n",
    "        'general_confidence': 'mean',\n",
    "        'specialized_confidence': 'mean'\n",
    "    }).round(3)\n",
    "    \n",
    "    print(category_stats)\n",
    "    \n",
    "    # è©³ç´°çµæœè¡¨ç¤º\n",
    "    print(\"\\nğŸ“‹ è©³ç´°çµæœ:\")\n",
    "    display_df = df[['image_path', 'semantic_category', 'general_confidence', \n",
    "                     'specialized_confidence', 'improvement_rate']].round(3)\n",
    "    print(display_df)\n",
    "    \n",
    "else:\n",
    "    print(\"âŒ åˆ†æã™ã‚‹çµæœãŒã‚ã‚Šã¾ã›ã‚“\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. å¯è¦–åŒ–ã‚°ãƒ©ãƒ•ä½œæˆ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ã‚°ãƒ©ãƒ•ä½œæˆ\n",
    "if classifier.results and len(classifier.results) > 1:\n",
    "    plt.style.use('default')\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "    \n",
    "    # 1. æ”¹å–„ç‡åˆ†å¸ƒ\n",
    "    valid_improvements = df[df['improvement_rate'] != 0]['improvement_rate']\n",
    "    if len(valid_improvements) > 0:\n",
    "        axes[0, 0].hist(valid_improvements, bins=10, alpha=0.7, color='skyblue', edgecolor='black')\n",
    "        axes[0, 0].set_title('æ”¹å–„ç‡åˆ†å¸ƒ')\n",
    "        axes[0, 0].set_xlabel('æ”¹å–„ç‡ (%)')\n",
    "        axes[0, 0].set_ylabel('é »åº¦')\n",
    "        axes[0, 0].axvline(valid_improvements.mean(), color='red', linestyle='--', \n",
    "                          label=f'å¹³å‡: {valid_improvements.mean():.1f}%')\n",
    "        axes[0, 0].legend()\n",
    "    \n",
    "    # 2. ã‚«ãƒ†ã‚´ãƒªåˆ¥æ”¹å–„ç‡\n",
    "    category_improvement = df[df['improvement_rate'] != 0].groupby('semantic_category')['improvement_rate'].mean()\n",
    "    if len(category_improvement) > 0:\n",
    "        category_improvement.plot(kind='bar', ax=axes[0, 1], color='lightgreen')\n",
    "        axes[0, 1].set_title('ã‚«ãƒ†ã‚´ãƒªåˆ¥å¹³å‡æ”¹å–„ç‡')\n",
    "        axes[0, 1].set_xlabel('æ„å‘³ã‚«ãƒ†ã‚´ãƒª')\n",
    "        axes[0, 1].set_ylabel('å¹³å‡æ”¹å–„ç‡ (%)')\n",
    "        axes[0, 1].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # 3. ç¢ºä¿¡åº¦æ¯”è¼ƒ\n",
    "    valid_confidences = df[(df['general_confidence'].notna()) & (df['specialized_confidence'].notna())]\n",
    "    if len(valid_confidences) > 0:\n",
    "        axes[1, 0].scatter(valid_confidences['general_confidence'], \n",
    "                          valid_confidences['specialized_confidence'], alpha=0.7)\n",
    "        axes[1, 0].plot([0, 1], [0, 1], 'r--', alpha=0.8)\n",
    "        axes[1, 0].set_title('ç¢ºä¿¡åº¦æ¯”è¼ƒ')\n",
    "        axes[1, 0].set_xlabel('æ±ç”¨ã‚¢ãƒ—ãƒ­ãƒ¼ãƒç¢ºä¿¡åº¦')\n",
    "        axes[1, 0].set_ylabel('ç‰¹åŒ–ã‚¢ãƒ—ãƒ­ãƒ¼ãƒç¢ºä¿¡åº¦')\n",
    "        axes[1, 0].set_xlim(0, 1)\n",
    "        axes[1, 0].set_ylim(0, 1)\n",
    "    \n",
    "    # 4. ã‚«ãƒ†ã‚´ãƒªåˆ†å¸ƒ\n",
    "    category_counts = df['semantic_category'].value_counts()\n",
    "    axes[1, 1].pie(category_counts.values, labels=category_counts.index, autopct='%1.1f%%')\n",
    "    axes[1, 1].set_title('æ„å‘³ã‚«ãƒ†ã‚´ãƒªåˆ†å¸ƒ')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # çµ±è¨ˆçš„æ¤œå®š\n",
    "    if len(valid_confidences) > 1:\n",
    "        t_stat, p_value = stats.ttest_rel(valid_confidences['specialized_confidence'], \n",
    "                                         valid_confidences['general_confidence'])\n",
    "        print(f\"\\nğŸ“Š çµ±è¨ˆçš„æ¤œå®šçµæœ:\")\n",
    "        print(f\"  - tçµ±è¨ˆé‡: {t_stat:.4f}\")\n",
    "        print(f\"  - på€¤: {p_value:.4f}\")\n",
    "        print(f\"  - æœ‰æ„æ€§: {'æœ‰æ„ (p < 0.05)' if p_value < 0.05 else 'éæœ‰æ„ (p >= 0.05)'}\")\n",
    "\n",
    "else:\n",
    "    print(\"âŒ ã‚°ãƒ©ãƒ•ä½œæˆã«ååˆ†ãªãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. çµæœã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# çµæœã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜\n",
    "if classifier.results:\n",
    "    # CSVå½¢å¼ã§ä¿å­˜\n",
    "    df.to_csv('research_results.csv', index=False, encoding='utf-8')\n",
    "    \n",
    "    # JSONå½¢å¼ã§ä¿å­˜\n",
    "    with open('research_results.json', 'w', encoding='utf-8') as f:\n",
    "        json.dump(classifier.results, f, ensure_ascii=False, indent=2)\n",
    "    \n",
    "    # çµ±è¨ˆã‚µãƒãƒªãƒ¼ä¿å­˜\n",
    "    summary = {\n",
    "        'total_images': len(df),\n",
    "        'categories_detected': df['semantic_category'].nunique(),\n",
    "        'average_improvement': valid_improvements.mean() if len(valid_improvements) > 0 else 0,\n",
    "        'improvement_std': valid_improvements.std() if len(valid_improvements) > 0 else 0,\n",
    "        'category_distribution': df['semantic_category'].value_counts().to_dict(),\n",
    "        'statistical_test': {\n",
    "            't_statistic': t_stat if 't_stat' in locals() else None,\n",
    "            'p_value': p_value if 'p_value' in locals() else None\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    with open('research_summary.json', 'w', encoding='utf-8') as f:\n",
    "        json.dump(summary, f, ensure_ascii=False, indent=2)\n",
    "    \n",
    "    print(\"âœ… çµæœãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜å®Œäº†:\")\n",
    "    print(\"  - research_results.csv\")\n",
    "    print(\"  - research_results.json\")\n",
    "    print(\"  - research_summary.json\")\n",
    "    \n",
    "    # Colabã‹ã‚‰ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰\n",
    "    if IN_COLAB:\n",
    "        from google.colab import files\n",
    "        files.download('research_results.csv')\n",
    "        files.download('research_results.json')\n",
    "        files.download('research_summary.json')\n",
    "        print(\"âœ… ãƒ•ã‚¡ã‚¤ãƒ«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å®Œäº†\")\n",
    "    \n",
    "    # Google Driveã«ã‚‚ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—\n",
    "    if IN_COLAB and os.path.exists('/content/drive/MyDrive'):\n",
    "        import shutil\n",
    "        backup_dir = '/content/drive/MyDrive/research_backup'\n",
    "        os.makedirs(backup_dir, exist_ok=True)\n",
    "        \n",
    "        shutil.copy('research_results.csv', backup_dir)\n",
    "        shutil.copy('research_results.json', backup_dir)\n",
    "        shutil.copy('research_summary.json', backup_dir)\n",
    "        print(\"âœ… Google Driveãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—å®Œäº†\")\n",
    "\n",
    "else:\n",
    "    print(\"âŒ ä¿å­˜ã™ã‚‹çµæœãŒã‚ã‚Šã¾ã›ã‚“\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. ç ”ç©¶çµæœã‚µãƒãƒªãƒ¼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æœ€çµ‚çš„ãªç ”ç©¶çµæœã‚µãƒãƒªãƒ¼\n",
    "print(\"=\"*60)\n",
    "print(\"ğŸ“ æ„å‘³ã‚«ãƒ†ã‚´ãƒªç”»åƒåˆ†é¡ç ”ç©¶ - æœ€çµ‚çµæœ\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "if classifier.results:\n",
    "    print(f\"\\nğŸ“Š å®Ÿé¨“æ¦‚è¦:\")\n",
    "    print(f\"  - å‡¦ç†ç”»åƒæ•°: {len(df)}\")\n",
    "    print(f\"  - æ¤œå‡ºã‚«ãƒ†ã‚´ãƒªæ•°: {df['semantic_category'].nunique()}\")\n",
    "    print(f\"  - ä½¿ç”¨AIæŠ€è¡“: BLIP, CLIP, YOLO, WordNet\")\n",
    "    \n",
    "    if len(valid_improvements) > 0:\n",
    "        print(f\"\\nğŸš€ ç‰¹åŒ–ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã®åŠ¹æœ:\")\n",
    "        print(f\"  - å¹³å‡æ”¹å–„ç‡: {valid_improvements.mean():.2f}%\")\n",
    "        print(f\"  - æ”¹å–„ã‚’ç¤ºã—ãŸç”»åƒ: {len(valid_improvements[valid_improvements > 0])}/{len(valid_improvements)}\")\n",
    "        print(f\"  - æœ€å¤§æ”¹å–„ç‡: {valid_improvements.max():.2f}%\")\n",
    "        \n",
    "        if 'p_value' in locals() and p_value < 0.05:\n",
    "            print(f\"  - çµ±è¨ˆçš„æœ‰æ„æ€§: æœ‰æ„ (p = {p_value:.4f})\")\n",
    "            print(f\"  - çµè«–: ç‰¹åŒ–ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã¯çµ±è¨ˆçš„ã«æœ‰æ„ãªæ”¹å–„ã‚’ç¤ºã—ãŸ\")\n",
    "        else:\n",
    "            print(f\"  - çµ±è¨ˆçš„æœ‰æ„æ€§: éæœ‰æ„ (p = {p_value:.4f})\" if 'p_value' in locals() else \"  - çµ±è¨ˆçš„æ¤œå®š: ãƒ‡ãƒ¼ã‚¿ä¸è¶³\")\n",
    "    \n",
    "    print(f\"\\nğŸ“ˆ ã‚«ãƒ†ã‚´ãƒªåˆ¥çµæœ:\")\n",
    "    for category in df['semantic_category'].unique():\n",
    "        cat_data = df[df['semantic_category'] == category]\n",
    "        cat_improvements = cat_data[cat_data['improvement_rate'] != 0]['improvement_rate']\n",
    "        if len(cat_improvements) > 0:\n",
    "            print(f\"  - {category}: {len(cat_data)}ç”»åƒ, å¹³å‡æ”¹å–„ç‡ {cat_improvements.mean():.2f}%\")\n",
    "        else:\n",
    "            print(f\"  - {category}: {len(cat_data)}ç”»åƒ, æ”¹å–„ç‡ãƒ‡ãƒ¼ã‚¿ãªã—\")\n",
    "    \n",
    "    print(f\"\\nğŸ“‹ ä»Šå¾Œã®ç ”ç©¶æ–¹å‘:\")\n",
    "    print(f\"  - ã‚ˆã‚Šå¤§è¦æ¨¡ãªãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ã®æ¤œè¨¼\")\n",
    "    print(f\"  - è¿½åŠ ã®æ„å‘³ã‚«ãƒ†ã‚´ãƒªã®æ¢ç´¢\")\n",
    "    print(f\"  - ã‚ˆã‚Šé«˜åº¦ãªç‰¹åŒ–ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã®é–‹ç™º\")\n",
    "    print(f\"  - å®Ÿä¸–ç•Œã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã¸ã®å¿œç”¨\")\n",
    "    \n",
    "else:\n",
    "    print(\"âŒ ç ”ç©¶çµæœãŒã‚ã‚Šã¾ã›ã‚“ã€‚ç”»åƒã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦å®Ÿé¨“ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚\")\n",
    "\n",
    "print(\"\\nâœ… ç ”ç©¶å®Ÿé¨“å®Œäº†ï¼\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}