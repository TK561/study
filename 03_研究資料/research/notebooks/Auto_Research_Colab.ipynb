{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸ¤– è‡ªå‹•ç ”ç©¶å®Ÿè¡Œã‚·ã‚¹ãƒ†ãƒ  - Colabç‰ˆ\n",
    "\n",
    "**ãƒ¯ãƒ³ã‚¯ãƒªãƒƒã‚¯ã§ç ”ç©¶ã‚’è‡ªå‹•å®Ÿè¡Œ**ã™ã‚‹Colabãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã§ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸš€ è‡ªå‹•å®Ÿè¡Œãƒˆãƒªã‚¬ãƒ¼ - ã“ã®ã‚»ãƒ«ã‚’å®Ÿè¡Œã™ã‚‹ã ã‘ï¼\n",
    "\n",
    "AUTO_RUN = True  # ã“ã‚Œã‚’Trueã«ã™ã‚‹ã ã‘ã§å…¨è‡ªå‹•å®Ÿè¡Œ\n",
    "UPLOAD_IMAGES = True  # ç”»åƒã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã‚‚è‡ªå‹•åŒ–\n",
    "SAVE_TO_DRIVE = True  # Google Driveã«è‡ªå‹•ä¿å­˜\n",
    "\n",
    "print(\"ğŸ¯ è‡ªå‹•ç ”ç©¶ã‚·ã‚¹ãƒ†ãƒ ã‚’é–‹å§‹ã—ã¾ã™...\")\n",
    "print(f\"ğŸ“Š è‡ªå‹•å®Ÿè¡Œ: {'æœ‰åŠ¹' if AUTO_RUN else 'ç„¡åŠ¹'}\")\n",
    "print(f\"ğŸ“¸ ç”»åƒã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰: {'è‡ªå‹•' if UPLOAD_IMAGES else 'æ‰‹å‹•'}\")\n",
    "print(f\"ğŸ’¾ Driveä¿å­˜: {'æœ‰åŠ¹' if SAVE_TO_DRIVE else 'ç„¡åŠ¹'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ç’°å¢ƒè‡ªå‹•ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—\n",
    "if AUTO_RUN:\n",
    "    print(\"ğŸ”§ ç’°å¢ƒã‚’è‡ªå‹•ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ä¸­...\")\n",
    "    \n",
    "    # Colabç’°å¢ƒç¢ºèª\n",
    "    try:\n",
    "        import google.colab\n",
    "        IN_COLAB = True\n",
    "        print(\"âœ… Google Colabç’°å¢ƒç¢ºèª\")\n",
    "    except:\n",
    "        IN_COLAB = False\n",
    "        print(\"âŒ ãƒ­ãƒ¼ã‚«ãƒ«ç’°å¢ƒã§å®Ÿè¡Œ\")\n",
    "    \n",
    "    # å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ä¸€æ‹¬ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«\n",
    "    if IN_COLAB:\n",
    "        import subprocess\n",
    "        import sys\n",
    "        \n",
    "        packages = [\n",
    "            'torch', 'torchvision', 'torchaudio',\n",
    "            'transformers', 'ultralytics', 'opencv-python',\n",
    "            'pillow', 'matplotlib', 'seaborn', 'pandas',\n",
    "            'numpy', 'nltk', 'scipy', 'scikit-learn'\n",
    "        ]\n",
    "        \n",
    "        for package in packages:\n",
    "            subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package, \"-q\"])\n",
    "        \n",
    "        print(\"âœ… ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«å®Œäº†\")\n",
    "    \n",
    "    # Google Driveè‡ªå‹•ãƒã‚¦ãƒ³ãƒˆ\n",
    "    if SAVE_TO_DRIVE and IN_COLAB:\n",
    "        from google.colab import drive\n",
    "        drive.mount('/content/drive', force_remount=True)\n",
    "        print(\"âœ… Google Driveè‡ªå‹•æ¥ç¶šå®Œäº†\")\n",
    "    \n",
    "    print(\"ğŸ‰ è‡ªå‹•ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—å®Œäº†ï¼\")\n",
    "else:\n",
    "    print(\"â¸ï¸ æ‰‹å‹•ãƒ¢ãƒ¼ãƒ‰ - å¿…è¦ã«å¿œã˜ã¦ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ã—ã¦ãã ã•ã„\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ç ”ç©¶ã‚·ã‚¹ãƒ†ãƒ è‡ªå‹•åˆæœŸåŒ–\n",
    "if AUTO_RUN:\n",
    "    print(\"ğŸ¤– AIç ”ç©¶ã‚·ã‚¹ãƒ†ãƒ ã‚’è‡ªå‹•åˆæœŸåŒ–ä¸­...\")\n",
    "    \n",
    "    # å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚¤ãƒ³ãƒãƒ¼ãƒˆ\n",
    "    import torch\n",
    "    import torch.nn as nn\n",
    "    from transformers import BlipProcessor, BlipForConditionalGeneration\n",
    "    from transformers import CLIPProcessor, CLIPModel\n",
    "    from ultralytics import YOLO\n",
    "    import cv2\n",
    "    from PIL import Image\n",
    "    import matplotlib.pyplot as plt\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import json\n",
    "    import nltk\n",
    "    import seaborn as sns\n",
    "    from scipy import stats\n",
    "    import os\n",
    "    import warnings\n",
    "    warnings.filterwarnings('ignore')\n",
    "    \n",
    "    # ãƒ‡ãƒã‚¤ã‚¹è‡ªå‹•è¨­å®š\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"ğŸ”¥ ä½¿ç”¨ãƒ‡ãƒã‚¤ã‚¹: {device}\")\n",
    "    \n",
    "    # NLTKè‡ªå‹•ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰\n",
    "    nltk.download('wordnet', quiet=True)\n",
    "    nltk.download('omw-1.4', quiet=True)\n",
    "    from nltk.corpus import wordnet as wn\n",
    "    \n",
    "    # AIãƒ¢ãƒ‡ãƒ«è‡ªå‹•åˆæœŸåŒ–\n",
    "    print(\"ğŸ§  AIãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã¿ä¸­...\")\n",
    "    blip_processor = BlipProcessor.from_pretrained(\"Salesforce/blip-image-captioning-base\")\n",
    "    blip_model = BlipForConditionalGeneration.from_pretrained(\"Salesforce/blip-image-captioning-base\").to(device)\n",
    "    \n",
    "    clip_processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "    clip_model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\").to(device)\n",
    "    \n",
    "    yolo_model = YOLO('yolov8n.pt')\n",
    "    \n",
    "    print(\"âœ… AIç ”ç©¶ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–å®Œäº†ï¼\")\n",
    "else:\n",
    "    print(\"â¸ï¸ æ‰‹å‹•ãƒ¢ãƒ¼ãƒ‰ - AIãƒ¢ãƒ‡ãƒ«ã‚’æ‰‹å‹•ã§åˆæœŸåŒ–ã—ã¦ãã ã•ã„\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# è‡ªå‹•ç ”ç©¶ã‚·ã‚¹ãƒ†ãƒ ã‚¯ãƒ©ã‚¹\n",
    "if AUTO_RUN:\n",
    "    class AutoResearchSystem:\n",
    "        def __init__(self):\n",
    "            self.results = []\n",
    "            self.categories = {\n",
    "                'person': ['person', 'man', 'woman', 'child', 'people', 'human', 'face'],\n",
    "                'animal': ['dog', 'cat', 'bird', 'horse', 'cow', 'elephant', 'bear'],\n",
    "                'food': ['pizza', 'hamburger', 'cake', 'apple', 'banana', 'sandwich'],\n",
    "                'vehicle': ['car', 'bus', 'truck', 'motorcycle', 'bicycle', 'airplane'],\n",
    "                'building': ['house', 'building', 'bridge', 'castle', 'church'],\n",
    "                'furniture': ['chair', 'table', 'sofa', 'bed', 'desk'],\n",
    "                'plant': ['tree', 'flower', 'grass', 'plant', 'garden'],\n",
    "                'landscape': ['mountain', 'beach', 'lake', 'river', 'sky']\n",
    "            }\n",
    "            print(\"ğŸ”¬ è‡ªå‹•ç ”ç©¶ã‚·ã‚¹ãƒ†ãƒ æº–å‚™å®Œäº†\")\n",
    "        \n",
    "        def auto_analyze_image(self, image_path):\n",
    "            \"\"\"ç”»åƒã‚’è‡ªå‹•åˆ†æ\"\"\"\n",
    "            try:\n",
    "                # ç”»åƒèª­ã¿è¾¼ã¿\n",
    "                image = Image.open(image_path).convert('RGB')\n",
    "                \n",
    "                # 1. ã‚­ãƒ£ãƒ—ã‚·ãƒ§ãƒ³è‡ªå‹•ç”Ÿæˆ\n",
    "                inputs = blip_processor(image, return_tensors=\"pt\").to(device)\n",
    "                out = blip_model.generate(**inputs, max_length=50)\n",
    "                caption = blip_processor.decode(out[0], skip_special_tokens=True)\n",
    "                \n",
    "                # 2. æ„å‘³ã‚«ãƒ†ã‚´ãƒªè‡ªå‹•æ¤œå‡º\n",
    "                caption_lower = caption.lower()\n",
    "                detected_category = 'general'\n",
    "                max_score = 0\n",
    "                \n",
    "                for category, keywords in self.categories.items():\n",
    "                    score = sum(1 for keyword in keywords if keyword in caption_lower)\n",
    "                    if score > max_score:\n",
    "                        max_score = score\n",
    "                        detected_category = category\n",
    "                \n",
    "                # 3. åˆ†é¡å®Ÿé¨“è‡ªå‹•å®Ÿè¡Œ\n",
    "                if detected_category in self.categories:\n",
    "                    labels = self.categories[detected_category]\n",
    "                    \n",
    "                    # æ±ç”¨ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ\n",
    "                    general_inputs = clip_processor(text=labels, images=image, return_tensors=\"pt\", padding=True).to(device)\n",
    "                    with torch.no_grad():\n",
    "                        general_outputs = clip_model(**general_inputs)\n",
    "                        general_probs = general_outputs.logits_per_image.softmax(dim=1)\n",
    "                        general_confidence = general_probs.max().item()\n",
    "                        general_label = labels[general_probs.argmax().item()]\n",
    "                    \n",
    "                    # ç‰¹åŒ–ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ\n",
    "                    specialized_labels = [f\"a photo of {detected_category}: {label}\" for label in labels]\n",
    "                    spec_inputs = clip_processor(text=specialized_labels, images=image, return_tensors=\"pt\", padding=True).to(device)\n",
    "                    with torch.no_grad():\n",
    "                        spec_outputs = clip_model(**spec_inputs)\n",
    "                        spec_probs = spec_outputs.logits_per_image.softmax(dim=1)\n",
    "                        specialized_confidence = spec_probs.max().item()\n",
    "                        specialized_label = labels[spec_probs.argmax().item()]\n",
    "                    \n",
    "                    # æ”¹å–„ç‡è¨ˆç®—\n",
    "                    improvement = (specialized_confidence - general_confidence) / general_confidence * 100\n",
    "                else:\n",
    "                    general_label = general_confidence = specialized_label = specialized_confidence = None\n",
    "                    improvement = 0\n",
    "                \n",
    "                # çµæœè¨˜éŒ²\n",
    "                result = {\n",
    "                    'image': image_path,\n",
    "                    'caption': caption,\n",
    "                    'category': detected_category,\n",
    "                    'general_label': general_label,\n",
    "                    'general_confidence': general_confidence,\n",
    "                    'specialized_label': specialized_label,\n",
    "                    'specialized_confidence': specialized_confidence,\n",
    "                    'improvement_rate': improvement\n",
    "                }\n",
    "                \n",
    "                self.results.append(result)\n",
    "                return result\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"âŒ ã‚¨ãƒ©ãƒ¼: {e}\")\n",
    "                return None\n",
    "        \n",
    "        def auto_visualize_results(self):\n",
    "            \"\"\"çµæœã‚’è‡ªå‹•å¯è¦–åŒ–\"\"\"\n",
    "            if not self.results:\n",
    "                print(\"âŒ åˆ†æçµæœãŒã‚ã‚Šã¾ã›ã‚“\")\n",
    "                return\n",
    "            \n",
    "            df = pd.DataFrame(self.results)\n",
    "            \n",
    "            # çµ±è¨ˆè¡¨ç¤º\n",
    "            valid_improvements = df[df['improvement_rate'] != 0]['improvement_rate']\n",
    "            print(f\"\\nğŸ“Š è‡ªå‹•åˆ†æçµæœ:\")\n",
    "            print(f\"  å‡¦ç†ç”»åƒæ•°: {len(df)}\")\n",
    "            print(f\"  å¹³å‡æ”¹å–„ç‡: {valid_improvements.mean():.2f}%\")\n",
    "            print(f\"  æœ€å¤§æ”¹å–„ç‡: {valid_improvements.max():.2f}%\")\n",
    "            \n",
    "            # è‡ªå‹•ã‚°ãƒ©ãƒ•ç”Ÿæˆ\n",
    "            plt.figure(figsize=(12, 8))\n",
    "            \n",
    "            # æ”¹å–„ç‡åˆ†å¸ƒ\n",
    "            plt.subplot(2, 2, 1)\n",
    "            plt.hist(valid_improvements, bins=10, alpha=0.7, color='skyblue')\n",
    "            plt.title('æ”¹å–„ç‡åˆ†å¸ƒ')\n",
    "            plt.xlabel('æ”¹å–„ç‡ (%)')\n",
    "            \n",
    "            # ã‚«ãƒ†ã‚´ãƒªåˆ¥æ”¹å–„ç‡\n",
    "            plt.subplot(2, 2, 2)\n",
    "            category_improvement = df[df['improvement_rate'] != 0].groupby('category')['improvement_rate'].mean()\n",
    "            category_improvement.plot(kind='bar', color='lightgreen')\n",
    "            plt.title('ã‚«ãƒ†ã‚´ãƒªåˆ¥æ”¹å–„ç‡')\n",
    "            plt.xticks(rotation=45)\n",
    "            \n",
    "            # ã‚«ãƒ†ã‚´ãƒªåˆ†å¸ƒ\n",
    "            plt.subplot(2, 2, 3)\n",
    "            df['category'].value_counts().plot(kind='pie', autopct='%1.1f%%')\n",
    "            plt.title('ã‚«ãƒ†ã‚´ãƒªåˆ†å¸ƒ')\n",
    "            \n",
    "            # ç¢ºä¿¡åº¦æ¯”è¼ƒ\n",
    "            plt.subplot(2, 2, 4)\n",
    "            valid_data = df[(df['general_confidence'].notna()) & (df['specialized_confidence'].notna())]\n",
    "            plt.scatter(valid_data['general_confidence'], valid_data['specialized_confidence'])\n",
    "            plt.plot([0, 1], [0, 1], 'r--')\n",
    "            plt.title('ç¢ºä¿¡åº¦æ¯”è¼ƒ')\n",
    "            plt.xlabel('æ±ç”¨ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ')\n",
    "            plt.ylabel('ç‰¹åŒ–ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ')\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "            \n",
    "            return df\n",
    "        \n",
    "        def auto_save_results(self):\n",
    "            \"\"\"çµæœã‚’è‡ªå‹•ä¿å­˜\"\"\"\n",
    "            if not self.results:\n",
    "                return\n",
    "            \n",
    "            # CSVä¿å­˜\n",
    "            df = pd.DataFrame(self.results)\n",
    "            df.to_csv('auto_research_results.csv', index=False)\n",
    "            \n",
    "            # JSONä¿å­˜\n",
    "            with open('auto_research_results.json', 'w', encoding='utf-8') as f:\n",
    "                json.dump(self.results, f, ensure_ascii=False, indent=2)\n",
    "            \n",
    "            print(\"âœ… çµæœã‚’è‡ªå‹•ä¿å­˜ã—ã¾ã—ãŸ\")\n",
    "            \n",
    "            # Colabè‡ªå‹•ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰\n",
    "            if IN_COLAB:\n",
    "                from google.colab import files\n",
    "                files.download('auto_research_results.csv')\n",
    "                files.download('auto_research_results.json')\n",
    "                print(\"ğŸ“¥ ãƒ•ã‚¡ã‚¤ãƒ«ã‚’è‡ªå‹•ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¾ã—ãŸ\")\n",
    "            \n",
    "            # Google Driveè‡ªå‹•ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—\n",
    "            if SAVE_TO_DRIVE and IN_COLAB and os.path.exists('/content/drive/MyDrive'):\n",
    "                import shutil\n",
    "                backup_dir = '/content/drive/MyDrive/auto_research_backup'\n",
    "                os.makedirs(backup_dir, exist_ok=True)\n",
    "                shutil.copy('auto_research_results.csv', backup_dir)\n",
    "                shutil.copy('auto_research_results.json', backup_dir)\n",
    "                print(\"â˜ï¸ Google Driveã«è‡ªå‹•ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã—ã¾ã—ãŸ\")\n",
    "    \n",
    "    # ç ”ç©¶ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–\n",
    "    research_system = AutoResearchSystem()\n",
    "    print(\"ğŸ¯ è‡ªå‹•ç ”ç©¶ã‚·ã‚¹ãƒ†ãƒ æº–å‚™å®Œäº†ï¼\")\n",
    "else:\n",
    "    print(\"â¸ï¸ æ‰‹å‹•ãƒ¢ãƒ¼ãƒ‰\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸš€ ãƒ¡ã‚¤ãƒ³è‡ªå‹•å®Ÿè¡Œã‚»ãƒ« - ã“ã“ã ã‘å®Ÿè¡Œã™ã‚Œã°å…¨ã¦å®Œäº†ï¼\n",
    "\n",
    "if AUTO_RUN:\n",
    "    print(\"ğŸ¯ è‡ªå‹•ç ”ç©¶ã‚’é–‹å§‹ã—ã¾ã™ï¼\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # 1. ç”»åƒè‡ªå‹•ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰\n",
    "    if UPLOAD_IMAGES and IN_COLAB:\n",
    "        print(\"ğŸ“¸ ç ”ç©¶ç”¨ç”»åƒã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„:\")\n",
    "        from google.colab import files\n",
    "        uploaded = files.upload()\n",
    "        image_files = list(uploaded.keys())\n",
    "        print(f\"âœ… {len(image_files)}å€‹ã®ç”»åƒã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¾ã—ãŸ\")\n",
    "    else:\n",
    "        # ã‚µãƒ³ãƒ—ãƒ«ç”»åƒï¼ˆå®Ÿéš›ã®ä½¿ç”¨æ™‚ã¯å‰Šé™¤ï¼‰\n",
    "        image_files = []  # ç©ºã®å ´åˆã¯ã‚µãƒ³ãƒ—ãƒ«ä½¿ç”¨\n",
    "        print(\"âš ï¸ ç”»åƒãŒã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚Œã¦ã„ã¾ã›ã‚“\")\n",
    "    \n",
    "    # 2. è‡ªå‹•ç”»åƒåˆ†æ\n",
    "    if image_files:\n",
    "        print(f\"\\nğŸ”¬ {len(image_files)}å€‹ã®ç”»åƒã‚’è‡ªå‹•åˆ†æä¸­...\")\n",
    "        for i, image_file in enumerate(image_files):\n",
    "            print(f\"ğŸ“Š åˆ†æä¸­ ({i+1}/{len(image_files)}): {image_file}\")\n",
    "            result = research_system.auto_analyze_image(image_file)\n",
    "            if result:\n",
    "                print(f\"  âœ… ã‚«ãƒ†ã‚´ãƒª: {result['category']}\")\n",
    "                print(f\"  ğŸ“ˆ æ”¹å–„ç‡: {result['improvement_rate']:.2f}%\")\n",
    "        \n",
    "        # 3. çµæœè‡ªå‹•å¯è¦–åŒ–\n",
    "        print(\"\\nğŸ“Š çµæœã‚’è‡ªå‹•å¯è¦–åŒ–ä¸­...\")\n",
    "        df = research_system.auto_visualize_results()\n",
    "        \n",
    "        # 4. çµæœè‡ªå‹•ä¿å­˜\n",
    "        print(\"\\nğŸ’¾ çµæœã‚’è‡ªå‹•ä¿å­˜ä¸­...\")\n",
    "        research_system.auto_save_results()\n",
    "        \n",
    "        # 5. æœ€çµ‚ã‚µãƒãƒªãƒ¼\n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(\"ğŸ‰ è‡ªå‹•ç ”ç©¶å®Œäº†ï¼\")\n",
    "        print(\"=\"*50)\n",
    "        \n",
    "        valid_improvements = df[df['improvement_rate'] != 0]['improvement_rate']\n",
    "        print(f\"ğŸ“Š æœ€çµ‚çµæœ:\")\n",
    "        print(f\"  - å‡¦ç†ç”»åƒæ•°: {len(df)}\")\n",
    "        print(f\"  - æ¤œå‡ºã‚«ãƒ†ã‚´ãƒªæ•°: {df['category'].nunique()}\")\n",
    "        if len(valid_improvements) > 0:\n",
    "            print(f\"  - å¹³å‡æ”¹å–„ç‡: {valid_improvements.mean():.2f}%\")\n",
    "            print(f\"  - æœ€å¤§æ”¹å–„ç‡: {valid_improvements.max():.2f}%\")\n",
    "            if valid_improvements.mean() > 5:\n",
    "                print(f\"  ğŸš€ ç‰¹åŒ–ã‚¢ãƒ—ãƒ­ãƒ¼ãƒãŒæœ‰åŠ¹ã§ã™ï¼\")\n",
    "            else:\n",
    "                print(f\"  ğŸ“ æ”¹å–„ã®ä½™åœ°ãŒã‚ã‚Šã¾ã™\")\n",
    "        \n",
    "        print(f\"\\nğŸ“¥ çµæœãƒ•ã‚¡ã‚¤ãƒ«:\")\n",
    "        print(f\"  - auto_research_results.csv (è‡ªå‹•ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰æ¸ˆã¿)\")\n",
    "        print(f\"  - auto_research_results.json (è‡ªå‹•ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰æ¸ˆã¿)\")\n",
    "        if SAVE_TO_DRIVE:\n",
    "            print(f\"  - Google Drive ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—å®Œäº†\")\n",
    "    \n",
    "    else:\n",
    "        print(\"âŒ åˆ†æã™ã‚‹ç”»åƒãŒã‚ã‚Šã¾ã›ã‚“\")\n",
    "        print(\"ğŸ“¸ ä¸Šã®ã‚»ãƒ«ã§ç”»åƒã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„\")\n",
    "\n",
    "else:\n",
    "    print(\"â¸ï¸ è‡ªå‹•å®Ÿè¡ŒãŒç„¡åŠ¹ã§ã™\")\n",
    "    print(\"ğŸ”§ AUTO_RUN = True ã«è¨­å®šã—ã¦å®Ÿè¡Œã—ã¦ãã ã•ã„\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ¯ ä½¿ç”¨æ–¹æ³•\n",
    "\n",
    "### ç°¡å˜3ã‚¹ãƒ†ãƒƒãƒ—ï¼\n",
    "\n",
    "1. **æœ€åˆã®ã‚»ãƒ«å®Ÿè¡Œ**: `AUTO_RUN = True` ã‚’ç¢ºèª\n",
    "2. **ç”»åƒã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰**: ç ”ç©¶ç”¨ç”»åƒã‚’é¸æŠ\n",
    "3. **è‡ªå‹•å®Ÿè¡Œå®Œäº†**: çµæœãŒè‡ªå‹•ã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰\n",
    "\n",
    "### è¨­å®šã‚ªãƒ—ã‚·ãƒ§ãƒ³\n",
    "```python\n",
    "AUTO_RUN = True      # å…¨è‡ªå‹•å®Ÿè¡Œ\n",
    "UPLOAD_IMAGES = True # ç”»åƒã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰\n",
    "SAVE_TO_DRIVE = True # Google Driveä¿å­˜\n",
    "```\n",
    "\n",
    "### å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«\n",
    "- `auto_research_results.csv` - è©³ç´°ãƒ‡ãƒ¼ã‚¿\n",
    "- `auto_research_results.json` - JSONå½¢å¼\n",
    "- Google Driveè‡ªå‹•ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—\n",
    "\n",
    "---\n",
    "**ğŸš€ ãƒ¯ãƒ³ã‚¯ãƒªãƒƒã‚¯ã§ç ”ç©¶å®Œäº†ï¼**"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}