{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸ¤– Claudeçµ±åˆç ”ç©¶ã‚·ã‚¹ãƒ†ãƒ  - Colabç‰ˆ\n",
    "\n",
    "ã“ã®ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã‚’ https://colab.research.google.com/drive/13MXbGLL56Li9WYTinOUEoqjkupjycbLr ã«è¿½åŠ ã—ã¦ãã ã•ã„ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸš€ Claudeç ”ç©¶ã‚·ã‚¹ãƒ†ãƒ  - ãƒ¯ãƒ³ã‚¯ãƒªãƒƒã‚¯å®Ÿè¡Œã‚»ãƒ«\n",
    "# ã“ã®ã‚»ãƒ«ã‚’æ—¢å­˜ã®Colabãƒ•ã‚¡ã‚¤ãƒ«ã«è¿½åŠ ã—ã¦å®Ÿè¡Œã™ã‚‹ã ã‘ï¼\n",
    "\n",
    "print(\"ğŸ¤– Claudeç ”ç©¶ã‚·ã‚¹ãƒ†ãƒ ã‚’é–‹å§‹ã—ã¾ã™...\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# 1. ç’°å¢ƒè‡ªå‹•ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—\n",
    "print(\"ğŸ”§ ç’°å¢ƒã‚’ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ä¸­...\")\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "packages = [\n",
    "    'torch', 'torchvision', 'transformers', 'ultralytics',\n",
    "    'opencv-python', 'pillow', 'matplotlib', 'seaborn', \n",
    "    'pandas', 'numpy', 'nltk', 'scipy', 'scikit-learn'\n",
    "]\n",
    "\n",
    "for package in packages:\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package, \"-q\"])\n",
    "\n",
    "print(\"âœ… ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«å®Œäº†\")\n",
    "\n",
    "# 2. å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚¤ãƒ³ãƒãƒ¼ãƒˆ\n",
    "import torch\n",
    "from transformers import BlipProcessor, BlipForConditionalGeneration, CLIPProcessor, CLIPModel\n",
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import nltk\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"ğŸ“š ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚¤ãƒ³ãƒãƒ¼ãƒˆå®Œäº†\")\n",
    "\n",
    "# 3. ãƒ‡ãƒã‚¤ã‚¹è¨­å®š\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"ğŸ”¥ ä½¿ç”¨ãƒ‡ãƒã‚¤ã‚¹: {device}\")\n",
    "\n",
    "# 4. Google Driveæ¥ç¶š\n",
    "try:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive', force_remount=True)\n",
    "    print(\"â˜ï¸ Google Driveæ¥ç¶šå®Œäº†\")\n",
    "except:\n",
    "    print(\"âš ï¸ Google Driveæ¥ç¶šã‚’ã‚¹ã‚­ãƒƒãƒ—\")\n",
    "\n",
    "print(\"\\nğŸ¯ Claudeç ”ç©¶ã‚·ã‚¹ãƒ†ãƒ æº–å‚™å®Œäº†ï¼\")\n",
    "print(\"æ¬¡ã®ã‚»ãƒ«ã§ç ”ç©¶ã‚’é–‹å§‹ã—ã¦ãã ã•ã„ã€‚\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ§  AIãƒ¢ãƒ‡ãƒ«è‡ªå‹•åˆæœŸåŒ–\n",
    "print(\"ğŸ¤– AIãƒ¢ãƒ‡ãƒ«ã‚’åˆæœŸåŒ–ä¸­...\")\n",
    "\n",
    "# NLTKæº–å‚™\n",
    "nltk.download('wordnet', quiet=True)\n",
    "nltk.download('omw-1.4', quiet=True)\n",
    "\n",
    "# BLIP (ç”»åƒã‚­ãƒ£ãƒ—ã‚·ãƒ§ãƒ³)\n",
    "print(\"ğŸ“ BLIPåˆæœŸåŒ–ä¸­...\")\n",
    "blip_processor = BlipProcessor.from_pretrained(\"Salesforce/blip-image-captioning-base\")\n",
    "blip_model = BlipForConditionalGeneration.from_pretrained(\"Salesforce/blip-image-captioning-base\").to(device)\n",
    "\n",
    "# CLIP (ç”»åƒåˆ†é¡)\n",
    "print(\"ğŸ¯ CLIPåˆæœŸåŒ–ä¸­...\")\n",
    "clip_processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "clip_model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\").to(device)\n",
    "\n",
    "# YOLO (ç‰©ä½“æ¤œå‡º)\n",
    "print(\"ğŸ” YOLOåˆæœŸåŒ–ä¸­...\")\n",
    "yolo_model = YOLO('yolov8n.pt')\n",
    "\n",
    "print(\"âœ… å…¨AIãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–å®Œäº†ï¼\")\n",
    "print(\"ğŸš€ ç ”ç©¶ã‚·ã‚¹ãƒ†ãƒ æº–å‚™å®Œäº† - æ¬¡ã®ã‚»ãƒ«ã§ç ”ç©¶é–‹å§‹ï¼\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ”¬ Claudeç ”ç©¶å®Ÿè¡Œã‚·ã‚¹ãƒ†ãƒ \n",
    "\n",
    "class ClaudeResearchSystem:\n",
    "    def __init__(self):\n",
    "        self.results = []\n",
    "        self.semantic_categories = {\n",
    "            'person': ['person', 'man', 'woman', 'child', 'people', 'human', 'face'],\n",
    "            'animal': ['dog', 'cat', 'bird', 'horse', 'cow', 'elephant', 'bear', 'lion'],\n",
    "            'food': ['pizza', 'hamburger', 'cake', 'apple', 'banana', 'sandwich', 'bread'],\n",
    "            'vehicle': ['car', 'bus', 'truck', 'motorcycle', 'bicycle', 'airplane', 'boat'],\n",
    "            'building': ['house', 'building', 'bridge', 'castle', 'church', 'tower'],\n",
    "            'furniture': ['chair', 'table', 'sofa', 'bed', 'desk', 'bench'],\n",
    "            'plant': ['tree', 'flower', 'grass', 'plant', 'garden', 'forest'],\n",
    "            'landscape': ['mountain', 'beach', 'lake', 'river', 'sky', 'sunset']\n",
    "        }\n",
    "        print(\"ğŸ”¬ Claudeç ”ç©¶ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–å®Œäº†\")\n",
    "    \n",
    "    def analyze_image(self, image_path):\n",
    "        \"\"\"ç”»åƒã‚’è©³ç´°åˆ†æ\"\"\"\n",
    "        try:\n",
    "            # ç”»åƒèª­ã¿è¾¼ã¿\n",
    "            image = Image.open(image_path).convert('RGB')\n",
    "            print(f\"ğŸ“¸ ç”»åƒèª­ã¿è¾¼ã¿: {image_path}\")\n",
    "            \n",
    "            # 1. ã‚­ãƒ£ãƒ—ã‚·ãƒ§ãƒ³ç”Ÿæˆ (BLIP)\n",
    "            inputs = blip_processor(image, return_tensors=\"pt\").to(device)\n",
    "            with torch.no_grad():\n",
    "                out = blip_model.generate(**inputs, max_length=50)\n",
    "                caption = blip_processor.decode(out[0], skip_special_tokens=True)\n",
    "            print(f\"ğŸ“ ã‚­ãƒ£ãƒ—ã‚·ãƒ§ãƒ³: {caption}\")\n",
    "            \n",
    "            # 2. æ„å‘³ã‚«ãƒ†ã‚´ãƒªæ¤œå‡º\n",
    "            detected_category = self.detect_semantic_category(caption)\n",
    "            print(f\"ğŸ“‚ æ„å‘³ã‚«ãƒ†ã‚´ãƒª: {detected_category}\")\n",
    "            \n",
    "            # 3. YOLOç‰©ä½“æ¤œå‡º\n",
    "            yolo_results = yolo_model(image_path)\n",
    "            detected_objects = []\n",
    "            for r in yolo_results:\n",
    "                for box in r.boxes:\n",
    "                    if box.conf[0] > 0.5:  # ç¢ºä¿¡åº¦50%ä»¥ä¸Š\n",
    "                        class_id = int(box.cls[0])\n",
    "                        class_name = yolo_model.names[class_id]\n",
    "                        confidence = float(box.conf[0])\n",
    "                        detected_objects.append({\n",
    "                            'class': class_name, \n",
    "                            'confidence': confidence\n",
    "                        })\n",
    "            print(f\"ğŸ” æ¤œå‡ºç‰©ä½“: {len(detected_objects)}å€‹\")\n",
    "            \n",
    "            # 4. åˆ†é¡å®Ÿé¨“ (æ±ç”¨ vs ç‰¹åŒ–)\n",
    "            if detected_category in self.semantic_categories:\n",
    "                category_labels = self.semantic_categories[detected_category]\n",
    "                \n",
    "                # æ±ç”¨ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ\n",
    "                general_result = self.classify_with_clip(image, category_labels)\n",
    "                \n",
    "                # ç‰¹åŒ–ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ\n",
    "                specialized_prefix = f\"a photo of {detected_category}: \"\n",
    "                specialized_result = self.classify_with_clip(image, category_labels, specialized_prefix)\n",
    "                \n",
    "                # æ”¹å–„ç‡è¨ˆç®—\n",
    "                improvement = (specialized_result['confidence'] - general_result['confidence']) / general_result['confidence'] * 100\n",
    "                \n",
    "                print(f\"ğŸ“Š æ±ç”¨åˆ†é¡: {general_result['label']} ({general_result['confidence']:.3f})\")\n",
    "                print(f\"ğŸš€ ç‰¹åŒ–åˆ†é¡: {specialized_result['label']} ({specialized_result['confidence']:.3f})\")\n",
    "                print(f\"ğŸ“ˆ æ”¹å–„ç‡: {improvement:.2f}%\")\n",
    "            else:\n",
    "                general_result = specialized_result = {'label': None, 'confidence': None}\n",
    "                improvement = 0\n",
    "            \n",
    "            # çµæœã¾ã¨ã‚\n",
    "            result = {\n",
    "                'image_path': image_path,\n",
    "                'caption': caption,\n",
    "                'semantic_category': detected_category,\n",
    "                'detected_objects_count': len(detected_objects),\n",
    "                'detected_objects': detected_objects,\n",
    "                'general_label': general_result['label'],\n",
    "                'general_confidence': general_result['confidence'],\n",
    "                'specialized_label': specialized_result['label'],\n",
    "                'specialized_confidence': specialized_result['confidence'],\n",
    "                'improvement_rate': improvement\n",
    "            }\n",
    "            \n",
    "            self.results.append(result)\n",
    "            \n",
    "            # ç”»åƒè¡¨ç¤º\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            plt.imshow(image)\n",
    "            title = f\"{image_path}\\n{caption}\\nã‚«ãƒ†ã‚´ãƒª: {detected_category}\\næ”¹å–„ç‡: {improvement:.1f}%\"\n",
    "            plt.title(title, fontsize=12)\n",
    "            plt.axis('off')\n",
    "            plt.show()\n",
    "            \n",
    "            return result\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"âŒ åˆ†æã‚¨ãƒ©ãƒ¼: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def detect_semantic_category(self, caption):\n",
    "        \"\"\"ã‚­ãƒ£ãƒ—ã‚·ãƒ§ãƒ³ã‹ã‚‰æ„å‘³ã‚«ãƒ†ã‚´ãƒªã‚’æ¤œå‡º\"\"\"\n",
    "        caption_lower = caption.lower()\n",
    "        \n",
    "        category_scores = {}\n",
    "        for category, keywords in self.semantic_categories.items():\n",
    "            score = sum(1 for keyword in keywords if keyword in caption_lower)\n",
    "            if score > 0:\n",
    "                category_scores[category] = score\n",
    "        \n",
    "        if category_scores:\n",
    "            return max(category_scores, key=category_scores.get)\n",
    "        return 'general'\n",
    "    \n",
    "    def classify_with_clip(self, image, labels, prefix=\"\"):\n",
    "        \"\"\"CLIPã§ç”»åƒåˆ†é¡\"\"\"\n",
    "        text_labels = [f\"{prefix}{label}\" for label in labels]\n",
    "        inputs = clip_processor(text=text_labels, images=image, return_tensors=\"pt\", padding=True).to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = clip_model(**inputs)\n",
    "            probs = outputs.logits_per_image.softmax(dim=1)\n",
    "            \n",
    "        max_idx = probs.argmax().item()\n",
    "        confidence = probs[0][max_idx].item()\n",
    "        predicted_label = labels[max_idx]\n",
    "        \n",
    "        return {'label': predicted_label, 'confidence': confidence}\n",
    "    \n",
    "    def generate_research_report(self):\n",
    "        \"\"\"ç ”ç©¶ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ\"\"\"\n",
    "        if not self.results:\n",
    "            print(\"âŒ åˆ†æçµæœãŒã‚ã‚Šã¾ã›ã‚“\")\n",
    "            return\n",
    "        \n",
    "        df = pd.DataFrame(self.results)\n",
    "        \n",
    "        print(\"\\n\" + \"=\" * 60)\n",
    "        print(\"ğŸ“Š Claudeç ”ç©¶ã‚·ã‚¹ãƒ†ãƒ  - æœ€çµ‚ãƒ¬ãƒãƒ¼ãƒˆ\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        # åŸºæœ¬çµ±è¨ˆ\n",
    "        print(f\"\\nğŸ“ˆ ç ”ç©¶çµæœã‚µãƒãƒªãƒ¼:\")\n",
    "        print(f\"  - åˆ†æç”»åƒæ•°: {len(df)}\")\n",
    "        print(f\"  - æ¤œå‡ºã‚«ãƒ†ã‚´ãƒªæ•°: {df['semantic_category'].nunique()}\")\n",
    "        print(f\"  - ç·æ¤œå‡ºç‰©ä½“æ•°: {df['detected_objects_count'].sum()}\")\n",
    "        \n",
    "        # æ”¹å–„ç‡åˆ†æ\n",
    "        valid_improvements = df[df['improvement_rate'] != 0]['improvement_rate']\n",
    "        if len(valid_improvements) > 0:\n",
    "            print(f\"\\nğŸš€ ç‰¹åŒ–ã‚¢ãƒ—ãƒ­ãƒ¼ãƒåŠ¹æœ:\")\n",
    "            print(f\"  - å¹³å‡æ”¹å–„ç‡: {valid_improvements.mean():.2f}%\")\n",
    "            print(f\"  - æ¨™æº–åå·®: {valid_improvements.std():.2f}%\")\n",
    "            print(f\"  - æœ€å¤§æ”¹å–„ç‡: {valid_improvements.max():.2f}%\")\n",
    "            print(f\"  - æœ€å°æ”¹å–„ç‡: {valid_improvements.min():.2f}%\")\n",
    "            \n",
    "            positive_improvements = valid_improvements[valid_improvements > 0]\n",
    "            print(f\"  - æ”¹å–„ã‚’ç¤ºã—ãŸç”»åƒ: {len(positive_improvements)}/{len(valid_improvements)}\")\n",
    "            \n",
    "            if len(positive_improvements) > len(valid_improvements) / 2:\n",
    "                print(f\"  ğŸ¯ çµè«–: ç‰¹åŒ–ã‚¢ãƒ—ãƒ­ãƒ¼ãƒãŒåŠ¹æœçš„ã§ã™ï¼\")\n",
    "            else:\n",
    "                print(f\"  ğŸ“ çµè«–: ã•ã‚‰ãªã‚‹æ”¹å–„ãŒå¿…è¦ã§ã™\")\n",
    "        \n",
    "        # ã‚«ãƒ†ã‚´ãƒªåˆ¥åˆ†æ\n",
    "        print(f\"\\nğŸ“Š ã‚«ãƒ†ã‚´ãƒªåˆ¥è©³ç´°:\")\n",
    "        for category in df['semantic_category'].unique():\n",
    "            cat_data = df[df['semantic_category'] == category]\n",
    "            cat_improvements = cat_data[cat_data['improvement_rate'] != 0]['improvement_rate']\n",
    "            print(f\"  - {category}: {len(cat_data)}ç”»åƒ\", end=\"\")\n",
    "            if len(cat_improvements) > 0:\n",
    "                print(f\", å¹³å‡æ”¹å–„ç‡ {cat_improvements.mean():.2f}%\")\n",
    "            else:\n",
    "                print(f\", æ”¹å–„ç‡ãƒ‡ãƒ¼ã‚¿ãªã—\")\n",
    "        \n",
    "        # ã‚°ãƒ©ãƒ•ç”Ÿæˆ\n",
    "        self.create_visualizations(df)\n",
    "        \n",
    "        # ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜\n",
    "        self.save_results(df)\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def create_visualizations(self, df):\n",
    "        \"\"\"å¯è¦–åŒ–ã‚°ãƒ©ãƒ•ä½œæˆ\"\"\"\n",
    "        fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "        fig.suptitle('Claudeç ”ç©¶ã‚·ã‚¹ãƒ†ãƒ  - åˆ†æçµæœ', fontsize=16)\n",
    "        \n",
    "        # 1. æ”¹å–„ç‡åˆ†å¸ƒ\n",
    "        valid_improvements = df[df['improvement_rate'] != 0]['improvement_rate']\n",
    "        if len(valid_improvements) > 0:\n",
    "            axes[0, 0].hist(valid_improvements, bins=max(5, len(valid_improvements)//2), \n",
    "                           alpha=0.7, color='skyblue', edgecolor='black')\n",
    "            axes[0, 0].axvline(valid_improvements.mean(), color='red', linestyle='--', \n",
    "                              label=f'å¹³å‡: {valid_improvements.mean():.1f}%')\n",
    "            axes[0, 0].set_title('æ”¹å–„ç‡åˆ†å¸ƒ')\n",
    "            axes[0, 0].set_xlabel('æ”¹å–„ç‡ (%)')\n",
    "            axes[0, 0].set_ylabel('é »åº¦')\n",
    "            axes[0, 0].legend()\n",
    "        \n",
    "        # 2. ã‚«ãƒ†ã‚´ãƒªåˆ¥æ”¹å–„ç‡\n",
    "        category_improvement = df[df['improvement_rate'] != 0].groupby('semantic_category')['improvement_rate'].mean()\n",
    "        if len(category_improvement) > 0:\n",
    "            category_improvement.plot(kind='bar', ax=axes[0, 1], color='lightgreen')\n",
    "            axes[0, 1].set_title('ã‚«ãƒ†ã‚´ãƒªåˆ¥å¹³å‡æ”¹å–„ç‡')\n",
    "            axes[0, 1].set_xlabel('æ„å‘³ã‚«ãƒ†ã‚´ãƒª')\n",
    "            axes[0, 1].set_ylabel('å¹³å‡æ”¹å–„ç‡ (%)')\n",
    "            axes[0, 1].tick_params(axis='x', rotation=45)\n",
    "        \n",
    "        # 3. ã‚«ãƒ†ã‚´ãƒªåˆ†å¸ƒ\n",
    "        category_counts = df['semantic_category'].value_counts()\n",
    "        axes[1, 0].pie(category_counts.values, labels=category_counts.index, autopct='%1.1f%%')\n",
    "        axes[1, 0].set_title('æ„å‘³ã‚«ãƒ†ã‚´ãƒªåˆ†å¸ƒ')\n",
    "        \n",
    "        # 4. ç¢ºä¿¡åº¦æ¯”è¼ƒ\n",
    "        valid_confidences = df[(df['general_confidence'].notna()) & (df['specialized_confidence'].notna())]\n",
    "        if len(valid_confidences) > 0:\n",
    "            axes[1, 1].scatter(valid_confidences['general_confidence'], \n",
    "                              valid_confidences['specialized_confidence'], alpha=0.7)\n",
    "            axes[1, 1].plot([0, 1], [0, 1], 'r--', alpha=0.8, label='åŒç­‰ç·š')\n",
    "            axes[1, 1].set_title('ç¢ºä¿¡åº¦æ¯”è¼ƒ')\n",
    "            axes[1, 1].set_xlabel('æ±ç”¨ã‚¢ãƒ—ãƒ­ãƒ¼ãƒç¢ºä¿¡åº¦')\n",
    "            axes[1, 1].set_ylabel('ç‰¹åŒ–ã‚¢ãƒ—ãƒ­ãƒ¼ãƒç¢ºä¿¡åº¦')\n",
    "            axes[1, 1].legend()\n",
    "            axes[1, 1].set_xlim(0, 1)\n",
    "            axes[1, 1].set_ylim(0, 1)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    def save_results(self, df):\n",
    "        \"\"\"çµæœä¿å­˜\"\"\"\n",
    "        # CSVä¿å­˜\n",
    "        df.to_csv('claude_research_results.csv', index=False, encoding='utf-8')\n",
    "        \n",
    "        # JSONä¿å­˜\n",
    "        with open('claude_research_results.json', 'w', encoding='utf-8') as f:\n",
    "            json.dump(self.results, f, ensure_ascii=False, indent=2)\n",
    "        \n",
    "        print(f\"\\nğŸ’¾ çµæœä¿å­˜å®Œäº†:\")\n",
    "        print(f\"  - claude_research_results.csv\")\n",
    "        print(f\"  - claude_research_results.json\")\n",
    "        \n",
    "        # Colabãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰\n",
    "        try:\n",
    "            from google.colab import files\n",
    "            files.download('claude_research_results.csv')\n",
    "            files.download('claude_research_results.json')\n",
    "            print(f\"ğŸ“¥ ãƒ•ã‚¡ã‚¤ãƒ«è‡ªå‹•ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å®Œäº†\")\n",
    "        except:\n",
    "            print(f\"â„¹ï¸ ãƒ­ãƒ¼ã‚«ãƒ«ç’°å¢ƒã§å®Ÿè¡Œä¸­\")\n",
    "        \n",
    "        # Google Driveãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—\n",
    "        try:\n",
    "            if os.path.exists('/content/drive/MyDrive'):\n",
    "                import shutil\n",
    "                backup_dir = '/content/drive/MyDrive/claude_research_backup'\n",
    "                os.makedirs(backup_dir, exist_ok=True)\n",
    "                shutil.copy('claude_research_results.csv', backup_dir)\n",
    "                shutil.copy('claude_research_results.json', backup_dir)\n",
    "                print(f\"â˜ï¸ Google Driveãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—å®Œäº†\")\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "# Claudeç ”ç©¶ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–\n",
    "claude_research = ClaudeResearchSystem()\n",
    "print(\"ğŸ¯ Claudeç ”ç©¶ã‚·ã‚¹ãƒ†ãƒ æº–å‚™å®Œäº†ï¼\")\n",
    "print(\"ğŸ“¸ æ¬¡ã®ã‚»ãƒ«ã§ç”»åƒã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ç ”ç©¶ã‚’é–‹å§‹ã—ã¦ãã ã•ã„ã€‚\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸš€ Claudeç ”ç©¶å®Ÿè¡Œ - ã“ã®ã‚»ãƒ«ã§ç ”ç©¶é–‹å§‹ï¼\n",
    "\n",
    "print(\"ğŸ“¸ ç ”ç©¶ç”¨ç”»åƒã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„:\")\n",
    "print(\"è¤‡æ•°ã®ç”»åƒã‚’é¸æŠå¯èƒ½ã§ã™ï¼ˆJPG, PNG, BMP ãªã©ï¼‰\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# ç”»åƒã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰\n",
    "from google.colab import files\n",
    "uploaded = files.upload()\n",
    "\n",
    "if uploaded:\n",
    "    print(f\"\\nâœ… {len(uploaded)}å€‹ã®ç”»åƒãŒã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚Œã¾ã—ãŸ\")\n",
    "    print(\"ğŸ”¬ Claudeç ”ç©¶ã‚·ã‚¹ãƒ†ãƒ ã§åˆ†æã‚’é–‹å§‹...\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # å„ç”»åƒã‚’åˆ†æ\n",
    "    for i, filename in enumerate(uploaded.keys()):\n",
    "        print(f\"\\nğŸ“Š åˆ†æä¸­ ({i+1}/{len(uploaded)}): {filename}\")\n",
    "        print(\"-\" * 30)\n",
    "        \n",
    "        result = claude_research.analyze_image(filename)\n",
    "        \n",
    "        if result:\n",
    "            print(f\"âœ… åˆ†æå®Œäº†\")\n",
    "        else:\n",
    "            print(f\"âŒ åˆ†æå¤±æ•—\")\n",
    "    \n",
    "    # ç ”ç©¶ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ\n",
    "    print(\"\\nğŸ“Š ç ”ç©¶ãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆä¸­...\")\n",
    "    research_results = claude_research.generate_research_report()\n",
    "    \n",
    "    print(\"\\nğŸ‰ Claudeç ”ç©¶ã‚·ã‚¹ãƒ†ãƒ å®Ÿè¡Œå®Œäº†ï¼\")\n",
    "    print(\"ğŸ“¥ çµæœãƒ•ã‚¡ã‚¤ãƒ«ãŒãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã•ã‚Œã¾ã—ãŸã€‚\")\n",
    "    \n",
    "else:\n",
    "    print(\"âŒ ç”»åƒãŒã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ\")\n",
    "    print(\"ğŸ“¸ ä¸Šè¨˜ã§ç”»åƒã‚’é¸æŠã—ã¦ã‹ã‚‰ã“ã®ã‚»ãƒ«ã‚’å†å®Ÿè¡Œã—ã¦ãã ã•ã„\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ¯ Claudeç ”ç©¶ã‚·ã‚¹ãƒ†ãƒ ã®ç‰¹å¾´\n",
    "\n",
    "### ğŸ¤– AIæŠ€è¡“çµ±åˆ\n",
    "- **BLIP**: ç”»åƒã‚­ãƒ£ãƒ—ã‚·ãƒ§ãƒ³è‡ªå‹•ç”Ÿæˆ\n",
    "- **CLIP**: æ±ç”¨ãƒ»ç‰¹åŒ–ç”»åƒåˆ†é¡\n",
    "- **YOLO**: é«˜ç²¾åº¦ç‰©ä½“æ¤œå‡º\n",
    "- **WordNet**: æ„å‘³ã‚«ãƒ†ã‚´ãƒªåˆ†æ\n",
    "\n",
    "### ğŸ“Š è‡ªå‹•åˆ†ææ©Ÿèƒ½\n",
    "- **æ„å‘³ã‚«ãƒ†ã‚´ãƒªæ¤œå‡º**: 8ã‚«ãƒ†ã‚´ãƒªè‡ªå‹•åˆ¤å®š\n",
    "- **æ”¹å–„ç‡è¨ˆç®—**: ç‰¹åŒ–ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã®åŠ¹æœæ¸¬å®š\n",
    "- **çµ±è¨ˆåˆ†æ**: è©³ç´°ãªç ”ç©¶çµæœãƒ¬ãƒãƒ¼ãƒˆ\n",
    "- **å¯è¦–åŒ–**: 4ç¨®é¡ã®ã‚°ãƒ©ãƒ•è‡ªå‹•ç”Ÿæˆ\n",
    "\n",
    "### ğŸ’¾ çµæœå‡ºåŠ›\n",
    "- **CSVå½¢å¼**: è©³ç´°ãƒ‡ãƒ¼ã‚¿\n",
    "- **JSONå½¢å¼**: æ§‹é€ åŒ–ãƒ‡ãƒ¼ã‚¿\n",
    "- **è‡ªå‹•ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰**: Colabç’°å¢ƒ\n",
    "- **Driveè‡ªå‹•ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—**: ã‚¯ãƒ©ã‚¦ãƒ‰ä¿å­˜\n",
    "\n",
    "---\n",
    "**ğŸš€ ã“ã®ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã‚’æ—¢å­˜ã®Colabãƒ•ã‚¡ã‚¤ãƒ«ã«è¿½åŠ ã—ã¦ä½¿ç”¨ã—ã¦ãã ã•ã„ï¼**"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}